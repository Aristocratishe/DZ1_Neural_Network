{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "5b81ff7a",
      "metadata": {
        "id": "5b81ff7a"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "5df7a6f7",
      "metadata": {
        "id": "5df7a6f7"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from tqdm.auto import tqdm\n",
        "from IPython.display import display, clear_output\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from numpy import zeros\n",
        "from tqdm.auto import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jP-Bqw3D0k8o",
        "outputId": "72247897-d216-4c90-9a10-bf05fe00214c"
      },
      "id": "jP-Bqw3D0k8o",
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2732d2e2",
      "metadata": {
        "id": "2732d2e2"
      },
      "source": [
        "Введем некоторые константы"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "07cb8e7b",
      "metadata": {
        "id": "07cb8e7b"
      },
      "outputs": [],
      "source": [
        "NUM_LABELS = 10\n",
        "SEED = 99\n",
        "INPUT_DIR = \"/content/gdrive/MyDrive/DZ1_NeuralNetwork\" # путь до данных для обучения\n",
        "OUTPUT_FNAME = \"MySubmission.csv\" # здесь должно быть записано имя выходного файла с ответами модели\n",
        "CLS_LIST = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5eaaf805",
      "metadata": {
        "id": "5eaaf805"
      },
      "source": [
        "Загрузим данные для обучения и теста"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "ddd660eb",
      "metadata": {
        "id": "ddd660eb"
      },
      "outputs": [],
      "source": [
        "X_train = np.load(f\"{INPUT_DIR}/x_train.npy\")\n",
        "y_train = np.load(f\"{INPUT_DIR}/y_train.npy\")\n",
        "X_valid = np.load(f\"{INPUT_DIR}/x_test.npy\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KieTQZrl1N6q",
        "outputId": "ec4affd4-0283-4b76-cf23-648cf20056f2"
      },
      "id": "KieTQZrl1N6q",
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "275248eb",
      "metadata": {
        "id": "275248eb"
      },
      "source": [
        "Посмотрим, как выглядят наши данные"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "4d99cbc0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "4d99cbc0",
        "outputId": "1dcb5fc2-b1a2-4e03-c500-169311e5d34e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 16 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.figure(figsize=(8,8))\n",
        "np.random.seed(SEED)\n",
        "num_rc = 4\n",
        "for i in range(16):\n",
        "    idx = np.random.randint(X_train.shape[0])\n",
        "    ax = plt.subplot(num_rc, num_rc, i + 1)\n",
        "    ax.set_title(CLS_LIST[y_train[idx]])\n",
        "    ax.set_axis_off()\n",
        "    plt.imshow(X_train[idx].reshape(28,28), cmap='gray', vmin = 0, vmax = 255)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ffbef89",
      "metadata": {
        "id": "5ffbef89"
      },
      "source": [
        "Разделим обучение на train и test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "ca2dfbbd",
      "metadata": {
        "id": "ca2dfbbd"
      },
      "outputs": [],
      "source": [
        "# Необходимо дописать пайплайн разделения данных\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.05, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jg6LH8gB1WO2",
        "outputId": "52fb8f53-c37c-4554-cd3d-b205cede105c"
      },
      "id": "jg6LH8gB1WO2",
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "57000"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6a32d50",
      "metadata": {
        "id": "b6a32d50"
      },
      "source": [
        "Определим классы наших слоев"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "id": "c5070c03",
      "metadata": {
        "id": "c5070c03"
      },
      "outputs": [],
      "source": [
        "class Dense:\n",
        "    def __init__(self, in_size, out_size):\n",
        "        np.random.seed(1)\n",
        "        self.W = np.random.normal(scale=0.1, size=(out_size, in_size))\n",
        "        self.b = np.random.normal(scale=0.1, size=(out_size))\n",
        "        \n",
        "    def forward(self, x):\n",
        "        self.x = x # запоминаем для обратного прохода\n",
        "        return np.dot(self.W, x) + self.b\n",
        "    \n",
        "    def backward(self, dz, lr=0.01):\n",
        "        # вычисляем градиенты по параметрам (запоминаем их для отладки)\n",
        "        self.dW = np.outer(dz, self.x)\n",
        "        self.db = dz\n",
        "        # вычисляем производную по входу\n",
        "        self.dx = np.matmul(dz, self.W) \n",
        "        # обновляем веса\n",
        "        self.W = self.W - lr * self.dW\n",
        "        self.db = self.db - lr * self.db\n",
        "        # возвращаем dx для продолжения алгоритма\n",
        "        return self.dx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "4c252935",
      "metadata": {
        "id": "4c252935"
      },
      "outputs": [],
      "source": [
        "class ELU:\n",
        "    def __init__(self, alpha):\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.x = x  \n",
        "        return np.where(x > 0, x, self.alpha * (np.exp(x) - 1)) \n",
        "\n",
        "    def backward(self, dz, lr=0.001):\n",
        "        t = np.where(self.x > 0, 0, self.alpha * (np.exp(self.x) - 1))\n",
        "        dz.put([i for i in range(self.x.shape[0]) if self.x[i] < 0], t[t != 0])\n",
        "        return dz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ReLU:\n",
        "    def forward(self, x):\n",
        "        self.x = x\n",
        "        return np.maximum(0, x)\n",
        "    \n",
        "    def backward(self, dz, lr=0.001):\n",
        "        dz[self.x < 0] = 0\n",
        "        return dz"
      ],
      "metadata": {
        "id": "-NK86g46CPhx"
      },
      "id": "-NK86g46CPhx",
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "id": "357a80aa",
      "metadata": {
        "id": "357a80aa"
      },
      "outputs": [],
      "source": [
        "class Softmax:\n",
        "    def forward(self, x):\n",
        "        self.x = x\n",
        "        exps = np.exp(x - np.max(x))\n",
        "        return exps / np.sum(exps)\n",
        "        \n",
        "    \n",
        "    def backward(self, dz, lr=0.001):\n",
        "        sm = self.forward(self.x)\n",
        "        self.lp = (np.eye(sm.shape[0], sm.shape[0]) - sm).T\n",
        "        self.lp2 = sm * self.lp\n",
        "        return np.dot(dz, self.lp2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "id": "5b6aeb26",
      "metadata": {
        "id": "5b6aeb26"
      },
      "outputs": [],
      "source": [
        "class CrossEntropy:\n",
        "    def forward(self, y_true, y_hat):\n",
        "        self.y_true = y_true\n",
        "        self.y_hat = y_hat\n",
        "        return -np.sum( y_true * np.log(y_hat))\n",
        "    \n",
        "    def backward(self, dz, lr=0.001):\n",
        "        return dz * -1. * self.y_true / self.y_hat"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6bc0fefa",
      "metadata": {
        "id": "6bc0fefa"
      },
      "source": [
        "Соберем сеть для классификации изображений"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "id": "dd7d6a42",
      "metadata": {
        "id": "dd7d6a42"
      },
      "outputs": [],
      "source": [
        "class FashionMnistNet:\n",
        "  def __init__(self):\n",
        "    self.a1 = ReLU()\n",
        "    self.a2 = ReLU()\n",
        "    self.a3 = ReLU()\n",
        "    self.a4 = ReLU()\n",
        "    self.d1 = Dense(784, 128)\n",
        "    self.d2 = Dense(128, 128)\n",
        "    self.d3 = Dense(128, 128)\n",
        "    self.d4 = Dense(128, 128)\n",
        "    self.d5 = Dense(128, 10)\n",
        "    self.sm = Softmax()\n",
        "    \n",
        "  def forward(self, x):\n",
        "    net = self.d1.forward(x)\n",
        "    net = self.a1.forward(net)\n",
        "    net = self.d2.forward(net)\n",
        "    net = self.a2.forward(net)\n",
        "    net = self.d3.forward(net)\n",
        "    net = self.a3.forward(net)\n",
        "    net = self.d4.forward(net)\n",
        "    net = self.a4.forward(net)\n",
        "    net = self.d5.forward(net)\n",
        "    net = self.sm.forward(net)\n",
        "    self.net = net\n",
        "    return net\n",
        "\n",
        "  def backward(self, dz, lr=0.001):\n",
        "    dz = self.sm.backward(dz, lr)\n",
        "    dz = self.d5.backward(dz, lr)\n",
        "    dz = self.a4.backward(dz, lr)\n",
        "    dz = self.d4.backward(dz, lr)\n",
        "    dz = self.a3.backward(dz, lr)\n",
        "    dz = self.d3.backward(dz, lr)\n",
        "    dz = self.a2.backward(dz, lr)\n",
        "    dz = self.d2.backward(dz, lr)\n",
        "    dz = self.a1.backward(dz, lr)\n",
        "    dz = self.d1.backward(dz, lr)\n",
        "    return dz"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8296ac2",
      "metadata": {
        "id": "c8296ac2"
      },
      "source": [
        "Предобработаем наши данные"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "id": "38903ed5",
      "metadata": {
        "id": "38903ed5"
      },
      "outputs": [],
      "source": [
        "# тут необходимо дописать базовую предобработку датасета\n",
        "scaler = MinMaxScaler()\n",
        "Xt_train_mod = scaler.fit_transform(X_train)\n",
        "Xt_test_mod = scaler.fit_transform(X_test)\n",
        "X_valid_mod = scaler.fit_transform(X_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "id": "fdbfe2cf",
      "metadata": {
        "id": "fdbfe2cf"
      },
      "outputs": [],
      "source": [
        "# заэнкодим наши ответы\n",
        "t = OneHotEncoder(sparse=False)\n",
        "yt_train_oh = t.fit_transform(y_train.reshape(-1, 1))\n",
        "yt_test_oh = t.fit_transform(y_test.reshape(-1, 1))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = FashionMnistNet()"
      ],
      "metadata": {
        "id": "khP8DB4bR4Xk"
      },
      "id": "khP8DB4bR4Xk",
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "id": "02c76b62",
      "metadata": {
        "id": "02c76b62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "057c56bb7c63429588a1ae7b02bd1ee3",
            "7417324dfa2e411f869f59820c370cad",
            "7b45758f3438487094a0f4ab032c7641",
            "c3346df0d1aa486ea84f8b4280c42c7b",
            "8247dbc9c7e5426093e40e8d0b3f8d01",
            "2c4fc5885cf342c38b39655bbeebcae4",
            "ec80d5f905624c5fa5e63426b8696f45",
            "3a5041d6cfde40fba520d53400611162",
            "78d6bb76ac644552b90ec10402e14b30",
            "904ca9309a3745bfb393becc615920de",
            "5dd52d5f6f124352915a32ca4ec9c105"
          ]
        },
        "outputId": "fa39650f-76ee-4ac0-d184-0fda3ce0c79b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "057c56bb7c63429588a1ae7b02bd1ee3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mВыходные данные были обрезаны до нескольких последних строк (5000).\u001b[0m\n",
            "Accuracy:  0.878\n",
            "############################################################\n",
            "Loss at train in  167  epoch\n",
            "0.008494276310589232\n",
            "Loss at test in  167  epoch\n",
            "0.34006460380068065\n",
            "Accuracy:  0.8763333333333333\n",
            "############################################################\n",
            "Loss at train in  168  epoch\n",
            "0.008410003126549494\n",
            "Loss at test in  168  epoch\n",
            "0.3407374486079156\n",
            "Accuracy:  0.878\n",
            "############################################################\n",
            "Loss at train in  169  epoch\n",
            "0.007975343984293903\n",
            "Loss at test in  169  epoch\n",
            "0.35011406488606145\n",
            "Accuracy:  0.8716666666666667\n",
            "############################################################\n",
            "Loss at train in  170  epoch\n",
            "0.008401133460742258\n",
            "Loss at test in  170  epoch\n",
            "0.32749349207262624\n",
            "Accuracy:  0.8796666666666667\n",
            "############################################################\n",
            "Loss at train in  171  epoch\n",
            "0.00861249485478777\n",
            "Loss at test in  171  epoch\n",
            "0.3231615842182642\n",
            "Accuracy:  0.8866666666666667\n",
            "############################################################\n",
            "Loss at train in  172  epoch\n",
            "0.00834298031077697\n",
            "Loss at test in  172  epoch\n",
            "0.3454269769112038\n",
            "Accuracy:  0.875\n",
            "############################################################\n",
            "Loss at train in  173  epoch\n",
            "0.008941803091906196\n",
            "Loss at test in  173  epoch\n",
            "0.3372843429319081\n",
            "Accuracy:  0.874\n",
            "############################################################\n",
            "Loss at train in  174  epoch\n",
            "0.008376847806251114\n",
            "Loss at test in  174  epoch\n",
            "0.33611658475042655\n",
            "Accuracy:  0.879\n",
            "############################################################\n",
            "Loss at train in  175  epoch\n",
            "0.008621253840169882\n",
            "Loss at test in  175  epoch\n",
            "0.33884700220153297\n",
            "Accuracy:  0.8743333333333333\n",
            "############################################################\n",
            "Loss at train in  176  epoch\n",
            "0.00895946822656055\n",
            "Loss at test in  176  epoch\n",
            "0.3569504449104327\n",
            "Accuracy:  0.875\n",
            "############################################################\n",
            "Loss at train in  177  epoch\n",
            "0.008246692082122406\n",
            "Loss at test in  177  epoch\n",
            "0.35881367452347285\n",
            "Accuracy:  0.8686666666666667\n",
            "############################################################\n",
            "Loss at train in  178  epoch\n",
            "0.00878341523264529\n",
            "Loss at test in  178  epoch\n",
            "0.3382167115804223\n",
            "Accuracy:  0.874\n",
            "############################################################\n",
            "Loss at train in  179  epoch\n",
            "0.00883806350200578\n",
            "Loss at test in  179  epoch\n",
            "0.3437927653798409\n",
            "Accuracy:  0.875\n",
            "############################################################\n",
            "Loss at train in  180  epoch\n",
            "0.008464751688205962\n",
            "Loss at test in  180  epoch\n",
            "0.32916283031864807\n",
            "Accuracy:  0.8833333333333333\n",
            "############################################################\n",
            "Loss at train in  181  epoch\n",
            "0.009311980413054172\n",
            "Loss at test in  181  epoch\n",
            "0.3359105754386338\n",
            "Accuracy:  0.872\n",
            "############################################################\n",
            "Loss at train in  182  epoch\n",
            "0.008097501055277682\n",
            "Loss at test in  182  epoch\n",
            "0.344728691917096\n",
            "Accuracy:  0.8743333333333333\n",
            "############################################################\n",
            "Loss at train in  183  epoch\n",
            "0.008502942415435854\n",
            "Loss at test in  183  epoch\n",
            "0.35533816203658064\n",
            "Accuracy:  0.8696666666666667\n",
            "############################################################\n",
            "Loss at train in  184  epoch\n",
            "0.007556831656204652\n",
            "Loss at test in  184  epoch\n",
            "0.3676948534823988\n",
            "Accuracy:  0.8673333333333333\n",
            "############################################################\n",
            "Loss at train in  185  epoch\n",
            "0.008470463946023164\n",
            "Loss at test in  185  epoch\n",
            "0.3469136946402028\n",
            "Accuracy:  0.8696666666666667\n",
            "############################################################\n",
            "Loss at train in  186  epoch\n",
            "0.008662259347763894\n",
            "Loss at test in  186  epoch\n",
            "0.32297673624970297\n",
            "Accuracy:  0.88\n",
            "############################################################\n",
            "Loss at train in  187  epoch\n",
            "0.008139999430996579\n",
            "Loss at test in  187  epoch\n",
            "0.3175689533743194\n",
            "Accuracy:  0.8853333333333333\n",
            "############################################################\n",
            "Loss at train in  188  epoch\n",
            "0.009081828342776908\n",
            "Loss at test in  188  epoch\n",
            "0.32444548743226204\n",
            "Accuracy:  0.883\n",
            "############################################################\n",
            "Loss at train in  189  epoch\n",
            "0.008170309039634224\n",
            "Loss at test in  189  epoch\n",
            "0.336839395894093\n",
            "Accuracy:  0.881\n",
            "############################################################\n",
            "Loss at train in  190  epoch\n",
            "0.007426666849277754\n",
            "Loss at test in  190  epoch\n",
            "0.33754082745828834\n",
            "Accuracy:  0.877\n",
            "############################################################\n",
            "Loss at train in  191  epoch\n",
            "0.008464265708360378\n",
            "Loss at test in  191  epoch\n",
            "0.33610209682761\n",
            "Accuracy:  0.8793333333333333\n",
            "############################################################\n",
            "Loss at train in  192  epoch\n",
            "0.008146685527963042\n",
            "Loss at test in  192  epoch\n",
            "0.32423842401909164\n",
            "Accuracy:  0.883\n",
            "############################################################\n",
            "Loss at train in  193  epoch\n",
            "0.008546881122433105\n",
            "Loss at test in  193  epoch\n",
            "0.32478756909198575\n",
            "Accuracy:  0.8773333333333333\n",
            "############################################################\n",
            "Loss at train in  194  epoch\n",
            "0.009171112601565357\n",
            "Loss at test in  194  epoch\n",
            "0.32648888883687727\n",
            "Accuracy:  0.882\n",
            "############################################################\n",
            "Loss at train in  195  epoch\n",
            "0.008075295229111419\n",
            "Loss at test in  195  epoch\n",
            "0.32680116085113514\n",
            "Accuracy:  0.8856666666666667\n",
            "############################################################\n",
            "Loss at train in  196  epoch\n",
            "0.008403359083996973\n",
            "Loss at test in  196  epoch\n",
            "0.3420313134217515\n",
            "Accuracy:  0.8733333333333333\n",
            "############################################################\n",
            "Loss at train in  197  epoch\n",
            "0.007398825890068243\n",
            "Loss at test in  197  epoch\n",
            "0.3358163176844111\n",
            "Accuracy:  0.8733333333333333\n",
            "############################################################\n",
            "Loss at train in  198  epoch\n",
            "0.008357127279078053\n",
            "Loss at test in  198  epoch\n",
            "0.33358378094612723\n",
            "Accuracy:  0.876\n",
            "############################################################\n",
            "Loss at train in  199  epoch\n",
            "0.007541337426759637\n",
            "Loss at test in  199  epoch\n",
            "0.3560257677201638\n",
            "Accuracy:  0.8656666666666667\n",
            "############################################################\n",
            "Loss at train in  200  epoch\n",
            "0.008339403037471426\n",
            "Loss at test in  200  epoch\n",
            "0.3250359448015561\n",
            "Accuracy:  0.8826666666666667\n",
            "############################################################\n",
            "Loss at train in  201  epoch\n",
            "0.008226340243059172\n",
            "Loss at test in  201  epoch\n",
            "0.35204029942474124\n",
            "Accuracy:  0.8786666666666667\n",
            "############################################################\n",
            "Loss at train in  202  epoch\n",
            "0.007683819440175869\n",
            "Loss at test in  202  epoch\n",
            "0.357017460363873\n",
            "Accuracy:  0.8656666666666667\n",
            "############################################################\n",
            "Loss at train in  203  epoch\n",
            "0.008073596726236245\n",
            "Loss at test in  203  epoch\n",
            "0.32640170032657406\n",
            "Accuracy:  0.876\n",
            "############################################################\n",
            "Loss at train in  204  epoch\n",
            "0.0075016886653796935\n",
            "Loss at test in  204  epoch\n",
            "0.32827324685772274\n",
            "Accuracy:  0.881\n",
            "############################################################\n",
            "Loss at train in  205  epoch\n",
            "0.007711010323534185\n",
            "Loss at test in  205  epoch\n",
            "0.3230349959664869\n",
            "Accuracy:  0.881\n",
            "############################################################\n",
            "Loss at train in  206  epoch\n",
            "0.00806980335380862\n",
            "Loss at test in  206  epoch\n",
            "0.3255823855353477\n",
            "Accuracy:  0.8806666666666667\n",
            "############################################################\n",
            "Loss at train in  207  epoch\n",
            "0.007285724010532376\n",
            "Loss at test in  207  epoch\n",
            "0.34062338215619087\n",
            "Accuracy:  0.8806666666666667\n",
            "############################################################\n",
            "Loss at train in  208  epoch\n",
            "0.007290275567503766\n",
            "Loss at test in  208  epoch\n",
            "0.3275476097587882\n",
            "Accuracy:  0.8793333333333333\n",
            "############################################################\n",
            "Loss at train in  209  epoch\n",
            "0.007225469287626624\n",
            "Loss at test in  209  epoch\n",
            "0.34344434101709165\n",
            "Accuracy:  0.8756666666666667\n",
            "############################################################\n",
            "Loss at train in  210  epoch\n",
            "0.00849857371695288\n",
            "Loss at test in  210  epoch\n",
            "0.3517087989326174\n",
            "Accuracy:  0.8706666666666667\n",
            "############################################################\n",
            "Loss at train in  211  epoch\n",
            "0.008266894300868872\n",
            "Loss at test in  211  epoch\n",
            "0.32301715941860226\n",
            "Accuracy:  0.8816666666666667\n",
            "############################################################\n",
            "Loss at train in  212  epoch\n",
            "0.00833507739680597\n",
            "Loss at test in  212  epoch\n",
            "0.35342217613908966\n",
            "Accuracy:  0.8653333333333333\n",
            "############################################################\n",
            "Loss at train in  213  epoch\n",
            "0.007664318511103093\n",
            "Loss at test in  213  epoch\n",
            "0.3162533250949039\n",
            "Accuracy:  0.8786666666666667\n",
            "############################################################\n",
            "Loss at train in  214  epoch\n",
            "0.007519357099824928\n",
            "Loss at test in  214  epoch\n",
            "0.3450476900359561\n",
            "Accuracy:  0.869\n",
            "############################################################\n",
            "Loss at train in  215  epoch\n",
            "0.007833852343931759\n",
            "Loss at test in  215  epoch\n",
            "0.3282270986644789\n",
            "Accuracy:  0.8763333333333333\n",
            "############################################################\n",
            "Loss at train in  216  epoch\n",
            "0.0077074521120930215\n",
            "Loss at test in  216  epoch\n",
            "0.3289196772458492\n",
            "Accuracy:  0.8746666666666667\n",
            "############################################################\n",
            "Loss at train in  217  epoch\n",
            "0.00794102505597031\n",
            "Loss at test in  217  epoch\n",
            "0.34158916203594775\n",
            "Accuracy:  0.874\n",
            "############################################################\n",
            "Loss at train in  218  epoch\n",
            "0.007880642347480645\n",
            "Loss at test in  218  epoch\n",
            "0.33777657752512014\n",
            "Accuracy:  0.8736666666666667\n",
            "############################################################\n",
            "Loss at train in  219  epoch\n",
            "0.007679917729145417\n",
            "Loss at test in  219  epoch\n",
            "0.3339981257892282\n",
            "Accuracy:  0.8756666666666667\n",
            "############################################################\n",
            "Loss at train in  220  epoch\n",
            "0.008075184103557785\n",
            "Loss at test in  220  epoch\n",
            "0.33288967656112267\n",
            "Accuracy:  0.8776666666666667\n",
            "############################################################\n",
            "Loss at train in  221  epoch\n",
            "0.008652760218554035\n",
            "Loss at test in  221  epoch\n",
            "0.3290102272856745\n",
            "Accuracy:  0.882\n",
            "############################################################\n",
            "Loss at train in  222  epoch\n",
            "0.007809973755600661\n",
            "Loss at test in  222  epoch\n",
            "0.3310897164368771\n",
            "Accuracy:  0.878\n",
            "############################################################\n",
            "Loss at train in  223  epoch\n",
            "0.008035973272670912\n",
            "Loss at test in  223  epoch\n",
            "0.31470250363147184\n",
            "Accuracy:  0.8876666666666667\n",
            "############################################################\n",
            "Loss at train in  224  epoch\n",
            "0.00826500789135158\n",
            "Loss at test in  224  epoch\n",
            "0.31659809261065247\n",
            "Accuracy:  0.882\n",
            "############################################################\n",
            "Loss at train in  225  epoch\n",
            "0.007222700307218919\n",
            "Loss at test in  225  epoch\n",
            "0.3274106354950656\n",
            "Accuracy:  0.8756666666666667\n",
            "############################################################\n",
            "Loss at train in  226  epoch\n",
            "0.007778006330093469\n",
            "Loss at test in  226  epoch\n",
            "0.3558959924480224\n",
            "Accuracy:  0.8756666666666667\n",
            "############################################################\n",
            "Loss at train in  227  epoch\n",
            "0.007282051413243464\n",
            "Loss at test in  227  epoch\n",
            "0.3147404676373715\n",
            "Accuracy:  0.885\n",
            "############################################################\n",
            "Loss at train in  228  epoch\n",
            "0.007572613053032183\n",
            "Loss at test in  228  epoch\n",
            "0.32532516748821727\n",
            "Accuracy:  0.8836666666666667\n",
            "############################################################\n",
            "Loss at train in  229  epoch\n",
            "0.008376128308119022\n",
            "Loss at test in  229  epoch\n",
            "0.3236772985719921\n",
            "Accuracy:  0.8816666666666667\n",
            "############################################################\n",
            "Loss at train in  230  epoch\n",
            "0.007689269133549103\n",
            "Loss at test in  230  epoch\n",
            "0.3350037998295206\n",
            "Accuracy:  0.878\n",
            "############################################################\n",
            "Loss at train in  231  epoch\n",
            "0.008401925886809498\n",
            "Loss at test in  231  epoch\n",
            "0.33778903085591977\n",
            "Accuracy:  0.88\n",
            "############################################################\n",
            "Loss at train in  232  epoch\n",
            "0.006818539424065232\n",
            "Loss at test in  232  epoch\n",
            "0.32488767531149515\n",
            "Accuracy:  0.8826666666666667\n",
            "############################################################\n",
            "Loss at train in  233  epoch\n",
            "0.008825204773706328\n",
            "Loss at test in  233  epoch\n",
            "0.32943900931897696\n",
            "Accuracy:  0.879\n",
            "############################################################\n",
            "Loss at train in  234  epoch\n",
            "0.007982401634308108\n",
            "Loss at test in  234  epoch\n",
            "0.33917768234754747\n",
            "Accuracy:  0.8743333333333333\n",
            "############################################################\n",
            "Loss at train in  235  epoch\n",
            "0.008194289215490579\n",
            "Loss at test in  235  epoch\n",
            "0.3172896088132671\n",
            "Accuracy:  0.8853333333333333\n",
            "############################################################\n",
            "Loss at train in  236  epoch\n",
            "0.0073343329989840125\n",
            "Loss at test in  236  epoch\n",
            "0.34446933608112024\n",
            "Accuracy:  0.879\n",
            "############################################################\n",
            "Loss at train in  237  epoch\n",
            "0.007668227697402365\n",
            "Loss at test in  237  epoch\n",
            "0.3208098178190517\n",
            "Accuracy:  0.8866666666666667\n",
            "############################################################\n",
            "Loss at train in  238  epoch\n",
            "0.007245975266446643\n",
            "Loss at test in  238  epoch\n",
            "0.331827678453135\n",
            "Accuracy:  0.876\n",
            "############################################################\n",
            "Loss at train in  239  epoch\n",
            "0.007146093477763567\n",
            "Loss at test in  239  epoch\n",
            "0.31491039576601715\n",
            "Accuracy:  0.8893333333333333\n",
            "############################################################\n",
            "Loss at train in  240  epoch\n",
            "0.007151406126443632\n",
            "Loss at test in  240  epoch\n",
            "0.35433283856288644\n",
            "Accuracy:  0.8776666666666667\n",
            "############################################################\n",
            "Loss at train in  241  epoch\n",
            "0.007878707098731553\n",
            "Loss at test in  241  epoch\n",
            "0.3130338755676808\n",
            "Accuracy:  0.8843333333333333\n",
            "############################################################\n",
            "Loss at train in  242  epoch\n",
            "0.008279056993008925\n",
            "Loss at test in  242  epoch\n",
            "0.3187507552273326\n",
            "Accuracy:  0.8813333333333333\n",
            "############################################################\n",
            "Loss at train in  243  epoch\n",
            "0.0073829043488579885\n",
            "Loss at test in  243  epoch\n",
            "0.31667932341313043\n",
            "Accuracy:  0.889\n",
            "############################################################\n",
            "Loss at train in  244  epoch\n",
            "0.007564799588922917\n",
            "Loss at test in  244  epoch\n",
            "0.31992736678091144\n",
            "Accuracy:  0.883\n",
            "############################################################\n",
            "Loss at train in  245  epoch\n",
            "0.006960717476156026\n",
            "Loss at test in  245  epoch\n",
            "0.3242540698903344\n",
            "Accuracy:  0.882\n",
            "############################################################\n",
            "Loss at train in  246  epoch\n",
            "0.0078099843705810015\n",
            "Loss at test in  246  epoch\n",
            "0.3244977327685069\n",
            "Accuracy:  0.881\n",
            "############################################################\n",
            "Loss at train in  247  epoch\n",
            "0.007588031520293356\n",
            "Loss at test in  247  epoch\n",
            "0.31845773555755946\n",
            "Accuracy:  0.887\n",
            "############################################################\n",
            "Loss at train in  248  epoch\n",
            "0.007918949633398556\n",
            "Loss at test in  248  epoch\n",
            "0.32758582610031295\n",
            "Accuracy:  0.883\n",
            "############################################################\n",
            "Loss at train in  249  epoch\n",
            "0.00718277631603679\n",
            "Loss at test in  249  epoch\n",
            "0.34718096659937114\n",
            "Accuracy:  0.8713333333333333\n",
            "############################################################\n",
            "Loss at train in  250  epoch\n",
            "0.007450377577487904\n",
            "Loss at test in  250  epoch\n",
            "0.3084116185870866\n",
            "Accuracy:  0.888\n",
            "############################################################\n",
            "Loss at train in  251  epoch\n",
            "0.008077735498925211\n",
            "Loss at test in  251  epoch\n",
            "0.33623727182172775\n",
            "Accuracy:  0.88\n",
            "############################################################\n",
            "Loss at train in  252  epoch\n",
            "0.007762899070810376\n",
            "Loss at test in  252  epoch\n",
            "0.3310207027483336\n",
            "Accuracy:  0.878\n",
            "############################################################\n",
            "Loss at train in  253  epoch\n",
            "0.007895662583807618\n",
            "Loss at test in  253  epoch\n",
            "0.32969770162471207\n",
            "Accuracy:  0.8786666666666667\n",
            "############################################################\n",
            "Loss at train in  254  epoch\n",
            "0.007584725192230458\n",
            "Loss at test in  254  epoch\n",
            "0.31875798330846944\n",
            "Accuracy:  0.8803333333333333\n",
            "############################################################\n",
            "Loss at train in  255  epoch\n",
            "0.007872371742168404\n",
            "Loss at test in  255  epoch\n",
            "0.32195092163654054\n",
            "Accuracy:  0.8793333333333333\n",
            "############################################################\n",
            "Loss at train in  256  epoch\n",
            "0.00835852017948804\n",
            "Loss at test in  256  epoch\n",
            "0.32585402725423424\n",
            "Accuracy:  0.8776666666666667\n",
            "############################################################\n",
            "Loss at train in  257  epoch\n",
            "0.007272172045899351\n",
            "Loss at test in  257  epoch\n",
            "0.3165423378041173\n",
            "Accuracy:  0.88\n",
            "############################################################\n",
            "Loss at train in  258  epoch\n",
            "0.007783738419961736\n",
            "Loss at test in  258  epoch\n",
            "0.3194439234969935\n",
            "Accuracy:  0.887\n",
            "############################################################\n",
            "Loss at train in  259  epoch\n",
            "0.0072127653466473925\n",
            "Loss at test in  259  epoch\n",
            "0.32749942929457954\n",
            "Accuracy:  0.8863333333333333\n",
            "############################################################\n",
            "Loss at train in  260  epoch\n",
            "0.007910483227353455\n",
            "Loss at test in  260  epoch\n",
            "0.31495638981806195\n",
            "Accuracy:  0.882\n",
            "############################################################\n",
            "Loss at train in  261  epoch\n",
            "0.007598896344361467\n",
            "Loss at test in  261  epoch\n",
            "0.3158396813360412\n",
            "Accuracy:  0.8823333333333333\n",
            "############################################################\n",
            "Loss at train in  262  epoch\n",
            "0.007898526622192467\n",
            "Loss at test in  262  epoch\n",
            "0.3196040669637769\n",
            "Accuracy:  0.8763333333333333\n",
            "############################################################\n",
            "Loss at train in  263  epoch\n",
            "0.007445407329057135\n",
            "Loss at test in  263  epoch\n",
            "0.3306103112397268\n",
            "Accuracy:  0.8816666666666667\n",
            "############################################################\n",
            "Loss at train in  264  epoch\n",
            "0.006854754339809386\n",
            "Loss at test in  264  epoch\n",
            "0.33001679467139083\n",
            "Accuracy:  0.89\n",
            "############################################################\n",
            "Loss at train in  265  epoch\n",
            "0.007398550045520722\n",
            "Loss at test in  265  epoch\n",
            "0.3051710550854828\n",
            "Accuracy:  0.8926666666666667\n",
            "############################################################\n",
            "Loss at train in  266  epoch\n",
            "0.006719187814894985\n",
            "Loss at test in  266  epoch\n",
            "0.3316457882311027\n",
            "Accuracy:  0.88\n",
            "############################################################\n",
            "Loss at train in  267  epoch\n",
            "0.007711353899292338\n",
            "Loss at test in  267  epoch\n",
            "0.3263021663907154\n",
            "Accuracy:  0.8866666666666667\n",
            "############################################################\n",
            "Loss at train in  268  epoch\n",
            "0.007144574212565893\n",
            "Loss at test in  268  epoch\n",
            "0.31700166426279874\n",
            "Accuracy:  0.8843333333333333\n",
            "############################################################\n",
            "Loss at train in  269  epoch\n",
            "0.007571576312058502\n",
            "Loss at test in  269  epoch\n",
            "0.33001464268567327\n",
            "Accuracy:  0.8783333333333333\n",
            "############################################################\n",
            "Loss at train in  270  epoch\n",
            "0.007133565227908819\n",
            "Loss at test in  270  epoch\n",
            "0.30940403650664416\n",
            "Accuracy:  0.889\n",
            "############################################################\n",
            "Loss at train in  271  epoch\n",
            "0.007135440500826104\n",
            "Loss at test in  271  epoch\n",
            "0.31995686003001056\n",
            "Accuracy:  0.883\n",
            "############################################################\n",
            "Loss at train in  272  epoch\n",
            "0.008371929205732353\n",
            "Loss at test in  272  epoch\n",
            "0.3155869925764581\n",
            "Accuracy:  0.8876666666666667\n",
            "############################################################\n",
            "Loss at train in  273  epoch\n",
            "0.008202688520628726\n",
            "Loss at test in  273  epoch\n",
            "0.32038572336448645\n",
            "Accuracy:  0.8853333333333333\n",
            "############################################################\n",
            "Loss at train in  274  epoch\n",
            "0.006851351967064372\n",
            "Loss at test in  274  epoch\n",
            "0.36263015002334276\n",
            "Accuracy:  0.8633333333333333\n",
            "############################################################\n",
            "Loss at train in  275  epoch\n",
            "0.006794643086893473\n",
            "Loss at test in  275  epoch\n",
            "0.3103888029822516\n",
            "Accuracy:  0.885\n",
            "############################################################\n",
            "Loss at train in  276  epoch\n",
            "0.007440954639381807\n",
            "Loss at test in  276  epoch\n",
            "0.3162122572420718\n",
            "Accuracy:  0.882\n",
            "############################################################\n",
            "Loss at train in  277  epoch\n",
            "0.007546357651589173\n",
            "Loss at test in  277  epoch\n",
            "0.31704435965758876\n",
            "Accuracy:  0.88\n",
            "############################################################\n",
            "Loss at train in  278  epoch\n",
            "0.006810863770473336\n",
            "Loss at test in  278  epoch\n",
            "0.3144557633377499\n",
            "Accuracy:  0.8893333333333333\n",
            "############################################################\n",
            "Loss at train in  279  epoch\n",
            "0.007474510946413017\n",
            "Loss at test in  279  epoch\n",
            "0.3021946248987613\n",
            "Accuracy:  0.8896666666666667\n",
            "############################################################\n",
            "Loss at train in  280  epoch\n",
            "0.00813566899992045\n",
            "Loss at test in  280  epoch\n",
            "0.31489527259920475\n",
            "Accuracy:  0.8846666666666667\n",
            "############################################################\n",
            "Loss at train in  281  epoch\n",
            "0.007329863841327253\n",
            "Loss at test in  281  epoch\n",
            "0.350198550268531\n",
            "Accuracy:  0.8763333333333333\n",
            "############################################################\n",
            "Loss at train in  282  epoch\n",
            "0.006790781665895647\n",
            "Loss at test in  282  epoch\n",
            "0.34772836920466904\n",
            "Accuracy:  0.8746666666666667\n",
            "############################################################\n",
            "Loss at train in  283  epoch\n",
            "0.008347559156647814\n",
            "Loss at test in  283  epoch\n",
            "0.312946949976755\n",
            "Accuracy:  0.886\n",
            "############################################################\n",
            "Loss at train in  284  epoch\n",
            "0.006587726462609831\n",
            "Loss at test in  284  epoch\n",
            "0.3106316170721915\n",
            "Accuracy:  0.8886666666666667\n",
            "############################################################\n",
            "Loss at train in  285  epoch\n",
            "0.007149920879410989\n",
            "Loss at test in  285  epoch\n",
            "0.31416773864961445\n",
            "Accuracy:  0.8893333333333333\n",
            "############################################################\n",
            "Loss at train in  286  epoch\n",
            "0.007652492227980958\n",
            "Loss at test in  286  epoch\n",
            "0.32372119284768236\n",
            "Accuracy:  0.8893333333333333\n",
            "############################################################\n",
            "Loss at train in  287  epoch\n",
            "0.007297302106437474\n",
            "Loss at test in  287  epoch\n",
            "0.31178759245115845\n",
            "Accuracy:  0.8873333333333333\n",
            "############################################################\n",
            "Loss at train in  288  epoch\n",
            "0.0072779876162224364\n",
            "Loss at test in  288  epoch\n",
            "0.3184051020280339\n",
            "Accuracy:  0.8876666666666667\n",
            "############################################################\n",
            "Loss at train in  289  epoch\n",
            "0.008138387339453162\n",
            "Loss at test in  289  epoch\n",
            "0.33219179938183385\n",
            "Accuracy:  0.8766666666666667\n",
            "############################################################\n",
            "Loss at train in  290  epoch\n",
            "0.007203930593347394\n",
            "Loss at test in  290  epoch\n",
            "0.320939202693819\n",
            "Accuracy:  0.8843333333333333\n",
            "############################################################\n",
            "Loss at train in  291  epoch\n",
            "0.007484812791144018\n",
            "Loss at test in  291  epoch\n",
            "0.31888927524182403\n",
            "Accuracy:  0.88\n",
            "############################################################\n",
            "Loss at train in  292  epoch\n",
            "0.007966909852898031\n",
            "Loss at test in  292  epoch\n",
            "0.3286748088088536\n",
            "Accuracy:  0.881\n",
            "############################################################\n",
            "Loss at train in  293  epoch\n",
            "0.007683039869249664\n",
            "Loss at test in  293  epoch\n",
            "0.3152280953037212\n",
            "Accuracy:  0.88\n",
            "############################################################\n",
            "Loss at train in  294  epoch\n",
            "0.006950783887460337\n",
            "Loss at test in  294  epoch\n",
            "0.369047842447711\n",
            "Accuracy:  0.8663333333333333\n",
            "############################################################\n",
            "Loss at train in  295  epoch\n",
            "0.006891671395827593\n",
            "Loss at test in  295  epoch\n",
            "0.33523821953568245\n",
            "Accuracy:  0.872\n",
            "############################################################\n",
            "Loss at train in  296  epoch\n",
            "0.0070820081527865255\n",
            "Loss at test in  296  epoch\n",
            "0.3293397859827853\n",
            "Accuracy:  0.882\n",
            "############################################################\n",
            "Loss at train in  297  epoch\n",
            "0.007399335283101477\n",
            "Loss at test in  297  epoch\n",
            "0.3445574703963018\n",
            "Accuracy:  0.8766666666666667\n",
            "############################################################\n",
            "Loss at train in  298  epoch\n",
            "0.006988815947169754\n",
            "Loss at test in  298  epoch\n",
            "0.31952715100068135\n",
            "Accuracy:  0.8856666666666667\n",
            "############################################################\n",
            "Loss at train in  299  epoch\n",
            "0.006523550929815958\n",
            "Loss at test in  299  epoch\n",
            "0.318119383431318\n",
            "Accuracy:  0.8896666666666667\n",
            "############################################################\n",
            "Loss at train in  300  epoch\n",
            "0.008058919810436934\n",
            "Loss at test in  300  epoch\n",
            "0.3385402340007975\n",
            "Accuracy:  0.8786666666666667\n",
            "############################################################\n",
            "Loss at train in  301  epoch\n",
            "0.0069538451469413854\n",
            "Loss at test in  301  epoch\n",
            "0.3226727758861958\n",
            "Accuracy:  0.8806666666666667\n",
            "############################################################\n",
            "Loss at train in  302  epoch\n",
            "0.007611620763222453\n",
            "Loss at test in  302  epoch\n",
            "0.3417390854422125\n",
            "Accuracy:  0.8783333333333333\n",
            "############################################################\n",
            "Loss at train in  303  epoch\n",
            "0.00663695850458058\n",
            "Loss at test in  303  epoch\n",
            "0.32465558809009526\n",
            "Accuracy:  0.8813333333333333\n",
            "############################################################\n",
            "Loss at train in  304  epoch\n",
            "0.006870924189594891\n",
            "Loss at test in  304  epoch\n",
            "0.31636445637574634\n",
            "Accuracy:  0.882\n",
            "############################################################\n",
            "Loss at train in  305  epoch\n",
            "0.007335361973973835\n",
            "Loss at test in  305  epoch\n",
            "0.3019811488129625\n",
            "Accuracy:  0.8933333333333333\n",
            "############################################################\n",
            "Loss at train in  306  epoch\n",
            "0.006482149821199016\n",
            "Loss at test in  306  epoch\n",
            "0.3098959952147793\n",
            "Accuracy:  0.8876666666666667\n",
            "############################################################\n",
            "Loss at train in  307  epoch\n",
            "0.007058861095451165\n",
            "Loss at test in  307  epoch\n",
            "0.312871286503101\n",
            "Accuracy:  0.8896666666666667\n",
            "############################################################\n",
            "Loss at train in  308  epoch\n",
            "0.006761991093822578\n",
            "Loss at test in  308  epoch\n",
            "0.32524185364907565\n",
            "Accuracy:  0.8823333333333333\n",
            "############################################################\n",
            "Loss at train in  309  epoch\n",
            "0.0071937518672586616\n",
            "Loss at test in  309  epoch\n",
            "0.3209471961541312\n",
            "Accuracy:  0.8896666666666667\n",
            "############################################################\n",
            "Loss at train in  310  epoch\n",
            "0.006593722439524385\n",
            "Loss at test in  310  epoch\n",
            "0.32345924107746443\n",
            "Accuracy:  0.8876666666666667\n",
            "############################################################\n",
            "Loss at train in  311  epoch\n",
            "0.0071099047326508074\n",
            "Loss at test in  311  epoch\n",
            "0.32110978538810137\n",
            "Accuracy:  0.8843333333333333\n",
            "############################################################\n",
            "Loss at train in  312  epoch\n",
            "0.0072091165820805615\n",
            "Loss at test in  312  epoch\n",
            "0.31462760868338124\n",
            "Accuracy:  0.8876666666666667\n",
            "############################################################\n",
            "Loss at train in  313  epoch\n",
            "0.007081097243278025\n",
            "Loss at test in  313  epoch\n",
            "0.31312430534826635\n",
            "Accuracy:  0.882\n",
            "############################################################\n",
            "Loss at train in  314  epoch\n",
            "0.00730536403046379\n",
            "Loss at test in  314  epoch\n",
            "0.3142333464273838\n",
            "Accuracy:  0.8833333333333333\n",
            "############################################################\n",
            "Loss at train in  315  epoch\n",
            "0.006459350921335289\n",
            "Loss at test in  315  epoch\n",
            "0.3594648272978353\n",
            "Accuracy:  0.8676666666666667\n",
            "############################################################\n",
            "Loss at train in  316  epoch\n",
            "0.0075999813161644805\n",
            "Loss at test in  316  epoch\n",
            "0.32328044202924516\n",
            "Accuracy:  0.8756666666666667\n",
            "############################################################\n",
            "Loss at train in  317  epoch\n",
            "0.008156183035825243\n",
            "Loss at test in  317  epoch\n",
            "0.3167405412171856\n",
            "Accuracy:  0.8846666666666667\n",
            "############################################################\n",
            "Loss at train in  318  epoch\n",
            "0.00767951652009103\n",
            "Loss at test in  318  epoch\n",
            "0.31506342865780074\n",
            "Accuracy:  0.8853333333333333\n",
            "############################################################\n",
            "Loss at train in  319  epoch\n",
            "0.006329621688224061\n",
            "Loss at test in  319  epoch\n",
            "0.36417347417403556\n",
            "Accuracy:  0.867\n",
            "############################################################\n",
            "Loss at train in  320  epoch\n",
            "0.0074690507994336795\n",
            "Loss at test in  320  epoch\n",
            "0.32024732465213634\n",
            "Accuracy:  0.8806666666666667\n",
            "############################################################\n",
            "Loss at train in  321  epoch\n",
            "0.006288274845936591\n",
            "Loss at test in  321  epoch\n",
            "0.3245482832424392\n",
            "Accuracy:  0.8893333333333333\n",
            "############################################################\n",
            "Loss at train in  322  epoch\n",
            "0.007202337315897923\n",
            "Loss at test in  322  epoch\n",
            "0.321766306698711\n",
            "Accuracy:  0.8786666666666667\n",
            "############################################################\n",
            "Loss at train in  323  epoch\n",
            "0.007755247126601618\n",
            "Loss at test in  323  epoch\n",
            "0.3207235953646075\n",
            "Accuracy:  0.885\n",
            "############################################################\n",
            "Loss at train in  324  epoch\n",
            "0.006768297970743269\n",
            "Loss at test in  324  epoch\n",
            "0.30846226467959603\n",
            "Accuracy:  0.8883333333333333\n",
            "############################################################\n",
            "Loss at train in  325  epoch\n",
            "0.006709957590514052\n",
            "Loss at test in  325  epoch\n",
            "0.31297061987807656\n",
            "Accuracy:  0.8886666666666667\n",
            "############################################################\n",
            "Loss at train in  326  epoch\n",
            "0.006677968341544074\n",
            "Loss at test in  326  epoch\n",
            "0.30060946009863826\n",
            "Accuracy:  0.8906666666666667\n",
            "############################################################\n",
            "Loss at train in  327  epoch\n",
            "0.007347513150847101\n",
            "Loss at test in  327  epoch\n",
            "0.3207868238930281\n",
            "Accuracy:  0.8736666666666667\n",
            "############################################################\n",
            "Loss at train in  328  epoch\n",
            "0.006757493488390125\n",
            "Loss at test in  328  epoch\n",
            "0.30684107680732203\n",
            "Accuracy:  0.89\n",
            "############################################################\n",
            "Loss at train in  329  epoch\n",
            "0.0071229919663902295\n",
            "Loss at test in  329  epoch\n",
            "0.31482682054823197\n",
            "Accuracy:  0.8916666666666667\n",
            "############################################################\n",
            "Loss at train in  330  epoch\n",
            "0.006745649727625373\n",
            "Loss at test in  330  epoch\n",
            "0.32542064456040265\n",
            "Accuracy:  0.884\n",
            "############################################################\n",
            "Loss at train in  331  epoch\n",
            "0.007030636537190799\n",
            "Loss at test in  331  epoch\n",
            "0.3096309533962963\n",
            "Accuracy:  0.885\n",
            "############################################################\n",
            "Loss at train in  332  epoch\n",
            "0.006741054775044969\n",
            "Loss at test in  332  epoch\n",
            "0.317105756454165\n",
            "Accuracy:  0.8843333333333333\n",
            "############################################################\n",
            "Loss at train in  333  epoch\n",
            "0.0069839065081621216\n",
            "Loss at test in  333  epoch\n",
            "0.3525313364163507\n",
            "Accuracy:  0.867\n",
            "############################################################\n",
            "Loss at train in  334  epoch\n",
            "0.006017593597319553\n",
            "Loss at test in  334  epoch\n",
            "0.3364066961592589\n",
            "Accuracy:  0.8783333333333333\n",
            "############################################################\n",
            "Loss at train in  335  epoch\n",
            "0.006917379382968187\n",
            "Loss at test in  335  epoch\n",
            "0.32504781214619677\n",
            "Accuracy:  0.8866666666666667\n",
            "############################################################\n",
            "Loss at train in  336  epoch\n",
            "0.0068768107764717095\n",
            "Loss at test in  336  epoch\n",
            "0.3094248380466581\n",
            "Accuracy:  0.8846666666666667\n",
            "############################################################\n",
            "Loss at train in  337  epoch\n",
            "0.007003342750699981\n",
            "Loss at test in  337  epoch\n",
            "0.3142623148631093\n",
            "Accuracy:  0.878\n",
            "############################################################\n",
            "Loss at train in  338  epoch\n",
            "0.00723150703785891\n",
            "Loss at test in  338  epoch\n",
            "0.3239578711407867\n",
            "Accuracy:  0.8773333333333333\n",
            "############################################################\n",
            "Loss at train in  339  epoch\n",
            "0.006661852819444188\n",
            "Loss at test in  339  epoch\n",
            "0.30731077198082746\n",
            "Accuracy:  0.8846666666666667\n",
            "############################################################\n",
            "Loss at train in  340  epoch\n",
            "0.007431402086185415\n",
            "Loss at test in  340  epoch\n",
            "0.3094621362059896\n",
            "Accuracy:  0.8916666666666667\n",
            "############################################################\n",
            "Loss at train in  341  epoch\n",
            "0.00702152831651066\n",
            "Loss at test in  341  epoch\n",
            "0.3254217307477552\n",
            "Accuracy:  0.883\n",
            "############################################################\n",
            "Loss at train in  342  epoch\n",
            "0.006512980605142488\n",
            "Loss at test in  342  epoch\n",
            "0.32057324237571905\n",
            "Accuracy:  0.89\n",
            "############################################################\n",
            "Loss at train in  343  epoch\n",
            "0.006743102732710438\n",
            "Loss at test in  343  epoch\n",
            "0.3091685625997242\n",
            "Accuracy:  0.8866666666666667\n",
            "############################################################\n",
            "Loss at train in  344  epoch\n",
            "0.007304494161006535\n",
            "Loss at test in  344  epoch\n",
            "0.3075643501388606\n",
            "Accuracy:  0.8866666666666667\n",
            "############################################################\n",
            "Loss at train in  345  epoch\n",
            "0.006361980547731864\n",
            "Loss at test in  345  epoch\n",
            "0.3134282840600745\n",
            "Accuracy:  0.8836666666666667\n",
            "############################################################\n",
            "Loss at train in  346  epoch\n",
            "0.0072797853527494846\n",
            "Loss at test in  346  epoch\n",
            "0.3122114083575079\n",
            "Accuracy:  0.887\n",
            "############################################################\n",
            "Loss at train in  347  epoch\n",
            "0.006932414538343378\n",
            "Loss at test in  347  epoch\n",
            "0.32290843227452964\n",
            "Accuracy:  0.883\n",
            "############################################################\n",
            "Loss at train in  348  epoch\n",
            "0.007049161159991784\n",
            "Loss at test in  348  epoch\n",
            "0.326221287765803\n",
            "Accuracy:  0.8826666666666667\n",
            "############################################################\n",
            "Loss at train in  349  epoch\n",
            "0.0073383330556307845\n",
            "Loss at test in  349  epoch\n",
            "0.3042738553379932\n",
            "Accuracy:  0.888\n",
            "############################################################\n",
            "Loss at train in  350  epoch\n",
            "0.006620584526724155\n",
            "Loss at test in  350  epoch\n",
            "0.29930125747308217\n",
            "Accuracy:  0.889\n",
            "############################################################\n",
            "Loss at train in  351  epoch\n",
            "0.006473694067795609\n",
            "Loss at test in  351  epoch\n",
            "0.31608094706933565\n",
            "Accuracy:  0.8923333333333333\n",
            "############################################################\n",
            "Loss at train in  352  epoch\n",
            "0.007053332473575526\n",
            "Loss at test in  352  epoch\n",
            "0.3253263544672393\n",
            "Accuracy:  0.8833333333333333\n",
            "############################################################\n",
            "Loss at train in  353  epoch\n",
            "0.006682715121408653\n",
            "Loss at test in  353  epoch\n",
            "0.30868301388974007\n",
            "Accuracy:  0.8866666666666667\n",
            "############################################################\n",
            "Loss at train in  354  epoch\n",
            "0.007174775039171694\n",
            "Loss at test in  354  epoch\n",
            "0.3114500424616131\n",
            "Accuracy:  0.8863333333333333\n",
            "############################################################\n",
            "Loss at train in  355  epoch\n",
            "0.006519226608873827\n",
            "Loss at test in  355  epoch\n",
            "0.3327639915743455\n",
            "Accuracy:  0.8933333333333333\n",
            "############################################################\n",
            "Loss at train in  356  epoch\n",
            "0.007234912142960077\n",
            "Loss at test in  356  epoch\n",
            "0.3601423982732032\n",
            "Accuracy:  0.8696666666666667\n",
            "############################################################\n",
            "Loss at train in  357  epoch\n",
            "0.0071887224893888105\n",
            "Loss at test in  357  epoch\n",
            "0.3297240264927851\n",
            "Accuracy:  0.884\n",
            "############################################################\n",
            "Loss at train in  358  epoch\n",
            "0.006085823393324791\n",
            "Loss at test in  358  epoch\n",
            "0.31020356093590856\n",
            "Accuracy:  0.8923333333333333\n",
            "############################################################\n",
            "Loss at train in  359  epoch\n",
            "0.007196620315327512\n",
            "Loss at test in  359  epoch\n",
            "0.3101975617955126\n",
            "Accuracy:  0.8856666666666667\n",
            "############################################################\n",
            "Loss at train in  360  epoch\n",
            "0.0072059066163631625\n",
            "Loss at test in  360  epoch\n",
            "0.3212742920812106\n",
            "Accuracy:  0.8866666666666667\n",
            "############################################################\n",
            "Loss at train in  361  epoch\n",
            "0.006991406200408545\n",
            "Loss at test in  361  epoch\n",
            "0.30892405635084547\n",
            "Accuracy:  0.8886666666666667\n",
            "############################################################\n",
            "Loss at train in  362  epoch\n",
            "0.006606791521097469\n",
            "Loss at test in  362  epoch\n",
            "0.3149573624839102\n",
            "Accuracy:  0.8846666666666667\n",
            "############################################################\n",
            "Loss at train in  363  epoch\n",
            "0.006474733057870248\n",
            "Loss at test in  363  epoch\n",
            "0.30934975578488044\n",
            "Accuracy:  0.8906666666666667\n",
            "############################################################\n",
            "Loss at train in  364  epoch\n",
            "0.006062312949525099\n",
            "Loss at test in  364  epoch\n",
            "0.31333921215457144\n",
            "Accuracy:  0.8886666666666667\n",
            "############################################################\n",
            "Loss at train in  365  epoch\n",
            "0.00721070345987665\n",
            "Loss at test in  365  epoch\n",
            "0.34547785011830984\n",
            "Accuracy:  0.8763333333333333\n",
            "############################################################\n",
            "Loss at train in  366  epoch\n",
            "0.0069157395665041905\n",
            "Loss at test in  366  epoch\n",
            "0.3128514742062613\n",
            "Accuracy:  0.8853333333333333\n",
            "############################################################\n",
            "Loss at train in  367  epoch\n",
            "0.006680096900765756\n",
            "Loss at test in  367  epoch\n",
            "0.3102104291403227\n",
            "Accuracy:  0.8903333333333333\n",
            "############################################################\n",
            "Loss at train in  368  epoch\n",
            "0.006780318667363107\n",
            "Loss at test in  368  epoch\n",
            "0.31378679903973183\n",
            "Accuracy:  0.8823333333333333\n",
            "############################################################\n",
            "Loss at train in  369  epoch\n",
            "0.007284556595480651\n",
            "Loss at test in  369  epoch\n",
            "0.3387939815209623\n",
            "Accuracy:  0.878\n",
            "############################################################\n",
            "Loss at train in  370  epoch\n",
            "0.006696675062816678\n",
            "Loss at test in  370  epoch\n",
            "0.3147861064873331\n",
            "Accuracy:  0.883\n",
            "############################################################\n",
            "Loss at train in  371  epoch\n",
            "0.006346893876200667\n",
            "Loss at test in  371  epoch\n",
            "0.3133010707992534\n",
            "Accuracy:  0.8893333333333333\n",
            "############################################################\n",
            "Loss at train in  372  epoch\n",
            "0.007047708578715212\n",
            "Loss at test in  372  epoch\n",
            "0.32062842686375637\n",
            "Accuracy:  0.8853333333333333\n",
            "############################################################\n",
            "Loss at train in  373  epoch\n",
            "0.0066117046087681075\n",
            "Loss at test in  373  epoch\n",
            "0.32479602369025007\n",
            "Accuracy:  0.8866666666666667\n",
            "############################################################\n",
            "Loss at train in  374  epoch\n",
            "0.0070094983811615046\n",
            "Loss at test in  374  epoch\n",
            "0.3041138709066892\n",
            "Accuracy:  0.8886666666666667\n",
            "############################################################\n",
            "Loss at train in  375  epoch\n",
            "0.005973634541583499\n",
            "Loss at test in  375  epoch\n",
            "0.3285061865884586\n",
            "Accuracy:  0.8783333333333333\n",
            "############################################################\n",
            "Loss at train in  376  epoch\n",
            "0.006776149435862256\n",
            "Loss at test in  376  epoch\n",
            "0.32108131437527493\n",
            "Accuracy:  0.886\n",
            "############################################################\n",
            "Loss at train in  377  epoch\n",
            "0.006931444120103105\n",
            "Loss at test in  377  epoch\n",
            "0.3069327136638188\n",
            "Accuracy:  0.891\n",
            "############################################################\n",
            "Loss at train in  378  epoch\n",
            "0.006749700223812172\n",
            "Loss at test in  378  epoch\n",
            "0.31581376995537774\n",
            "Accuracy:  0.8833333333333333\n",
            "############################################################\n",
            "Loss at train in  379  epoch\n",
            "0.006571729536857979\n",
            "Loss at test in  379  epoch\n",
            "0.3325945662034594\n",
            "Accuracy:  0.8833333333333333\n",
            "############################################################\n",
            "Loss at train in  380  epoch\n",
            "0.006534996225188833\n",
            "Loss at test in  380  epoch\n",
            "0.3171332421142956\n",
            "Accuracy:  0.8866666666666667\n",
            "############################################################\n",
            "Loss at train in  381  epoch\n",
            "0.007482907270830504\n",
            "Loss at test in  381  epoch\n",
            "0.315604822387707\n",
            "Accuracy:  0.884\n",
            "############################################################\n",
            "Loss at train in  382  epoch\n",
            "0.006802409397663933\n",
            "Loss at test in  382  epoch\n",
            "0.31306332202069553\n",
            "Accuracy:  0.8816666666666667\n",
            "############################################################\n",
            "Loss at train in  383  epoch\n",
            "0.00633983420630668\n",
            "Loss at test in  383  epoch\n",
            "0.31994099224367833\n",
            "Accuracy:  0.8886666666666667\n",
            "############################################################\n",
            "Loss at train in  384  epoch\n",
            "0.007252439320112022\n",
            "Loss at test in  384  epoch\n",
            "0.3196271534706318\n",
            "Accuracy:  0.886\n",
            "############################################################\n",
            "Loss at train in  385  epoch\n",
            "0.0065713498998572996\n",
            "Loss at test in  385  epoch\n",
            "0.3110740298206394\n",
            "Accuracy:  0.8863333333333333\n",
            "############################################################\n",
            "Loss at train in  386  epoch\n",
            "0.006726829957858995\n",
            "Loss at test in  386  epoch\n",
            "0.3157420203184923\n",
            "Accuracy:  0.891\n",
            "############################################################\n",
            "Loss at train in  387  epoch\n",
            "0.007541212500307039\n",
            "Loss at test in  387  epoch\n",
            "0.30330450047321844\n",
            "Accuracy:  0.8903333333333333\n",
            "############################################################\n",
            "Loss at train in  388  epoch\n",
            "0.00668496596027546\n",
            "Loss at test in  388  epoch\n",
            "0.3092464269949328\n",
            "Accuracy:  0.893\n",
            "############################################################\n",
            "Loss at train in  389  epoch\n",
            "0.006319714268558413\n",
            "Loss at test in  389  epoch\n",
            "0.33625632341873424\n",
            "Accuracy:  0.879\n",
            "############################################################\n",
            "Loss at train in  390  epoch\n",
            "0.006915005167462956\n",
            "Loss at test in  390  epoch\n",
            "0.31838214720916425\n",
            "Accuracy:  0.8896666666666667\n",
            "############################################################\n",
            "Loss at train in  391  epoch\n",
            "0.006410638558416049\n",
            "Loss at test in  391  epoch\n",
            "0.3265142747598693\n",
            "Accuracy:  0.8846666666666667\n",
            "############################################################\n",
            "Loss at train in  392  epoch\n",
            "0.006940740621489349\n",
            "Loss at test in  392  epoch\n",
            "0.3329393155279568\n",
            "Accuracy:  0.883\n",
            "############################################################\n",
            "Loss at train in  393  epoch\n",
            "0.00666319097469523\n",
            "Loss at test in  393  epoch\n",
            "0.3028227326327757\n",
            "Accuracy:  0.8856666666666667\n",
            "############################################################\n",
            "Loss at train in  394  epoch\n",
            "0.006525471340014662\n",
            "Loss at test in  394  epoch\n",
            "0.2989824888472474\n",
            "Accuracy:  0.893\n",
            "############################################################\n",
            "Loss at train in  395  epoch\n",
            "0.007347714249718525\n",
            "Loss at test in  395  epoch\n",
            "0.3045456907185052\n",
            "Accuracy:  0.8926666666666667\n",
            "############################################################\n",
            "Loss at train in  396  epoch\n",
            "0.00660518595349986\n",
            "Loss at test in  396  epoch\n",
            "0.3193492107602957\n",
            "Accuracy:  0.8806666666666667\n",
            "############################################################\n",
            "Loss at train in  397  epoch\n",
            "0.006478011894987983\n",
            "Loss at test in  397  epoch\n",
            "0.3280141617603605\n",
            "Accuracy:  0.877\n",
            "############################################################\n",
            "Loss at train in  398  epoch\n",
            "0.006581608363833887\n",
            "Loss at test in  398  epoch\n",
            "0.35643155331726956\n",
            "Accuracy:  0.8843333333333333\n",
            "############################################################\n",
            "Loss at train in  399  epoch\n",
            "0.006472909571904224\n",
            "Loss at test in  399  epoch\n",
            "0.3096927663635485\n",
            "Accuracy:  0.888\n",
            "############################################################\n",
            "Loss at train in  400  epoch\n",
            "0.006725440302295881\n",
            "Loss at test in  400  epoch\n",
            "0.3186552469906032\n",
            "Accuracy:  0.8823333333333333\n",
            "############################################################\n",
            "Loss at train in  401  epoch\n",
            "0.006755595649372284\n",
            "Loss at test in  401  epoch\n",
            "0.31532150340416987\n",
            "Accuracy:  0.8903333333333333\n",
            "############################################################\n",
            "Loss at train in  402  epoch\n",
            "0.00646167853938688\n",
            "Loss at test in  402  epoch\n",
            "0.3228454477077633\n",
            "Accuracy:  0.8806666666666667\n",
            "############################################################\n",
            "Loss at train in  403  epoch\n",
            "0.006394065177547935\n",
            "Loss at test in  403  epoch\n",
            "0.32787649977556155\n",
            "Accuracy:  0.8843333333333333\n",
            "############################################################\n",
            "Loss at train in  404  epoch\n",
            "0.006577733231788798\n",
            "Loss at test in  404  epoch\n",
            "0.30943610089425755\n",
            "Accuracy:  0.8903333333333333\n",
            "############################################################\n",
            "Loss at train in  405  epoch\n",
            "0.005998290851757161\n",
            "Loss at test in  405  epoch\n",
            "0.29820565131262444\n",
            "Accuracy:  0.8893333333333333\n",
            "############################################################\n",
            "Loss at train in  406  epoch\n",
            "0.006233953586673251\n",
            "Loss at test in  406  epoch\n",
            "0.3352109225612671\n",
            "Accuracy:  0.8816666666666667\n",
            "############################################################\n",
            "Loss at train in  407  epoch\n",
            "0.007155061929993882\n",
            "Loss at test in  407  epoch\n",
            "0.32311733883918475\n",
            "Accuracy:  0.8896666666666667\n",
            "############################################################\n",
            "Loss at train in  408  epoch\n",
            "0.006664898018173016\n",
            "Loss at test in  408  epoch\n",
            "0.31458142712428205\n",
            "Accuracy:  0.8846666666666667\n",
            "############################################################\n",
            "Loss at train in  409  epoch\n",
            "0.006777738088578176\n",
            "Loss at test in  409  epoch\n",
            "0.3172762213785962\n",
            "Accuracy:  0.8903333333333333\n",
            "############################################################\n",
            "Loss at train in  410  epoch\n",
            "0.007269444412946233\n",
            "Loss at test in  410  epoch\n",
            "0.3097818077655067\n",
            "Accuracy:  0.8926666666666667\n",
            "############################################################\n",
            "Loss at train in  411  epoch\n",
            "0.0070148894997459285\n",
            "Loss at test in  411  epoch\n",
            "0.3177264840096648\n",
            "Accuracy:  0.8863333333333333\n",
            "############################################################\n",
            "Loss at train in  412  epoch\n",
            "0.00626911995760503\n",
            "Loss at test in  412  epoch\n",
            "0.30855058036477406\n",
            "Accuracy:  0.8893333333333333\n",
            "############################################################\n",
            "Loss at train in  413  epoch\n",
            "0.006067042675493062\n",
            "Loss at test in  413  epoch\n",
            "0.31573030780599126\n",
            "Accuracy:  0.8873333333333333\n",
            "############################################################\n",
            "Loss at train in  414  epoch\n",
            "0.007039002550252452\n",
            "Loss at test in  414  epoch\n",
            "0.30638644852731395\n",
            "Accuracy:  0.892\n",
            "############################################################\n",
            "Loss at train in  415  epoch\n",
            "0.007095012257497977\n",
            "Loss at test in  415  epoch\n",
            "0.30163935014987936\n",
            "Accuracy:  0.89\n",
            "############################################################\n",
            "Loss at train in  416  epoch\n",
            "0.006735322141818242\n",
            "Loss at test in  416  epoch\n",
            "0.3053261783398148\n",
            "Accuracy:  0.8946666666666667\n",
            "############################################################\n",
            "Loss at train in  417  epoch\n",
            "0.006841892765219155\n",
            "Loss at test in  417  epoch\n",
            "0.30467114313154875\n",
            "Accuracy:  0.8903333333333333\n",
            "############################################################\n",
            "Loss at train in  418  epoch\n",
            "0.006476208208514526\n",
            "Loss at test in  418  epoch\n",
            "0.3018331211379583\n",
            "Accuracy:  0.8946666666666667\n",
            "############################################################\n",
            "Loss at train in  419  epoch\n",
            "0.006933790321662389\n",
            "Loss at test in  419  epoch\n",
            "0.3181417004650906\n",
            "Accuracy:  0.8876666666666667\n",
            "############################################################\n",
            "Loss at train in  420  epoch\n",
            "0.006608297166437916\n",
            "Loss at test in  420  epoch\n",
            "0.31347407702395624\n",
            "Accuracy:  0.8896666666666667\n",
            "############################################################\n",
            "Loss at train in  421  epoch\n",
            "0.006365904523362664\n",
            "Loss at test in  421  epoch\n",
            "0.3124566690884597\n",
            "Accuracy:  0.8906666666666667\n",
            "############################################################\n",
            "Loss at train in  422  epoch\n",
            "0.00658648093265058\n",
            "Loss at test in  422  epoch\n",
            "0.3225359629567235\n",
            "Accuracy:  0.8923333333333333\n",
            "############################################################\n",
            "Loss at train in  423  epoch\n",
            "0.006187390097835666\n",
            "Loss at test in  423  epoch\n",
            "0.34198085988963356\n",
            "Accuracy:  0.8683333333333333\n",
            "############################################################\n",
            "Loss at train in  424  epoch\n",
            "0.0064897668355471776\n",
            "Loss at test in  424  epoch\n",
            "0.3057202638129475\n",
            "Accuracy:  0.8966666666666666\n",
            "############################################################\n",
            "Loss at train in  425  epoch\n",
            "0.005827732495170457\n",
            "Loss at test in  425  epoch\n",
            "0.31516704243725835\n",
            "Accuracy:  0.88\n",
            "############################################################\n",
            "Loss at train in  426  epoch\n",
            "0.00654573381145385\n",
            "Loss at test in  426  epoch\n",
            "0.31406318196914956\n",
            "Accuracy:  0.8826666666666667\n",
            "############################################################\n",
            "Loss at train in  427  epoch\n",
            "0.006794964812993307\n",
            "Loss at test in  427  epoch\n",
            "0.3176431607002008\n",
            "Accuracy:  0.892\n",
            "############################################################\n",
            "Loss at train in  428  epoch\n",
            "0.006032105216503217\n",
            "Loss at test in  428  epoch\n",
            "0.3161917532371145\n",
            "Accuracy:  0.8856666666666667\n",
            "############################################################\n",
            "Loss at train in  429  epoch\n",
            "0.006691685249313991\n",
            "Loss at test in  429  epoch\n",
            "0.33226829686499526\n",
            "Accuracy:  0.8766666666666667\n",
            "############################################################\n",
            "Loss at train in  430  epoch\n",
            "0.006352665519491388\n",
            "Loss at test in  430  epoch\n",
            "0.32372253955654035\n",
            "Accuracy:  0.8903333333333333\n",
            "############################################################\n",
            "Loss at train in  431  epoch\n",
            "0.006380400378657245\n",
            "Loss at test in  431  epoch\n",
            "0.33063677663808044\n",
            "Accuracy:  0.8866666666666667\n",
            "############################################################\n",
            "Loss at train in  432  epoch\n",
            "0.007143528066032204\n",
            "Loss at test in  432  epoch\n",
            "0.31959087533609626\n",
            "Accuracy:  0.8813333333333333\n",
            "############################################################\n",
            "Loss at train in  433  epoch\n",
            "0.00636433081279054\n",
            "Loss at test in  433  epoch\n",
            "0.3299841536687509\n",
            "Accuracy:  0.8876666666666667\n",
            "############################################################\n",
            "Loss at train in  434  epoch\n",
            "0.007009211561498168\n",
            "Loss at test in  434  epoch\n",
            "0.32770428966197\n",
            "Accuracy:  0.8813333333333333\n",
            "############################################################\n",
            "Loss at train in  435  epoch\n",
            "0.006370748597426802\n",
            "Loss at test in  435  epoch\n",
            "0.3174452353760639\n",
            "Accuracy:  0.887\n",
            "############################################################\n",
            "Loss at train in  436  epoch\n",
            "0.006562302432231415\n",
            "Loss at test in  436  epoch\n",
            "0.3150847918900855\n",
            "Accuracy:  0.879\n",
            "############################################################\n",
            "Loss at train in  437  epoch\n",
            "0.0071745831115883904\n",
            "Loss at test in  437  epoch\n",
            "0.312265926364854\n",
            "Accuracy:  0.8866666666666667\n",
            "############################################################\n",
            "Loss at train in  438  epoch\n",
            "0.006127929235546204\n",
            "Loss at test in  438  epoch\n",
            "0.30259142869367944\n",
            "Accuracy:  0.8896666666666667\n",
            "############################################################\n",
            "Loss at train in  439  epoch\n",
            "0.006773743181224668\n",
            "Loss at test in  439  epoch\n",
            "0.31167388490317965\n",
            "Accuracy:  0.8833333333333333\n",
            "############################################################\n",
            "Loss at train in  440  epoch\n",
            "0.0063094673180735215\n",
            "Loss at test in  440  epoch\n",
            "0.3303396368894101\n",
            "Accuracy:  0.8833333333333333\n",
            "############################################################\n",
            "Loss at train in  441  epoch\n",
            "0.0070712714386493465\n",
            "Loss at test in  441  epoch\n",
            "0.3052050698089042\n",
            "Accuracy:  0.8926666666666667\n",
            "############################################################\n",
            "Loss at train in  442  epoch\n",
            "0.006552780193685811\n",
            "Loss at test in  442  epoch\n",
            "0.3227633890728359\n",
            "Accuracy:  0.8883333333333333\n",
            "############################################################\n",
            "Loss at train in  443  epoch\n",
            "0.00592854423515921\n",
            "Loss at test in  443  epoch\n",
            "0.32432562229460243\n",
            "Accuracy:  0.8806666666666667\n",
            "############################################################\n",
            "Loss at train in  444  epoch\n",
            "0.006620921197571677\n",
            "Loss at test in  444  epoch\n",
            "0.31352030930143127\n",
            "Accuracy:  0.885\n",
            "############################################################\n",
            "Loss at train in  445  epoch\n",
            "0.005406467809995927\n",
            "Loss at test in  445  epoch\n",
            "0.3219762862724123\n",
            "Accuracy:  0.886\n",
            "############################################################\n",
            "Loss at train in  446  epoch\n",
            "0.006715017550865677\n",
            "Loss at test in  446  epoch\n",
            "0.3189317063006534\n",
            "Accuracy:  0.8876666666666667\n",
            "############################################################\n",
            "Loss at train in  447  epoch\n",
            "0.006236431487606573\n",
            "Loss at test in  447  epoch\n",
            "0.30430536577958056\n",
            "Accuracy:  0.8913333333333333\n",
            "############################################################\n",
            "Loss at train in  448  epoch\n",
            "0.007189278805893427\n",
            "Loss at test in  448  epoch\n",
            "0.3121213596408522\n",
            "Accuracy:  0.8846666666666667\n",
            "############################################################\n",
            "Loss at train in  449  epoch\n",
            "0.006197502660428289\n",
            "Loss at test in  449  epoch\n",
            "0.32244528484573115\n",
            "Accuracy:  0.881\n",
            "############################################################\n",
            "Loss at train in  450  epoch\n",
            "0.00612905650026186\n",
            "Loss at test in  450  epoch\n",
            "0.32871421302591286\n",
            "Accuracy:  0.8856666666666667\n",
            "############################################################\n",
            "Loss at train in  451  epoch\n",
            "0.005655335515234868\n",
            "Loss at test in  451  epoch\n",
            "0.34209421132354745\n",
            "Accuracy:  0.8796666666666667\n",
            "############################################################\n",
            "Loss at train in  452  epoch\n",
            "0.0060809884946294536\n",
            "Loss at test in  452  epoch\n",
            "0.31616706467184125\n",
            "Accuracy:  0.8873333333333333\n",
            "############################################################\n",
            "Loss at train in  453  epoch\n",
            "0.00613263691931153\n",
            "Loss at test in  453  epoch\n",
            "0.3207219315967105\n",
            "Accuracy:  0.8816666666666667\n",
            "############################################################\n",
            "Loss at train in  454  epoch\n",
            "0.006455568781141112\n",
            "Loss at test in  454  epoch\n",
            "0.31695531548627165\n",
            "Accuracy:  0.8903333333333333\n",
            "############################################################\n",
            "Loss at train in  455  epoch\n",
            "0.006583251295844821\n",
            "Loss at test in  455  epoch\n",
            "0.33188071968531346\n",
            "Accuracy:  0.8816666666666667\n",
            "############################################################\n",
            "Loss at train in  456  epoch\n",
            "0.006505907891850537\n",
            "Loss at test in  456  epoch\n",
            "0.3083728013416859\n",
            "Accuracy:  0.8876666666666667\n",
            "############################################################\n",
            "Loss at train in  457  epoch\n",
            "0.006748571733784692\n",
            "Loss at test in  457  epoch\n",
            "0.3185756968142452\n",
            "Accuracy:  0.883\n",
            "############################################################\n",
            "Loss at train in  458  epoch\n",
            "0.006134988041406279\n",
            "Loss at test in  458  epoch\n",
            "0.30803745056442855\n",
            "Accuracy:  0.8893333333333333\n",
            "############################################################\n",
            "Loss at train in  459  epoch\n",
            "0.005830747837046724\n",
            "Loss at test in  459  epoch\n",
            "0.3687766742453816\n",
            "Accuracy:  0.865\n",
            "############################################################\n",
            "Loss at train in  460  epoch\n",
            "0.006391425131177637\n",
            "Loss at test in  460  epoch\n",
            "0.3259895450979853\n",
            "Accuracy:  0.8836666666666667\n",
            "############################################################\n",
            "Loss at train in  461  epoch\n",
            "0.006027331198894509\n",
            "Loss at test in  461  epoch\n",
            "0.3146409466781946\n",
            "Accuracy:  0.8853333333333333\n",
            "############################################################\n",
            "Loss at train in  462  epoch\n",
            "0.0063545119049889486\n",
            "Loss at test in  462  epoch\n",
            "0.2964188916344471\n",
            "Accuracy:  0.894\n",
            "############################################################\n",
            "Loss at train in  463  epoch\n",
            "0.0068094036709087135\n",
            "Loss at test in  463  epoch\n",
            "0.30497621975002703\n",
            "Accuracy:  0.8953333333333333\n",
            "############################################################\n",
            "Loss at train in  464  epoch\n",
            "0.005653890449078228\n",
            "Loss at test in  464  epoch\n",
            "0.2981800290754415\n",
            "Accuracy:  0.892\n",
            "############################################################\n",
            "Loss at train in  465  epoch\n",
            "0.006601581756453322\n",
            "Loss at test in  465  epoch\n",
            "0.299659152213034\n",
            "Accuracy:  0.8926666666666667\n",
            "############################################################\n",
            "Loss at train in  466  epoch\n",
            "0.006292654871205741\n",
            "Loss at test in  466  epoch\n",
            "0.31353673810365185\n",
            "Accuracy:  0.887\n",
            "############################################################\n",
            "Loss at train in  467  epoch\n",
            "0.005488273009061558\n",
            "Loss at test in  467  epoch\n",
            "0.30400145117152766\n",
            "Accuracy:  0.8866666666666667\n",
            "############################################################\n",
            "Loss at train in  468  epoch\n",
            "0.006691907104375643\n",
            "Loss at test in  468  epoch\n",
            "0.31822045919101294\n",
            "Accuracy:  0.8883333333333333\n",
            "############################################################\n",
            "Loss at train in  469  epoch\n",
            "0.006918143561990753\n",
            "Loss at test in  469  epoch\n",
            "0.31095704884063313\n",
            "Accuracy:  0.8836666666666667\n",
            "############################################################\n",
            "Loss at train in  470  epoch\n",
            "0.006074368335837455\n",
            "Loss at test in  470  epoch\n",
            "0.3168770485434809\n",
            "Accuracy:  0.8883333333333333\n",
            "############################################################\n",
            "Loss at train in  471  epoch\n",
            "0.005899258847703763\n",
            "Loss at test in  471  epoch\n",
            "0.31041619937294995\n",
            "Accuracy:  0.8896666666666667\n",
            "############################################################\n",
            "Loss at train in  472  epoch\n",
            "0.005763748677411627\n",
            "Loss at test in  472  epoch\n",
            "0.3232569616542852\n",
            "Accuracy:  0.889\n",
            "############################################################\n",
            "Loss at train in  473  epoch\n",
            "0.007504880339563918\n",
            "Loss at test in  473  epoch\n",
            "0.3037344685611134\n",
            "Accuracy:  0.889\n",
            "############################################################\n",
            "Loss at train in  474  epoch\n",
            "0.006374222286161568\n",
            "Loss at test in  474  epoch\n",
            "0.32821970146190177\n",
            "Accuracy:  0.8806666666666667\n",
            "############################################################\n",
            "Loss at train in  475  epoch\n",
            "0.006254169519697232\n",
            "Loss at test in  475  epoch\n",
            "0.3140057259053112\n",
            "Accuracy:  0.891\n",
            "############################################################\n",
            "Loss at train in  476  epoch\n",
            "0.006076211192861996\n",
            "Loss at test in  476  epoch\n",
            "0.29915889918246563\n",
            "Accuracy:  0.894\n",
            "############################################################\n",
            "Loss at train in  477  epoch\n",
            "0.006308993458154504\n",
            "Loss at test in  477  epoch\n",
            "0.3004048634348758\n",
            "Accuracy:  0.885\n",
            "############################################################\n",
            "Loss at train in  478  epoch\n",
            "0.00586339294583676\n",
            "Loss at test in  478  epoch\n",
            "0.3125114730956116\n",
            "Accuracy:  0.888\n",
            "############################################################\n",
            "Loss at train in  479  epoch\n",
            "0.005289222556279368\n",
            "Loss at test in  479  epoch\n",
            "0.30122086742388504\n",
            "Accuracy:  0.8976666666666666\n",
            "############################################################\n",
            "Loss at train in  480  epoch\n",
            "0.006494785778430862\n",
            "Loss at test in  480  epoch\n",
            "0.3214219217414219\n",
            "Accuracy:  0.8856666666666667\n",
            "############################################################\n",
            "Loss at train in  481  epoch\n",
            "0.006746132481339986\n",
            "Loss at test in  481  epoch\n",
            "0.30588285015541555\n",
            "Accuracy:  0.8956666666666667\n",
            "############################################################\n",
            "Loss at train in  482  epoch\n",
            "0.005076873806626023\n",
            "Loss at test in  482  epoch\n",
            "0.3140692753755971\n",
            "Accuracy:  0.8936666666666667\n",
            "############################################################\n",
            "Loss at train in  483  epoch\n",
            "0.005911234482632069\n",
            "Loss at test in  483  epoch\n",
            "0.31202807745237854\n",
            "Accuracy:  0.8873333333333333\n",
            "############################################################\n",
            "Loss at train in  484  epoch\n",
            "0.006298495969262826\n",
            "Loss at test in  484  epoch\n",
            "0.3060230450292405\n",
            "Accuracy:  0.8976666666666666\n",
            "############################################################\n",
            "Loss at train in  485  epoch\n",
            "0.006326236353058678\n",
            "Loss at test in  485  epoch\n",
            "0.3197937055301499\n",
            "Accuracy:  0.888\n",
            "############################################################\n",
            "Loss at train in  486  epoch\n",
            "0.006080004886752339\n",
            "Loss at test in  486  epoch\n",
            "0.3110113896578439\n",
            "Accuracy:  0.8906666666666667\n",
            "############################################################\n",
            "Loss at train in  487  epoch\n",
            "0.0061339327113184945\n",
            "Loss at test in  487  epoch\n",
            "0.30437806235714093\n",
            "Accuracy:  0.8953333333333333\n",
            "############################################################\n",
            "Loss at train in  488  epoch\n",
            "0.006059137561714458\n",
            "Loss at test in  488  epoch\n",
            "0.3097345294111965\n",
            "Accuracy:  0.888\n",
            "############################################################\n",
            "Loss at train in  489  epoch\n",
            "0.0060822593724535225\n",
            "Loss at test in  489  epoch\n",
            "0.31216594685544163\n",
            "Accuracy:  0.8853333333333333\n",
            "############################################################\n",
            "Loss at train in  490  epoch\n",
            "0.006397230685897176\n",
            "Loss at test in  490  epoch\n",
            "0.30902606029083385\n",
            "Accuracy:  0.885\n",
            "############################################################\n",
            "Loss at train in  491  epoch\n",
            "0.00634438162799724\n",
            "Loss at test in  491  epoch\n",
            "0.3122709508694728\n",
            "Accuracy:  0.8823333333333333\n",
            "############################################################\n",
            "Loss at train in  492  epoch\n",
            "0.006145845969894707\n",
            "Loss at test in  492  epoch\n",
            "0.3120509191358144\n",
            "Accuracy:  0.885\n",
            "############################################################\n",
            "Loss at train in  493  epoch\n",
            "0.006087517177565963\n",
            "Loss at test in  493  epoch\n",
            "0.30346959847285987\n",
            "Accuracy:  0.8913333333333333\n",
            "############################################################\n",
            "Loss at train in  494  epoch\n",
            "0.006181596386040561\n",
            "Loss at test in  494  epoch\n",
            "0.29870137550328524\n",
            "Accuracy:  0.893\n",
            "############################################################\n",
            "Loss at train in  495  epoch\n",
            "0.006627925680049898\n",
            "Loss at test in  495  epoch\n",
            "0.31076246753271586\n",
            "Accuracy:  0.8833333333333333\n",
            "############################################################\n",
            "Loss at train in  496  epoch\n",
            "0.0059235529919629834\n",
            "Loss at test in  496  epoch\n",
            "0.31676553697558063\n",
            "Accuracy:  0.8833333333333333\n",
            "############################################################\n",
            "Loss at train in  497  epoch\n",
            "0.0062026326966061335\n",
            "Loss at test in  497  epoch\n",
            "0.3373470317552781\n",
            "Accuracy:  0.882\n",
            "############################################################\n",
            "Loss at train in  498  epoch\n",
            "0.005514283764588776\n",
            "Loss at test in  498  epoch\n",
            "0.3154920353818552\n",
            "Accuracy:  0.8866666666666667\n",
            "############################################################\n",
            "Loss at train in  499  epoch\n",
            "0.00618527025896701\n",
            "Loss at test in  499  epoch\n",
            "0.3378465626971603\n",
            "Accuracy:  0.8796666666666667\n",
            "############################################################\n",
            "Loss at train in  500  epoch\n",
            "0.005905154588053037\n",
            "Loss at test in  500  epoch\n",
            "0.3118929662838017\n",
            "Accuracy:  0.8896666666666667\n",
            "############################################################\n",
            "Loss at train in  501  epoch\n",
            "0.006265098011746451\n",
            "Loss at test in  501  epoch\n",
            "0.3170491061441876\n",
            "Accuracy:  0.8863333333333333\n",
            "############################################################\n",
            "Loss at train in  502  epoch\n",
            "0.006026569476767051\n",
            "Loss at test in  502  epoch\n",
            "0.3072326218751643\n",
            "Accuracy:  0.893\n",
            "############################################################\n",
            "Loss at train in  503  epoch\n",
            "0.006947058774977623\n",
            "Loss at test in  503  epoch\n",
            "0.31349578069662154\n",
            "Accuracy:  0.891\n",
            "############################################################\n",
            "Loss at train in  504  epoch\n",
            "0.006280271880821643\n",
            "Loss at test in  504  epoch\n",
            "0.3277743915969496\n",
            "Accuracy:  0.8783333333333333\n",
            "############################################################\n",
            "Loss at train in  505  epoch\n",
            "0.006179463745033253\n",
            "Loss at test in  505  epoch\n",
            "0.32139427305302637\n",
            "Accuracy:  0.8866666666666667\n",
            "############################################################\n",
            "Loss at train in  506  epoch\n",
            "0.006097883721063822\n",
            "Loss at test in  506  epoch\n",
            "0.3221195177456636\n",
            "Accuracy:  0.8903333333333333\n",
            "############################################################\n",
            "Loss at train in  507  epoch\n",
            "0.006436540830070347\n",
            "Loss at test in  507  epoch\n",
            "0.31120915817818573\n",
            "Accuracy:  0.8903333333333333\n",
            "############################################################\n",
            "Loss at train in  508  epoch\n",
            "0.006454603418891843\n",
            "Loss at test in  508  epoch\n",
            "0.3142590775158824\n",
            "Accuracy:  0.8866666666666667\n",
            "############################################################\n",
            "Loss at train in  509  epoch\n",
            "0.006053448821222085\n",
            "Loss at test in  509  epoch\n",
            "0.3008432948282137\n",
            "Accuracy:  0.8893333333333333\n",
            "############################################################\n",
            "Loss at train in  510  epoch\n",
            "0.006054977500349838\n",
            "Loss at test in  510  epoch\n",
            "0.31047862511776975\n",
            "Accuracy:  0.8886666666666667\n",
            "############################################################\n",
            "Loss at train in  511  epoch\n",
            "0.005824467944178238\n",
            "Loss at test in  511  epoch\n",
            "0.32717755946729854\n",
            "Accuracy:  0.8903333333333333\n",
            "############################################################\n",
            "Loss at train in  512  epoch\n",
            "0.005449180187937999\n",
            "Loss at test in  512  epoch\n",
            "0.3192298596694312\n",
            "Accuracy:  0.8903333333333333\n",
            "############################################################\n",
            "Loss at train in  513  epoch\n",
            "0.00634369456450659\n",
            "Loss at test in  513  epoch\n",
            "0.30934550047014403\n",
            "Accuracy:  0.8886666666666667\n",
            "############################################################\n",
            "Loss at train in  514  epoch\n",
            "0.005166233181044111\n",
            "Loss at test in  514  epoch\n",
            "0.3095860011849856\n",
            "Accuracy:  0.891\n",
            "############################################################\n",
            "Loss at train in  515  epoch\n",
            "0.0063599800612844\n",
            "Loss at test in  515  epoch\n",
            "0.3207683720803939\n",
            "Accuracy:  0.8836666666666667\n",
            "############################################################\n",
            "Loss at train in  516  epoch\n",
            "0.006057293849361019\n",
            "Loss at test in  516  epoch\n",
            "0.29677629528363125\n",
            "Accuracy:  0.89\n",
            "############################################################\n",
            "Loss at train in  517  epoch\n",
            "0.00631980084053941\n",
            "Loss at test in  517  epoch\n",
            "0.3226609338613545\n",
            "Accuracy:  0.8783333333333333\n",
            "############################################################\n",
            "Loss at train in  518  epoch\n",
            "0.006758377395227975\n",
            "Loss at test in  518  epoch\n",
            "0.3123265163151887\n",
            "Accuracy:  0.8873333333333333\n",
            "############################################################\n",
            "Loss at train in  519  epoch\n",
            "0.006095851696130775\n",
            "Loss at test in  519  epoch\n",
            "0.3142019562701854\n",
            "Accuracy:  0.8863333333333333\n",
            "############################################################\n",
            "Loss at train in  520  epoch\n",
            "0.006056336525125705\n",
            "Loss at test in  520  epoch\n",
            "0.33292048421930737\n",
            "Accuracy:  0.8863333333333333\n",
            "############################################################\n",
            "Loss at train in  521  epoch\n",
            "0.0056657991724190174\n",
            "Loss at test in  521  epoch\n",
            "0.3150127334857539\n",
            "Accuracy:  0.8863333333333333\n",
            "############################################################\n",
            "Loss at train in  522  epoch\n",
            "0.006619604935895129\n",
            "Loss at test in  522  epoch\n",
            "0.32560595262944547\n",
            "Accuracy:  0.8766666666666667\n",
            "############################################################\n",
            "Loss at train in  523  epoch\n",
            "0.0064760690733514795\n",
            "Loss at test in  523  epoch\n",
            "0.3061542323752716\n",
            "Accuracy:  0.8943333333333333\n",
            "############################################################\n",
            "Loss at train in  524  epoch\n",
            "0.005845117745521271\n",
            "Loss at test in  524  epoch\n",
            "0.3168563520344971\n",
            "Accuracy:  0.8933333333333333\n",
            "############################################################\n",
            "Loss at train in  525  epoch\n",
            "0.00616344513015421\n",
            "Loss at test in  525  epoch\n",
            "0.3209469179727465\n",
            "Accuracy:  0.8833333333333333\n",
            "############################################################\n",
            "Loss at train in  526  epoch\n",
            "0.006182584186286891\n",
            "Loss at test in  526  epoch\n",
            "0.3158540668360177\n",
            "Accuracy:  0.8886666666666667\n",
            "############################################################\n",
            "Loss at train in  527  epoch\n",
            "0.005400035499000617\n",
            "Loss at test in  527  epoch\n",
            "0.3136654333183305\n",
            "Accuracy:  0.8926666666666667\n",
            "############################################################\n",
            "Loss at train in  528  epoch\n",
            "0.005515675888896796\n",
            "Loss at test in  528  epoch\n",
            "0.31130860471830574\n",
            "Accuracy:  0.8896666666666667\n",
            "############################################################\n",
            "Loss at train in  529  epoch\n",
            "0.006055243058552201\n",
            "Loss at test in  529  epoch\n",
            "0.3211525663866196\n",
            "Accuracy:  0.89\n",
            "############################################################\n",
            "Loss at train in  530  epoch\n",
            "0.005580531131613153\n",
            "Loss at test in  530  epoch\n",
            "0.3315735595375709\n",
            "Accuracy:  0.884\n",
            "############################################################\n",
            "Loss at train in  531  epoch\n",
            "0.006187756466386965\n",
            "Loss at test in  531  epoch\n",
            "0.33079029281634115\n",
            "Accuracy:  0.886\n",
            "############################################################\n",
            "Loss at train in  532  epoch\n",
            "0.0058990748829688055\n",
            "Loss at test in  532  epoch\n",
            "0.3255777047730421\n",
            "Accuracy:  0.8856666666666667\n",
            "############################################################\n",
            "Loss at train in  533  epoch\n",
            "0.005609473964150424\n",
            "Loss at test in  533  epoch\n",
            "0.31899738674853606\n",
            "Accuracy:  0.8866666666666667\n",
            "############################################################\n",
            "Loss at train in  534  epoch\n",
            "0.006355192367827434\n",
            "Loss at test in  534  epoch\n",
            "0.3164161443944077\n",
            "Accuracy:  0.8963333333333333\n",
            "############################################################\n",
            "Loss at train in  535  epoch\n",
            "0.005267232313815398\n",
            "Loss at test in  535  epoch\n",
            "0.34046358621743894\n",
            "Accuracy:  0.8853333333333333\n",
            "############################################################\n",
            "Loss at train in  536  epoch\n",
            "0.005480217653791324\n",
            "Loss at test in  536  epoch\n",
            "0.3105004813411994\n",
            "Accuracy:  0.8933333333333333\n",
            "############################################################\n",
            "Loss at train in  537  epoch\n",
            "0.006588696542308753\n",
            "Loss at test in  537  epoch\n",
            "0.30991321525335064\n",
            "Accuracy:  0.8926666666666667\n",
            "############################################################\n",
            "Loss at train in  538  epoch\n",
            "0.006287315895199785\n",
            "Loss at test in  538  epoch\n",
            "0.3182456450432563\n",
            "Accuracy:  0.887\n",
            "############################################################\n",
            "Loss at train in  539  epoch\n",
            "0.006509022316189088\n",
            "Loss at test in  539  epoch\n",
            "0.3071958500663039\n",
            "Accuracy:  0.8946666666666667\n",
            "############################################################\n",
            "Loss at train in  540  epoch\n",
            "0.006148299495629911\n",
            "Loss at test in  540  epoch\n",
            "0.31115144883975626\n",
            "Accuracy:  0.888\n",
            "############################################################\n",
            "Loss at train in  541  epoch\n",
            "0.006574664443750124\n",
            "Loss at test in  541  epoch\n",
            "0.317279530917874\n",
            "Accuracy:  0.89\n",
            "############################################################\n",
            "Loss at train in  542  epoch\n",
            "0.006335014079021737\n",
            "Loss at test in  542  epoch\n",
            "0.30005770519009\n",
            "Accuracy:  0.8953333333333333\n",
            "############################################################\n",
            "Loss at train in  543  epoch\n",
            "0.005250976989615485\n",
            "Loss at test in  543  epoch\n",
            "0.3281438701159895\n",
            "Accuracy:  0.885\n",
            "############################################################\n",
            "Loss at train in  544  epoch\n",
            "0.0066092104155867715\n",
            "Loss at test in  544  epoch\n",
            "0.31450701761801275\n",
            "Accuracy:  0.885\n",
            "############################################################\n",
            "Loss at train in  545  epoch\n",
            "0.006131123825964365\n",
            "Loss at test in  545  epoch\n",
            "0.31545332673679854\n",
            "Accuracy:  0.8876666666666667\n",
            "############################################################\n",
            "Loss at train in  546  epoch\n",
            "0.005659657232557433\n",
            "Loss at test in  546  epoch\n",
            "0.30458929201036455\n",
            "Accuracy:  0.8936666666666667\n",
            "############################################################\n",
            "Loss at train in  547  epoch\n",
            "0.0054167336390921065\n",
            "Loss at test in  547  epoch\n",
            "0.3110018786645699\n",
            "Accuracy:  0.8853333333333333\n",
            "############################################################\n",
            "Loss at train in  548  epoch\n",
            "0.006428283224983757\n",
            "Loss at test in  548  epoch\n",
            "0.30890587533950575\n",
            "Accuracy:  0.896\n",
            "############################################################\n",
            "Loss at train in  549  epoch\n",
            "0.005572685540002518\n",
            "Loss at test in  549  epoch\n",
            "0.3185796406514694\n",
            "Accuracy:  0.8946666666666667\n",
            "############################################################\n",
            "Loss at train in  550  epoch\n",
            "0.0052634601911051085\n",
            "Loss at test in  550  epoch\n",
            "0.32639393707528186\n",
            "Accuracy:  0.8923333333333333\n",
            "############################################################\n",
            "Loss at train in  551  epoch\n",
            "0.005698890150572758\n",
            "Loss at test in  551  epoch\n",
            "0.31655725699328285\n",
            "Accuracy:  0.8893333333333333\n",
            "############################################################\n",
            "Loss at train in  552  epoch\n",
            "0.005597283261571738\n",
            "Loss at test in  552  epoch\n",
            "0.31566680372640543\n",
            "Accuracy:  0.8903333333333333\n",
            "############################################################\n",
            "Loss at train in  553  epoch\n",
            "0.006125839400299883\n",
            "Loss at test in  553  epoch\n",
            "0.3092936530549799\n",
            "Accuracy:  0.8906666666666667\n",
            "############################################################\n",
            "Loss at train in  554  epoch\n",
            "0.006109980997133074\n",
            "Loss at test in  554  epoch\n",
            "0.3202556950381744\n",
            "Accuracy:  0.8806666666666667\n",
            "############################################################\n",
            "Loss at train in  555  epoch\n",
            "0.00673189011934656\n",
            "Loss at test in  555  epoch\n",
            "0.3184118616800743\n",
            "Accuracy:  0.884\n",
            "############################################################\n",
            "Loss at train in  556  epoch\n",
            "0.006245088155570436\n",
            "Loss at test in  556  epoch\n",
            "0.3068395551731371\n",
            "Accuracy:  0.8906666666666667\n",
            "############################################################\n",
            "Loss at train in  557  epoch\n",
            "0.006418373215273477\n",
            "Loss at test in  557  epoch\n",
            "0.30817965500132954\n",
            "Accuracy:  0.8923333333333333\n",
            "############################################################\n",
            "Loss at train in  558  epoch\n",
            "0.0059930795840893135\n",
            "Loss at test in  558  epoch\n",
            "0.3036059866054559\n",
            "Accuracy:  0.895\n",
            "############################################################\n",
            "Loss at train in  559  epoch\n",
            "0.005955396588745514\n",
            "Loss at test in  559  epoch\n",
            "0.3040440540176318\n",
            "Accuracy:  0.8976666666666666\n",
            "############################################################\n",
            "Loss at train in  560  epoch\n",
            "0.005752921086236721\n",
            "Loss at test in  560  epoch\n",
            "0.33064847765970934\n",
            "Accuracy:  0.89\n",
            "############################################################\n",
            "Loss at train in  561  epoch\n",
            "0.004998680124529464\n",
            "Loss at test in  561  epoch\n",
            "0.32390659716594505\n",
            "Accuracy:  0.8896666666666667\n",
            "############################################################\n",
            "Loss at train in  562  epoch\n",
            "0.006326308572271952\n",
            "Loss at test in  562  epoch\n",
            "0.3055949563514311\n",
            "Accuracy:  0.8953333333333333\n",
            "############################################################\n",
            "Loss at train in  563  epoch\n",
            "0.0050754801043690475\n",
            "Loss at test in  563  epoch\n",
            "0.3536333105741662\n",
            "Accuracy:  0.879\n",
            "############################################################\n",
            "Loss at train in  564  epoch\n",
            "0.0052715881866395985\n",
            "Loss at test in  564  epoch\n",
            "0.3133598245750945\n",
            "Accuracy:  0.8913333333333333\n",
            "############################################################\n",
            "Loss at train in  565  epoch\n",
            "0.006043455199885426\n",
            "Loss at test in  565  epoch\n",
            "0.34986051867565604\n",
            "Accuracy:  0.8833333333333333\n",
            "############################################################\n",
            "Loss at train in  566  epoch\n",
            "0.005197703888299448\n",
            "Loss at test in  566  epoch\n",
            "0.3370687759745464\n",
            "Accuracy:  0.8826666666666667\n",
            "############################################################\n",
            "Loss at train in  567  epoch\n",
            "0.005829710869651093\n",
            "Loss at test in  567  epoch\n",
            "0.3230112833515626\n",
            "Accuracy:  0.883\n",
            "############################################################\n",
            "Loss at train in  568  epoch\n",
            "0.006000059106970694\n",
            "Loss at test in  568  epoch\n",
            "0.31076437823837066\n",
            "Accuracy:  0.8953333333333333\n",
            "############################################################\n",
            "Loss at train in  569  epoch\n",
            "0.005353448357390417\n",
            "Loss at test in  569  epoch\n",
            "0.3112128830271616\n",
            "Accuracy:  0.8953333333333333\n",
            "############################################################\n",
            "Loss at train in  570  epoch\n",
            "0.005611409125188244\n",
            "Loss at test in  570  epoch\n",
            "0.3282824911209967\n",
            "Accuracy:  0.8836666666666667\n",
            "############################################################\n",
            "Loss at train in  571  epoch\n",
            "0.005871652796989307\n",
            "Loss at test in  571  epoch\n",
            "0.3056587639394457\n",
            "Accuracy:  0.8956666666666667\n",
            "############################################################\n",
            "Loss at train in  572  epoch\n",
            "0.005787851337630274\n",
            "Loss at test in  572  epoch\n",
            "0.30021356708283053\n",
            "Accuracy:  0.8946666666666667\n",
            "############################################################\n",
            "Loss at train in  573  epoch\n",
            "0.0056217363993530944\n",
            "Loss at test in  573  epoch\n",
            "0.3101374831268524\n",
            "Accuracy:  0.89\n",
            "############################################################\n",
            "Loss at train in  574  epoch\n",
            "0.0057460142619022775\n",
            "Loss at test in  574  epoch\n",
            "0.3089186577916628\n",
            "Accuracy:  0.892\n",
            "############################################################\n",
            "Loss at train in  575  epoch\n",
            "0.005781984978861813\n",
            "Loss at test in  575  epoch\n",
            "0.3072692529562607\n",
            "Accuracy:  0.8886666666666667\n",
            "############################################################\n",
            "Loss at train in  576  epoch\n",
            "0.005870823822186029\n",
            "Loss at test in  576  epoch\n",
            "0.31875945919205634\n",
            "Accuracy:  0.8936666666666667\n",
            "############################################################\n",
            "Loss at train in  577  epoch\n",
            "0.0060174821298024945\n",
            "Loss at test in  577  epoch\n",
            "0.3179945766896476\n",
            "Accuracy:  0.891\n",
            "############################################################\n",
            "Loss at train in  578  epoch\n",
            "0.00557612783774068\n",
            "Loss at test in  578  epoch\n",
            "0.3225148221069063\n",
            "Accuracy:  0.888\n",
            "############################################################\n",
            "Loss at train in  579  epoch\n",
            "0.006372122662846288\n",
            "Loss at test in  579  epoch\n",
            "0.33399419030380795\n",
            "Accuracy:  0.8793333333333333\n",
            "############################################################\n",
            "Loss at train in  580  epoch\n",
            "0.006481222646929848\n",
            "Loss at test in  580  epoch\n",
            "0.30526130495730386\n",
            "Accuracy:  0.8873333333333333\n",
            "############################################################\n",
            "Loss at train in  581  epoch\n",
            "0.005535170227511827\n",
            "Loss at test in  581  epoch\n",
            "0.3119652319842107\n",
            "Accuracy:  0.8956666666666667\n",
            "############################################################\n",
            "Loss at train in  582  epoch\n",
            "0.005789565026741559\n",
            "Loss at test in  582  epoch\n",
            "0.314344208483404\n",
            "Accuracy:  0.8913333333333333\n",
            "############################################################\n",
            "Loss at train in  583  epoch\n",
            "0.004859755180240247\n",
            "Loss at test in  583  epoch\n",
            "0.31195625412362027\n",
            "Accuracy:  0.8883333333333333\n",
            "############################################################\n",
            "Loss at train in  584  epoch\n",
            "0.005786303967587859\n",
            "Loss at test in  584  epoch\n",
            "0.30201813137440925\n",
            "Accuracy:  0.8966666666666666\n",
            "############################################################\n",
            "Loss at train in  585  epoch\n",
            "0.005755951871342421\n",
            "Loss at test in  585  epoch\n",
            "0.30655215136449443\n",
            "Accuracy:  0.8966666666666666\n",
            "############################################################\n",
            "Loss at train in  586  epoch\n",
            "0.005923055498124181\n",
            "Loss at test in  586  epoch\n",
            "0.3104397056383761\n",
            "Accuracy:  0.8913333333333333\n",
            "############################################################\n",
            "Loss at train in  587  epoch\n",
            "0.00583287828700465\n",
            "Loss at test in  587  epoch\n",
            "0.31687437009027325\n",
            "Accuracy:  0.887\n",
            "############################################################\n",
            "Loss at train in  588  epoch\n",
            "0.005438627818113542\n",
            "Loss at test in  588  epoch\n",
            "0.3103424170680547\n",
            "Accuracy:  0.8883333333333333\n",
            "############################################################\n",
            "Loss at train in  589  epoch\n",
            "0.006013513111774426\n",
            "Loss at test in  589  epoch\n",
            "0.31109325752711003\n",
            "Accuracy:  0.891\n",
            "############################################################\n",
            "Loss at train in  590  epoch\n",
            "0.005589386159730238\n",
            "Loss at test in  590  epoch\n",
            "0.3001893987745659\n",
            "Accuracy:  0.8936666666666667\n",
            "############################################################\n",
            "Loss at train in  591  epoch\n",
            "0.005559345376378043\n",
            "Loss at test in  591  epoch\n",
            "0.3125580775789085\n",
            "Accuracy:  0.8943333333333333\n",
            "############################################################\n",
            "Loss at train in  592  epoch\n",
            "0.005859605443966149\n",
            "Loss at test in  592  epoch\n",
            "0.3086090783165058\n",
            "Accuracy:  0.8876666666666667\n",
            "############################################################\n",
            "Loss at train in  593  epoch\n",
            "0.006421717466790681\n",
            "Loss at test in  593  epoch\n",
            "0.3032726743958543\n",
            "Accuracy:  0.8913333333333333\n",
            "############################################################\n",
            "Loss at train in  594  epoch\n",
            "0.005968899658956529\n",
            "Loss at test in  594  epoch\n",
            "0.33958327496437213\n",
            "Accuracy:  0.886\n",
            "############################################################\n",
            "Loss at train in  595  epoch\n",
            "0.005925599076904332\n",
            "Loss at test in  595  epoch\n",
            "0.33847061176003\n",
            "Accuracy:  0.883\n",
            "############################################################\n",
            "Loss at train in  596  epoch\n",
            "0.005803754666436751\n",
            "Loss at test in  596  epoch\n",
            "0.3274759181757988\n",
            "Accuracy:  0.8853333333333333\n",
            "############################################################\n",
            "Loss at train in  597  epoch\n",
            "0.0052657544811662614\n",
            "Loss at test in  597  epoch\n",
            "0.30717171356926354\n",
            "Accuracy:  0.8883333333333333\n",
            "############################################################\n",
            "Loss at train in  598  epoch\n",
            "0.005142790177638252\n",
            "Loss at test in  598  epoch\n",
            "0.33238389963650705\n",
            "Accuracy:  0.889\n",
            "############################################################\n",
            "Loss at train in  599  epoch\n",
            "0.005610906591745483\n",
            "Loss at test in  599  epoch\n",
            "0.33307102472422556\n",
            "Accuracy:  0.8876666666666667\n",
            "############################################################\n",
            "Loss at train in  600  epoch\n",
            "0.004416089287472644\n",
            "Loss at test in  600  epoch\n",
            "0.3242733938146731\n",
            "Accuracy:  0.8946666666666667\n",
            "############################################################\n",
            "Loss at train in  601  epoch\n",
            "0.00534320317502838\n",
            "Loss at test in  601  epoch\n",
            "0.31837524265672146\n",
            "Accuracy:  0.8826666666666667\n",
            "############################################################\n",
            "Loss at train in  602  epoch\n",
            "0.004992081133972188\n",
            "Loss at test in  602  epoch\n",
            "0.320145004618201\n",
            "Accuracy:  0.8823333333333333\n",
            "############################################################\n",
            "Loss at train in  603  epoch\n",
            "0.005345359863452893\n",
            "Loss at test in  603  epoch\n",
            "0.31295655312096976\n",
            "Accuracy:  0.8913333333333333\n",
            "############################################################\n",
            "Loss at train in  604  epoch\n",
            "0.005240827448959992\n",
            "Loss at test in  604  epoch\n",
            "0.317078451561526\n",
            "Accuracy:  0.8906666666666667\n",
            "############################################################\n",
            "Loss at train in  605  epoch\n",
            "0.005297640877664848\n",
            "Loss at test in  605  epoch\n",
            "0.3165705862500004\n",
            "Accuracy:  0.8913333333333333\n",
            "############################################################\n",
            "Loss at train in  606  epoch\n",
            "0.0059376992962643154\n",
            "Loss at test in  606  epoch\n",
            "0.3283528992697264\n",
            "Accuracy:  0.8876666666666667\n",
            "############################################################\n",
            "Loss at train in  607  epoch\n",
            "0.006035285444419296\n",
            "Loss at test in  607  epoch\n",
            "0.3177895779657875\n",
            "Accuracy:  0.8906666666666667\n",
            "############################################################\n",
            "Loss at train in  608  epoch\n",
            "0.005112901702010985\n",
            "Loss at test in  608  epoch\n",
            "0.3199487093810203\n",
            "Accuracy:  0.8923333333333333\n",
            "############################################################\n",
            "Loss at train in  609  epoch\n",
            "0.005682049757697509\n",
            "Loss at test in  609  epoch\n",
            "0.3221706025170064\n",
            "Accuracy:  0.8866666666666667\n",
            "############################################################\n",
            "Loss at train in  610  epoch\n",
            "0.005549400522520889\n",
            "Loss at test in  610  epoch\n",
            "0.3205997922663548\n",
            "Accuracy:  0.888\n",
            "############################################################\n",
            "Loss at train in  611  epoch\n",
            "0.0056503056727178055\n",
            "Loss at test in  611  epoch\n",
            "0.3556683197718046\n",
            "Accuracy:  0.878\n",
            "############################################################\n",
            "Loss at train in  612  epoch\n",
            "0.0056825760534725805\n",
            "Loss at test in  612  epoch\n",
            "0.3076249302294678\n",
            "Accuracy:  0.894\n",
            "############################################################\n",
            "Loss at train in  613  epoch\n",
            "0.005871687999498326\n",
            "Loss at test in  613  epoch\n",
            "0.3330630673870052\n",
            "Accuracy:  0.8843333333333333\n",
            "############################################################\n",
            "Loss at train in  614  epoch\n",
            "0.005118117701680994\n",
            "Loss at test in  614  epoch\n",
            "0.33771403918223314\n",
            "Accuracy:  0.8866666666666667\n",
            "############################################################\n",
            "Loss at train in  615  epoch\n",
            "0.005352652977167349\n",
            "Loss at test in  615  epoch\n",
            "0.335459289079667\n",
            "Accuracy:  0.8826666666666667\n",
            "############################################################\n",
            "Loss at train in  616  epoch\n",
            "0.005797299987265482\n",
            "Loss at test in  616  epoch\n",
            "0.3047306660724384\n",
            "Accuracy:  0.8936666666666667\n",
            "############################################################\n",
            "Loss at train in  617  epoch\n",
            "0.005842907767788304\n",
            "Loss at test in  617  epoch\n",
            "0.30013543875014975\n",
            "Accuracy:  0.8973333333333333\n",
            "############################################################\n",
            "Loss at train in  618  epoch\n",
            "0.005032414368667703\n",
            "Loss at test in  618  epoch\n",
            "0.32836976964792625\n",
            "Accuracy:  0.8836666666666667\n",
            "############################################################\n",
            "Loss at train in  619  epoch\n",
            "0.005768237059569398\n",
            "Loss at test in  619  epoch\n",
            "0.2982341646402979\n",
            "Accuracy:  0.8976666666666666\n",
            "############################################################\n",
            "Loss at train in  620  epoch\n",
            "0.006645710057466671\n",
            "Loss at test in  620  epoch\n",
            "0.30927543796016255\n",
            "Accuracy:  0.8886666666666667\n",
            "############################################################\n",
            "Loss at train in  621  epoch\n",
            "0.005899509562367746\n",
            "Loss at test in  621  epoch\n",
            "0.33580391768796697\n",
            "Accuracy:  0.886\n",
            "############################################################\n",
            "Loss at train in  622  epoch\n",
            "0.005797659283765498\n",
            "Loss at test in  622  epoch\n",
            "0.3055410579044598\n",
            "Accuracy:  0.8956666666666667\n",
            "############################################################\n",
            "Loss at train in  623  epoch\n",
            "0.00585812610640485\n",
            "Loss at test in  623  epoch\n",
            "0.31478919562961605\n",
            "Accuracy:  0.885\n",
            "############################################################\n",
            "Loss at train in  624  epoch\n",
            "0.006069886070841055\n",
            "Loss at test in  624  epoch\n",
            "0.33672926173015855\n",
            "Accuracy:  0.886\n",
            "############################################################\n",
            "Loss at train in  625  epoch\n",
            "0.0062339233004266425\n",
            "Loss at test in  625  epoch\n",
            "0.32890805503849607\n",
            "Accuracy:  0.8896666666666667\n",
            "############################################################\n",
            "Loss at train in  626  epoch\n",
            "0.005121739874592983\n",
            "Loss at test in  626  epoch\n",
            "0.31994964042411267\n",
            "Accuracy:  0.8933333333333333\n",
            "############################################################\n",
            "Loss at train in  627  epoch\n",
            "0.005834953099681277\n",
            "Loss at test in  627  epoch\n",
            "0.33365968772073934\n",
            "Accuracy:  0.886\n",
            "############################################################\n",
            "Loss at train in  628  epoch\n",
            "0.005717762851860283\n",
            "Loss at test in  628  epoch\n",
            "0.30540759952407975\n",
            "Accuracy:  0.8966666666666666\n",
            "############################################################\n",
            "Loss at train in  629  epoch\n",
            "0.005291705978174995\n",
            "Loss at test in  629  epoch\n",
            "0.2998517550215811\n",
            "Accuracy:  0.8973333333333333\n",
            "############################################################\n",
            "Loss at train in  630  epoch\n",
            "0.005686744099078015\n",
            "Loss at test in  630  epoch\n",
            "0.3074830671778246\n",
            "Accuracy:  0.8956666666666667\n",
            "############################################################\n",
            "Loss at train in  631  epoch\n",
            "0.005258780517479471\n",
            "Loss at test in  631  epoch\n",
            "0.302073103375134\n",
            "Accuracy:  0.8963333333333333\n",
            "############################################################\n",
            "Loss at train in  632  epoch\n",
            "0.006066483463203177\n",
            "Loss at test in  632  epoch\n",
            "0.31553948449233893\n",
            "Accuracy:  0.89\n",
            "############################################################\n",
            "Loss at train in  633  epoch\n",
            "0.005885674829563927\n",
            "Loss at test in  633  epoch\n",
            "0.3069779064785391\n",
            "Accuracy:  0.8916666666666667\n",
            "############################################################\n",
            "Loss at train in  634  epoch\n",
            "0.005380632546003716\n",
            "Loss at test in  634  epoch\n",
            "0.3158714478145839\n",
            "Accuracy:  0.8936666666666667\n",
            "############################################################\n",
            "Loss at train in  635  epoch\n",
            "0.005663692055544273\n",
            "Loss at test in  635  epoch\n",
            "0.3071465742243577\n",
            "Accuracy:  0.8943333333333333\n",
            "############################################################\n",
            "Loss at train in  636  epoch\n",
            "0.005766811569038013\n",
            "Loss at test in  636  epoch\n",
            "0.30403102277402194\n",
            "Accuracy:  0.8973333333333333\n",
            "############################################################\n",
            "Loss at train in  637  epoch\n",
            "0.005677812857175992\n",
            "Loss at test in  637  epoch\n",
            "0.3299913286157396\n",
            "Accuracy:  0.8823333333333333\n",
            "############################################################\n",
            "Loss at train in  638  epoch\n",
            "0.0050780336066079575\n",
            "Loss at test in  638  epoch\n",
            "0.33439968028970357\n",
            "Accuracy:  0.8896666666666667\n",
            "############################################################\n",
            "Loss at train in  639  epoch\n",
            "0.005420653753674656\n",
            "Loss at test in  639  epoch\n",
            "0.3323465160897715\n",
            "Accuracy:  0.8893333333333333\n",
            "############################################################\n",
            "Loss at train in  640  epoch\n",
            "0.005077757319508136\n",
            "Loss at test in  640  epoch\n",
            "0.3136067646714895\n",
            "Accuracy:  0.8863333333333333\n",
            "############################################################\n",
            "Loss at train in  641  epoch\n",
            "0.005727632549798472\n",
            "Loss at test in  641  epoch\n",
            "0.3283103110091342\n",
            "Accuracy:  0.8836666666666667\n",
            "############################################################\n",
            "Loss at train in  642  epoch\n",
            "0.005556683666157941\n",
            "Loss at test in  642  epoch\n",
            "0.32130922245720006\n",
            "Accuracy:  0.8856666666666667\n",
            "############################################################\n",
            "Loss at train in  643  epoch\n",
            "0.00554968146186303\n",
            "Loss at test in  643  epoch\n",
            "0.33602220655231074\n",
            "Accuracy:  0.889\n",
            "############################################################\n",
            "Loss at train in  644  epoch\n",
            "0.005757909167977913\n",
            "Loss at test in  644  epoch\n",
            "0.3195287602593737\n",
            "Accuracy:  0.8953333333333333\n",
            "############################################################\n",
            "Loss at train in  645  epoch\n",
            "0.005576431671912871\n",
            "Loss at test in  645  epoch\n",
            "0.3307356410917546\n",
            "Accuracy:  0.894\n",
            "############################################################\n",
            "Loss at train in  646  epoch\n",
            "0.005553171727428794\n",
            "Loss at test in  646  epoch\n",
            "0.3208219645701837\n",
            "Accuracy:  0.8906666666666667\n",
            "############################################################\n",
            "Loss at train in  647  epoch\n",
            "0.00483158461011746\n",
            "Loss at test in  647  epoch\n",
            "0.3260420418312164\n",
            "Accuracy:  0.8906666666666667\n",
            "############################################################\n",
            "Loss at train in  648  epoch\n",
            "0.005331028712940245\n",
            "Loss at test in  648  epoch\n",
            "0.3370707193663945\n",
            "Accuracy:  0.8863333333333333\n",
            "############################################################\n",
            "Loss at train in  649  epoch\n",
            "0.005803808024489415\n",
            "Loss at test in  649  epoch\n",
            "0.3280528297530083\n",
            "Accuracy:  0.8873333333333333\n",
            "############################################################\n",
            "Loss at train in  650  epoch\n",
            "0.005789062275004543\n",
            "Loss at test in  650  epoch\n",
            "0.29795070232691856\n",
            "Accuracy:  0.8943333333333333\n",
            "############################################################\n",
            "Loss at train in  651  epoch\n",
            "0.005648806151601814\n",
            "Loss at test in  651  epoch\n",
            "0.3083928114269946\n",
            "Accuracy:  0.893\n",
            "############################################################\n",
            "Loss at train in  652  epoch\n",
            "0.005649158101079194\n",
            "Loss at test in  652  epoch\n",
            "0.29873861161845366\n",
            "Accuracy:  0.897\n",
            "############################################################\n",
            "Loss at train in  653  epoch\n",
            "0.0057506104919462404\n",
            "Loss at test in  653  epoch\n",
            "0.30551556847278966\n",
            "Accuracy:  0.892\n",
            "############################################################\n",
            "Loss at train in  654  epoch\n",
            "0.00636869745047035\n",
            "Loss at test in  654  epoch\n",
            "0.2994355706596142\n",
            "Accuracy:  0.896\n",
            "############################################################\n",
            "Loss at train in  655  epoch\n",
            "0.005047892634639662\n",
            "Loss at test in  655  epoch\n",
            "0.32670948420645385\n",
            "Accuracy:  0.888\n",
            "############################################################\n",
            "Loss at train in  656  epoch\n",
            "0.005783993233186918\n",
            "Loss at test in  656  epoch\n",
            "0.30119946757558164\n",
            "Accuracy:  0.8963333333333333\n",
            "############################################################\n",
            "Loss at train in  657  epoch\n",
            "0.0054967161626772254\n",
            "Loss at test in  657  epoch\n",
            "0.3181192218713523\n",
            "Accuracy:  0.8883333333333333\n",
            "############################################################\n",
            "Loss at train in  658  epoch\n",
            "0.005274148455549774\n",
            "Loss at test in  658  epoch\n",
            "0.31206919267305094\n",
            "Accuracy:  0.899\n",
            "############################################################\n",
            "Loss at train in  659  epoch\n",
            "0.005462588263384663\n",
            "Loss at test in  659  epoch\n",
            "0.3224115756034542\n",
            "Accuracy:  0.885\n",
            "############################################################\n",
            "Loss at train in  660  epoch\n",
            "0.004926429629766793\n",
            "Loss at test in  660  epoch\n",
            "0.332370293690688\n",
            "Accuracy:  0.8916666666666667\n",
            "############################################################\n",
            "Loss at train in  661  epoch\n",
            "0.005065637907047757\n",
            "Loss at test in  661  epoch\n",
            "0.3030201673724612\n",
            "Accuracy:  0.8983333333333333\n",
            "############################################################\n",
            "Loss at train in  662  epoch\n",
            "0.005042093639206901\n",
            "Loss at test in  662  epoch\n",
            "0.3142213448148319\n",
            "Accuracy:  0.8936666666666667\n",
            "############################################################\n",
            "Loss at train in  663  epoch\n",
            "0.005998221374912602\n",
            "Loss at test in  663  epoch\n",
            "0.31641240819711186\n",
            "Accuracy:  0.8926666666666667\n",
            "############################################################\n",
            "Loss at train in  664  epoch\n",
            "0.005435004555564309\n",
            "Loss at test in  664  epoch\n",
            "0.29974641617434133\n",
            "Accuracy:  0.892\n",
            "############################################################\n",
            "Loss at train in  665  epoch\n",
            "0.005858081217750749\n",
            "Loss at test in  665  epoch\n",
            "0.3333998400535154\n",
            "Accuracy:  0.8906666666666667\n",
            "############################################################\n",
            "Loss at train in  666  epoch\n",
            "0.004956729625739946\n",
            "Loss at test in  666  epoch\n",
            "0.2979060223127589\n",
            "Accuracy:  0.899\n",
            "############################################################\n",
            "Loss at train in  667  epoch\n",
            "0.005194338663281514\n",
            "Loss at test in  667  epoch\n",
            "0.32916084317595845\n",
            "Accuracy:  0.8886666666666667\n",
            "############################################################\n",
            "Loss at train in  668  epoch\n",
            "0.005414318807275908\n",
            "Loss at test in  668  epoch\n",
            "0.33242564425745075\n",
            "Accuracy:  0.8843333333333333\n",
            "############################################################\n",
            "Loss at train in  669  epoch\n",
            "0.005555418000243443\n",
            "Loss at test in  669  epoch\n",
            "0.3381934877801195\n",
            "Accuracy:  0.8906666666666667\n",
            "############################################################\n",
            "Loss at train in  670  epoch\n",
            "0.005669792194343242\n",
            "Loss at test in  670  epoch\n",
            "0.3249885640961013\n",
            "Accuracy:  0.8903333333333333\n",
            "############################################################\n",
            "Loss at train in  671  epoch\n",
            "0.0055787523208572975\n",
            "Loss at test in  671  epoch\n",
            "0.32238520109199487\n",
            "Accuracy:  0.8966666666666666\n",
            "############################################################\n",
            "Loss at train in  672  epoch\n",
            "0.005903901256073025\n",
            "Loss at test in  672  epoch\n",
            "0.3224997758009231\n",
            "Accuracy:  0.8836666666666667\n",
            "############################################################\n",
            "Loss at train in  673  epoch\n",
            "0.004936387638919759\n",
            "Loss at test in  673  epoch\n",
            "0.3130853049438736\n",
            "Accuracy:  0.893\n",
            "############################################################\n",
            "Loss at train in  674  epoch\n",
            "0.005134463980881475\n",
            "Loss at test in  674  epoch\n",
            "0.297985076713378\n",
            "Accuracy:  0.904\n",
            "############################################################\n",
            "Loss at train in  675  epoch\n",
            "0.005642492854227602\n",
            "Loss at test in  675  epoch\n",
            "0.31371987305578847\n",
            "Accuracy:  0.8896666666666667\n",
            "############################################################\n",
            "Loss at train in  676  epoch\n",
            "0.004734951285959524\n",
            "Loss at test in  676  epoch\n",
            "0.3590339411969907\n",
            "Accuracy:  0.885\n",
            "############################################################\n",
            "Loss at train in  677  epoch\n",
            "0.0055632360873448215\n",
            "Loss at test in  677  epoch\n",
            "0.3202649748608326\n",
            "Accuracy:  0.8903333333333333\n",
            "############################################################\n",
            "Loss at train in  678  epoch\n",
            "0.004961655262153243\n",
            "Loss at test in  678  epoch\n",
            "0.29952032673721524\n",
            "Accuracy:  0.8943333333333333\n",
            "############################################################\n",
            "Loss at train in  679  epoch\n",
            "0.005104643042787586\n",
            "Loss at test in  679  epoch\n",
            "0.33110464856290345\n",
            "Accuracy:  0.8906666666666667\n",
            "############################################################\n",
            "Loss at train in  680  epoch\n",
            "0.004881990865361934\n",
            "Loss at test in  680  epoch\n",
            "0.3116960355503119\n",
            "Accuracy:  0.8906666666666667\n",
            "############################################################\n",
            "Loss at train in  681  epoch\n",
            "0.00512045612908823\n",
            "Loss at test in  681  epoch\n",
            "0.31932305260824334\n",
            "Accuracy:  0.8933333333333333\n",
            "############################################################\n",
            "Loss at train in  682  epoch\n",
            "0.005492045103722594\n",
            "Loss at test in  682  epoch\n",
            "0.31975620827059786\n",
            "Accuracy:  0.8983333333333333\n",
            "############################################################\n",
            "Loss at train in  683  epoch\n",
            "0.00593245556458433\n",
            "Loss at test in  683  epoch\n",
            "0.3014736312781386\n",
            "Accuracy:  0.8953333333333333\n",
            "############################################################\n",
            "Loss at train in  684  epoch\n",
            "0.005146730805488706\n",
            "Loss at test in  684  epoch\n",
            "0.312122378332252\n",
            "Accuracy:  0.883\n",
            "############################################################\n",
            "Loss at train in  685  epoch\n",
            "0.0057134299517552665\n",
            "Loss at test in  685  epoch\n",
            "0.36989194109242424\n",
            "Accuracy:  0.8686666666666667\n",
            "############################################################\n",
            "Loss at train in  686  epoch\n",
            "0.006076570365039275\n",
            "Loss at test in  686  epoch\n",
            "0.3068759946920772\n",
            "Accuracy:  0.8943333333333333\n",
            "############################################################\n",
            "Loss at train in  687  epoch\n",
            "0.00575471249981537\n",
            "Loss at test in  687  epoch\n",
            "0.32415739752589273\n",
            "Accuracy:  0.8873333333333333\n",
            "############################################################\n",
            "Loss at train in  688  epoch\n",
            "0.00499429803398866\n",
            "Loss at test in  688  epoch\n",
            "0.31695431376107014\n",
            "Accuracy:  0.8883333333333333\n",
            "############################################################\n",
            "Loss at train in  689  epoch\n",
            "0.005105698443995208\n",
            "Loss at test in  689  epoch\n",
            "0.3239173967374485\n",
            "Accuracy:  0.889\n",
            "############################################################\n",
            "Loss at train in  690  epoch\n",
            "0.005388136694537303\n",
            "Loss at test in  690  epoch\n",
            "0.3013674335945553\n",
            "Accuracy:  0.897\n",
            "############################################################\n",
            "Loss at train in  691  epoch\n",
            "0.004931420650174479\n",
            "Loss at test in  691  epoch\n",
            "0.3335988949158088\n",
            "Accuracy:  0.89\n",
            "############################################################\n",
            "Loss at train in  692  epoch\n",
            "0.005248157697994823\n",
            "Loss at test in  692  epoch\n",
            "0.3328176216058048\n",
            "Accuracy:  0.886\n",
            "############################################################\n",
            "Loss at train in  693  epoch\n",
            "0.005366357254961018\n",
            "Loss at test in  693  epoch\n",
            "0.3211109608777277\n",
            "Accuracy:  0.8923333333333333\n",
            "############################################################\n",
            "Loss at train in  694  epoch\n",
            "0.005567269937596216\n",
            "Loss at test in  694  epoch\n",
            "0.3300755824285212\n",
            "Accuracy:  0.8893333333333333\n",
            "############################################################\n",
            "Loss at train in  695  epoch\n",
            "0.004888069044238006\n",
            "Loss at test in  695  epoch\n",
            "0.32457767705465645\n",
            "Accuracy:  0.893\n",
            "############################################################\n",
            "Loss at train in  696  epoch\n",
            "0.005652148900628369\n",
            "Loss at test in  696  epoch\n",
            "0.3131099974905213\n",
            "Accuracy:  0.892\n",
            "############################################################\n",
            "Loss at train in  697  epoch\n",
            "0.005484446912030589\n",
            "Loss at test in  697  epoch\n",
            "0.3151275874165706\n",
            "Accuracy:  0.8943333333333333\n",
            "############################################################\n",
            "Loss at train in  698  epoch\n",
            "0.005468991889248226\n",
            "Loss at test in  698  epoch\n",
            "0.3130580956584378\n",
            "Accuracy:  0.892\n",
            "############################################################\n",
            "Loss at train in  699  epoch\n",
            "0.00511874994334219\n",
            "Loss at test in  699  epoch\n",
            "0.3006375201405713\n",
            "Accuracy:  0.895\n",
            "############################################################\n",
            "Loss at train in  700  epoch\n",
            "0.005763469926204467\n",
            "Loss at test in  700  epoch\n",
            "0.3181826230625475\n",
            "Accuracy:  0.8886666666666667\n",
            "############################################################\n",
            "Loss at train in  701  epoch\n",
            "0.005278864291678105\n",
            "Loss at test in  701  epoch\n",
            "0.31206934332067\n",
            "Accuracy:  0.895\n",
            "############################################################\n",
            "Loss at train in  702  epoch\n",
            "0.004851494664286548\n",
            "Loss at test in  702  epoch\n",
            "0.3195834049258161\n",
            "Accuracy:  0.896\n",
            "############################################################\n",
            "Loss at train in  703  epoch\n",
            "0.0053622155702393185\n",
            "Loss at test in  703  epoch\n",
            "0.342893404540254\n",
            "Accuracy:  0.8883333333333333\n",
            "############################################################\n",
            "Loss at train in  704  epoch\n",
            "0.005284573410414003\n",
            "Loss at test in  704  epoch\n",
            "0.30448247635695574\n",
            "Accuracy:  0.8906666666666667\n",
            "############################################################\n",
            "Loss at train in  705  epoch\n",
            "0.004969730946551385\n",
            "Loss at test in  705  epoch\n",
            "0.31767578655462847\n",
            "Accuracy:  0.8906666666666667\n",
            "############################################################\n",
            "Loss at train in  706  epoch\n",
            "0.0052564036399324445\n",
            "Loss at test in  706  epoch\n",
            "0.3314703862671479\n",
            "Accuracy:  0.8853333333333333\n",
            "############################################################\n",
            "Loss at train in  707  epoch\n",
            "0.004751218277478701\n",
            "Loss at test in  707  epoch\n",
            "0.3299916014286271\n",
            "Accuracy:  0.8876666666666667\n",
            "############################################################\n",
            "Loss at train in  708  epoch\n",
            "0.0050697493396228924\n",
            "Loss at test in  708  epoch\n",
            "0.3222241292183556\n",
            "Accuracy:  0.8846666666666667\n",
            "############################################################\n",
            "Loss at train in  709  epoch\n",
            "0.005370986291403087\n",
            "Loss at test in  709  epoch\n",
            "0.3068160572854238\n",
            "Accuracy:  0.891\n",
            "############################################################\n",
            "Loss at train in  710  epoch\n",
            "0.005283098328788146\n",
            "Loss at test in  710  epoch\n",
            "0.3205963744575847\n",
            "Accuracy:  0.8903333333333333\n",
            "############################################################\n",
            "Loss at train in  711  epoch\n",
            "0.005548667260005174\n",
            "Loss at test in  711  epoch\n",
            "0.30815541780608535\n",
            "Accuracy:  0.8953333333333333\n",
            "############################################################\n",
            "Loss at train in  712  epoch\n",
            "0.005490725491312496\n",
            "Loss at test in  712  epoch\n",
            "0.335282502758738\n",
            "Accuracy:  0.8833333333333333\n",
            "############################################################\n",
            "Loss at train in  713  epoch\n",
            "0.004998142247848904\n",
            "Loss at test in  713  epoch\n",
            "0.30368743711886625\n",
            "Accuracy:  0.8973333333333333\n",
            "############################################################\n",
            "Loss at train in  714  epoch\n",
            "0.005932775616876695\n",
            "Loss at test in  714  epoch\n",
            "0.29755248513694155\n",
            "Accuracy:  0.8986666666666666\n",
            "############################################################\n",
            "Loss at train in  715  epoch\n",
            "0.005492973314412849\n",
            "Loss at test in  715  epoch\n",
            "0.3226674571369114\n",
            "Accuracy:  0.8886666666666667\n",
            "############################################################\n",
            "Loss at train in  716  epoch\n",
            "0.0053515585877132454\n",
            "Loss at test in  716  epoch\n",
            "0.3148025246073362\n",
            "Accuracy:  0.891\n",
            "############################################################\n",
            "Loss at train in  717  epoch\n",
            "0.005157599798951944\n",
            "Loss at test in  717  epoch\n",
            "0.3115244954439695\n",
            "Accuracy:  0.8936666666666667\n",
            "############################################################\n",
            "Loss at train in  718  epoch\n",
            "0.005837813151555794\n",
            "Loss at test in  718  epoch\n",
            "0.3195978650872023\n",
            "Accuracy:  0.8866666666666667\n",
            "############################################################\n",
            "Loss at train in  719  epoch\n",
            "0.0048843043585328335\n",
            "Loss at test in  719  epoch\n",
            "0.3280625820350875\n",
            "Accuracy:  0.8926666666666667\n",
            "############################################################\n",
            "Loss at train in  720  epoch\n",
            "0.004670261616088338\n",
            "Loss at test in  720  epoch\n",
            "0.31441512514724324\n",
            "Accuracy:  0.8926666666666667\n",
            "############################################################\n",
            "Loss at train in  721  epoch\n",
            "0.004577977320835401\n",
            "Loss at test in  721  epoch\n",
            "0.3262235310371598\n",
            "Accuracy:  0.8896666666666667\n",
            "############################################################\n",
            "Loss at train in  722  epoch\n",
            "0.005569811662653675\n",
            "Loss at test in  722  epoch\n",
            "0.31424443268802144\n",
            "Accuracy:  0.885\n",
            "############################################################\n",
            "Loss at train in  723  epoch\n",
            "0.005172732689564523\n",
            "Loss at test in  723  epoch\n",
            "0.33360778185302503\n",
            "Accuracy:  0.8886666666666667\n",
            "############################################################\n",
            "Loss at train in  724  epoch\n",
            "0.005600553084045811\n",
            "Loss at test in  724  epoch\n",
            "0.3202582661102241\n",
            "Accuracy:  0.891\n",
            "############################################################\n",
            "Loss at train in  725  epoch\n",
            "0.004943620542250697\n",
            "Loss at test in  725  epoch\n",
            "0.31268864307777094\n",
            "Accuracy:  0.8996666666666666\n",
            "############################################################\n",
            "Loss at train in  726  epoch\n",
            "0.00506115669850036\n",
            "Loss at test in  726  epoch\n",
            "0.3201024017087772\n",
            "Accuracy:  0.8976666666666666\n",
            "############################################################\n",
            "Loss at train in  727  epoch\n",
            "0.005768576334858656\n",
            "Loss at test in  727  epoch\n",
            "0.3183911877607049\n",
            "Accuracy:  0.892\n",
            "############################################################\n",
            "Loss at train in  728  epoch\n",
            "0.0048855339744680835\n",
            "Loss at test in  728  epoch\n",
            "0.3083661655724806\n",
            "Accuracy:  0.8983333333333333\n",
            "############################################################\n",
            "Loss at train in  729  epoch\n",
            "0.004546916356857202\n",
            "Loss at test in  729  epoch\n",
            "0.3255990239876014\n",
            "Accuracy:  0.9\n",
            "############################################################\n",
            "Loss at train in  730  epoch\n",
            "0.005504446985283238\n",
            "Loss at test in  730  epoch\n",
            "0.3387574574817957\n",
            "Accuracy:  0.8923333333333333\n",
            "############################################################\n",
            "Loss at train in  731  epoch\n",
            "0.0056090608825002785\n",
            "Loss at test in  731  epoch\n",
            "0.31390981322406547\n",
            "Accuracy:  0.8883333333333333\n",
            "############################################################\n",
            "Loss at train in  732  epoch\n",
            "0.00517081933294873\n",
            "Loss at test in  732  epoch\n",
            "0.3300676251459045\n",
            "Accuracy:  0.8966666666666666\n",
            "############################################################\n",
            "Loss at train in  733  epoch\n",
            "0.0050121310485526606\n",
            "Loss at test in  733  epoch\n",
            "0.3267860970606148\n",
            "Accuracy:  0.8956666666666667\n",
            "############################################################\n",
            "Loss at train in  734  epoch\n",
            "0.004476269777475142\n",
            "Loss at test in  734  epoch\n",
            "0.33256375142235567\n",
            "Accuracy:  0.8853333333333333\n",
            "############################################################\n",
            "Loss at train in  735  epoch\n",
            "0.004628137011937413\n",
            "Loss at test in  735  epoch\n",
            "0.35732889565333253\n",
            "Accuracy:  0.875\n",
            "############################################################\n",
            "Loss at train in  736  epoch\n",
            "0.005877179072871408\n",
            "Loss at test in  736  epoch\n",
            "0.31282379446777714\n",
            "Accuracy:  0.8976666666666666\n",
            "############################################################\n",
            "Loss at train in  737  epoch\n",
            "0.005272808673578753\n",
            "Loss at test in  737  epoch\n",
            "0.3243036385794289\n",
            "Accuracy:  0.8926666666666667\n",
            "############################################################\n",
            "Loss at train in  738  epoch\n",
            "0.004859420752156613\n",
            "Loss at test in  738  epoch\n",
            "0.3322680474139212\n",
            "Accuracy:  0.8896666666666667\n",
            "############################################################\n",
            "Loss at train in  739  epoch\n",
            "0.0049592263184135175\n",
            "Loss at test in  739  epoch\n",
            "0.3311453746630023\n",
            "Accuracy:  0.8896666666666667\n",
            "############################################################\n",
            "Loss at train in  740  epoch\n",
            "0.0045233022079346815\n",
            "Loss at test in  740  epoch\n",
            "0.35919133989505037\n",
            "Accuracy:  0.889\n",
            "############################################################\n",
            "Loss at train in  741  epoch\n",
            "0.005549938455719621\n",
            "Loss at test in  741  epoch\n",
            "0.3268250495565502\n",
            "Accuracy:  0.8923333333333333\n",
            "############################################################\n",
            "Loss at train in  742  epoch\n",
            "0.0052494877565362735\n",
            "Loss at test in  742  epoch\n",
            "0.3145798792017925\n",
            "Accuracy:  0.8983333333333333\n",
            "############################################################\n",
            "Loss at train in  743  epoch\n",
            "0.005040695773782825\n",
            "Loss at test in  743  epoch\n",
            "0.3218783001593921\n",
            "Accuracy:  0.8896666666666667\n",
            "############################################################\n",
            "Loss at train in  744  epoch\n",
            "0.004630669312454301\n",
            "Loss at test in  744  epoch\n",
            "0.34283974605218714\n",
            "Accuracy:  0.891\n",
            "############################################################\n",
            "Loss at train in  745  epoch\n",
            "0.00521298071118703\n",
            "Loss at test in  745  epoch\n",
            "0.3138542241459202\n",
            "Accuracy:  0.893\n",
            "############################################################\n",
            "Loss at train in  746  epoch\n",
            "0.004840164292707609\n",
            "Loss at test in  746  epoch\n",
            "0.3175710794425071\n",
            "Accuracy:  0.895\n",
            "############################################################\n",
            "Loss at train in  747  epoch\n",
            "0.00502310363751981\n",
            "Loss at test in  747  epoch\n",
            "0.34473875966602946\n",
            "Accuracy:  0.8856666666666667\n",
            "############################################################\n",
            "Loss at train in  748  epoch\n",
            "0.005501523140846215\n",
            "Loss at test in  748  epoch\n",
            "0.3239664452617256\n",
            "Accuracy:  0.8886666666666667\n",
            "############################################################\n",
            "Loss at train in  749  epoch\n",
            "0.005717931329165617\n",
            "Loss at test in  749  epoch\n",
            "0.3259306223820976\n",
            "Accuracy:  0.8886666666666667\n",
            "############################################################\n",
            "Loss at train in  750  epoch\n",
            "0.0051652223854241845\n",
            "Loss at test in  750  epoch\n",
            "0.31698585954217945\n",
            "Accuracy:  0.895\n",
            "############################################################\n",
            "Loss at train in  751  epoch\n",
            "0.004712397741816053\n",
            "Loss at test in  751  epoch\n",
            "0.3425771366708952\n",
            "Accuracy:  0.885\n",
            "############################################################\n",
            "Loss at train in  752  epoch\n",
            "0.005165341968838205\n",
            "Loss at test in  752  epoch\n",
            "0.33687148557113966\n",
            "Accuracy:  0.8873333333333333\n",
            "############################################################\n",
            "Loss at train in  753  epoch\n",
            "0.004790358900829985\n",
            "Loss at test in  753  epoch\n",
            "0.31759033348067744\n",
            "Accuracy:  0.8946666666666667\n",
            "############################################################\n",
            "Loss at train in  754  epoch\n",
            "0.004804757456833462\n",
            "Loss at test in  754  epoch\n",
            "0.31106076740488076\n",
            "Accuracy:  0.8986666666666666\n",
            "############################################################\n",
            "Loss at train in  755  epoch\n",
            "0.00443345216722056\n",
            "Loss at test in  755  epoch\n",
            "0.3189332748849716\n",
            "Accuracy:  0.8886666666666667\n",
            "############################################################\n",
            "Loss at train in  756  epoch\n",
            "0.0047588742651153305\n",
            "Loss at test in  756  epoch\n",
            "0.33895057634472603\n",
            "Accuracy:  0.8943333333333333\n",
            "############################################################\n",
            "Loss at train in  757  epoch\n",
            "0.0049105370468524815\n",
            "Loss at test in  757  epoch\n",
            "0.3225456122643601\n",
            "Accuracy:  0.893\n",
            "############################################################\n",
            "Loss at train in  758  epoch\n",
            "0.004262935880138894\n",
            "Loss at test in  758  epoch\n",
            "0.3272608649488847\n",
            "Accuracy:  0.897\n",
            "############################################################\n",
            "Loss at train in  759  epoch\n",
            "0.004650576775765055\n",
            "Loss at test in  759  epoch\n",
            "0.3402530205816731\n",
            "Accuracy:  0.8856666666666667\n",
            "############################################################\n",
            "Loss at train in  760  epoch\n",
            "0.004060437598590288\n",
            "Loss at test in  760  epoch\n",
            "0.31817345035305566\n",
            "Accuracy:  0.8913333333333333\n",
            "############################################################\n",
            "Loss at train in  761  epoch\n",
            "0.004723328968651888\n",
            "Loss at test in  761  epoch\n",
            "0.3636329603045956\n",
            "Accuracy:  0.88\n",
            "############################################################\n",
            "Loss at train in  762  epoch\n",
            "0.005410184693429044\n",
            "Loss at test in  762  epoch\n",
            "0.3287491191568728\n",
            "Accuracy:  0.8856666666666667\n",
            "############################################################\n",
            "Loss at train in  763  epoch\n",
            "0.005428883192459066\n",
            "Loss at test in  763  epoch\n",
            "0.3289032317862484\n",
            "Accuracy:  0.888\n",
            "############################################################\n",
            "Loss at train in  764  epoch\n",
            "0.0052473898490567146\n",
            "Loss at test in  764  epoch\n",
            "0.31159672727474513\n",
            "Accuracy:  0.8906666666666667\n",
            "############################################################\n",
            "Loss at train in  765  epoch\n",
            "0.00489209678647292\n",
            "Loss at test in  765  epoch\n",
            "0.3066699500306653\n",
            "Accuracy:  0.894\n",
            "############################################################\n",
            "Loss at train in  766  epoch\n",
            "0.005066348515729918\n",
            "Loss at test in  766  epoch\n",
            "0.33488861194381786\n",
            "Accuracy:  0.8916666666666667\n",
            "############################################################\n",
            "Loss at train in  767  epoch\n",
            "0.005897578894509267\n",
            "Loss at test in  767  epoch\n",
            "0.30127276343511894\n",
            "Accuracy:  0.897\n",
            "############################################################\n",
            "Loss at train in  768  epoch\n",
            "0.004457608894579812\n",
            "Loss at test in  768  epoch\n",
            "0.3190714366553571\n",
            "Accuracy:  0.896\n",
            "############################################################\n",
            "Loss at train in  769  epoch\n",
            "0.004718413005164337\n",
            "Loss at test in  769  epoch\n",
            "0.3066052893520828\n",
            "Accuracy:  0.895\n",
            "############################################################\n",
            "Loss at train in  770  epoch\n",
            "0.005525155317987953\n",
            "Loss at test in  770  epoch\n",
            "0.3078805043639342\n",
            "Accuracy:  0.892\n",
            "############################################################\n",
            "Loss at train in  771  epoch\n",
            "0.0046753307465275985\n",
            "Loss at test in  771  epoch\n",
            "0.3486977204158576\n",
            "Accuracy:  0.882\n",
            "############################################################\n",
            "Loss at train in  772  epoch\n",
            "0.005603501732468722\n",
            "Loss at test in  772  epoch\n",
            "0.3334755476438566\n",
            "Accuracy:  0.89\n",
            "############################################################\n",
            "Loss at train in  773  epoch\n",
            "0.004668822261564931\n",
            "Loss at test in  773  epoch\n",
            "0.3301708049923465\n",
            "Accuracy:  0.894\n",
            "############################################################\n",
            "Loss at train in  774  epoch\n",
            "0.0055777920458459\n",
            "Loss at test in  774  epoch\n",
            "0.34899474567070016\n",
            "Accuracy:  0.8846666666666667\n",
            "############################################################\n",
            "Loss at train in  775  epoch\n",
            "0.005022219139538288\n",
            "Loss at test in  775  epoch\n",
            "0.3180360725845412\n",
            "Accuracy:  0.8946666666666667\n",
            "############################################################\n",
            "Loss at train in  776  epoch\n",
            "0.005985074137819535\n",
            "Loss at test in  776  epoch\n",
            "0.3122384490322555\n",
            "Accuracy:  0.8953333333333333\n",
            "############################################################\n",
            "Loss at train in  777  epoch\n",
            "0.0053855847977798835\n",
            "Loss at test in  777  epoch\n",
            "0.32048523903606746\n",
            "Accuracy:  0.895\n",
            "############################################################\n",
            "Loss at train in  778  epoch\n",
            "0.004321338554665789\n",
            "Loss at test in  778  epoch\n",
            "0.31002880444704384\n",
            "Accuracy:  0.902\n",
            "############################################################\n",
            "Loss at train in  779  epoch\n",
            "0.004996089663580855\n",
            "Loss at test in  779  epoch\n",
            "0.33757002822590754\n",
            "Accuracy:  0.891\n",
            "############################################################\n",
            "Loss at train in  780  epoch\n",
            "0.004948349384583939\n",
            "Loss at test in  780  epoch\n",
            "0.31789395858005615\n",
            "Accuracy:  0.8966666666666666\n",
            "############################################################\n",
            "Loss at train in  781  epoch\n",
            "0.005234450686955155\n",
            "Loss at test in  781  epoch\n",
            "0.3194821467793194\n",
            "Accuracy:  0.9003333333333333\n",
            "############################################################\n",
            "Loss at train in  782  epoch\n",
            "0.005187266927870712\n",
            "Loss at test in  782  epoch\n",
            "0.338286309133866\n",
            "Accuracy:  0.8953333333333333\n",
            "############################################################\n",
            "Loss at train in  783  epoch\n",
            "0.004836670008731685\n",
            "Loss at test in  783  epoch\n",
            "0.3201270685773288\n",
            "Accuracy:  0.8933333333333333\n",
            "############################################################\n",
            "Loss at train in  784  epoch\n",
            "0.00429295692138974\n",
            "Loss at test in  784  epoch\n",
            "0.3254394283115972\n",
            "Accuracy:  0.888\n",
            "############################################################\n",
            "Loss at train in  785  epoch\n",
            "0.004942564282852135\n",
            "Loss at test in  785  epoch\n",
            "0.3154313645634103\n",
            "Accuracy:  0.8966666666666666\n",
            "############################################################\n",
            "Loss at train in  786  epoch\n",
            "0.004864762807147524\n",
            "Loss at test in  786  epoch\n",
            "0.33890159556250904\n",
            "Accuracy:  0.8896666666666667\n",
            "############################################################\n",
            "Loss at train in  787  epoch\n",
            "0.0042037374892352035\n",
            "Loss at test in  787  epoch\n",
            "0.3430440321870644\n",
            "Accuracy:  0.8953333333333333\n",
            "############################################################\n",
            "Loss at train in  788  epoch\n",
            "0.005902372738373301\n",
            "Loss at test in  788  epoch\n",
            "0.35705156816686384\n",
            "Accuracy:  0.8816666666666667\n",
            "############################################################\n",
            "Loss at train in  789  epoch\n",
            "0.005212743205543964\n",
            "Loss at test in  789  epoch\n",
            "0.31754392404887927\n",
            "Accuracy:  0.8943333333333333\n",
            "############################################################\n",
            "Loss at train in  790  epoch\n",
            "0.0045323316695464475\n",
            "Loss at test in  790  epoch\n",
            "0.350764835624784\n",
            "Accuracy:  0.8873333333333333\n",
            "############################################################\n",
            "Loss at train in  791  epoch\n",
            "0.005016041930443926\n",
            "Loss at test in  791  epoch\n",
            "0.3203209722751108\n",
            "Accuracy:  0.889\n",
            "############################################################\n",
            "Loss at train in  792  epoch\n",
            "0.0053350477333378825\n",
            "Loss at test in  792  epoch\n",
            "0.3225996304587098\n",
            "Accuracy:  0.8896666666666667\n",
            "############################################################\n",
            "Loss at train in  793  epoch\n",
            "0.004704546763415913\n",
            "Loss at test in  793  epoch\n",
            "0.337622752921007\n",
            "Accuracy:  0.8893333333333333\n",
            "############################################################\n",
            "Loss at train in  794  epoch\n",
            "0.004721885495922712\n",
            "Loss at test in  794  epoch\n",
            "0.33031510076351006\n",
            "Accuracy:  0.892\n",
            "############################################################\n",
            "Loss at train in  795  epoch\n",
            "0.0041809138289630055\n",
            "Loss at test in  795  epoch\n",
            "0.34196633306922813\n",
            "Accuracy:  0.885\n",
            "############################################################\n",
            "Loss at train in  796  epoch\n",
            "0.004886895460267903\n",
            "Loss at test in  796  epoch\n",
            "0.3056890750866813\n",
            "Accuracy:  0.8956666666666667\n",
            "############################################################\n",
            "Loss at train in  797  epoch\n",
            "0.004693999133260713\n",
            "Loss at test in  797  epoch\n",
            "0.3045699045020285\n",
            "Accuracy:  0.8933333333333333\n",
            "############################################################\n",
            "Loss at train in  798  epoch\n",
            "0.004740458150992825\n",
            "Loss at test in  798  epoch\n",
            "0.3184722209906987\n",
            "Accuracy:  0.8976666666666666\n",
            "############################################################\n",
            "Loss at train in  799  epoch\n",
            "0.005005525822366606\n",
            "Loss at test in  799  epoch\n",
            "0.3156427410015622\n",
            "Accuracy:  0.8946666666666667\n",
            "############################################################\n",
            "Loss at train in  800  epoch\n",
            "0.004809438078997295\n",
            "Loss at test in  800  epoch\n",
            "0.31769618106588254\n",
            "Accuracy:  0.8906666666666667\n",
            "############################################################\n",
            "Loss at train in  801  epoch\n",
            "0.004857016380242931\n",
            "Loss at test in  801  epoch\n",
            "0.30976358208528865\n",
            "Accuracy:  0.8993333333333333\n",
            "############################################################\n",
            "Loss at train in  802  epoch\n",
            "0.004269584988819496\n",
            "Loss at test in  802  epoch\n",
            "0.34065132383368274\n",
            "Accuracy:  0.893\n",
            "############################################################\n",
            "Loss at train in  803  epoch\n",
            "0.005706956732723937\n",
            "Loss at test in  803  epoch\n",
            "0.33862543023696856\n",
            "Accuracy:  0.8963333333333333\n",
            "############################################################\n",
            "Loss at train in  804  epoch\n",
            "0.004993466670200035\n",
            "Loss at test in  804  epoch\n",
            "0.3370109002563082\n",
            "Accuracy:  0.892\n",
            "############################################################\n",
            "Loss at train in  805  epoch\n",
            "0.004837713365815098\n",
            "Loss at test in  805  epoch\n",
            "0.3286605061208352\n",
            "Accuracy:  0.889\n",
            "############################################################\n",
            "Loss at train in  806  epoch\n",
            "0.005113759638207435\n",
            "Loss at test in  806  epoch\n",
            "0.35513774203823184\n",
            "Accuracy:  0.8826666666666667\n",
            "############################################################\n",
            "Loss at train in  807  epoch\n",
            "0.004768160380492708\n",
            "Loss at test in  807  epoch\n",
            "0.3234515933016612\n",
            "Accuracy:  0.897\n",
            "############################################################\n",
            "Loss at train in  808  epoch\n",
            "0.0057577607544183965\n",
            "Loss at test in  808  epoch\n",
            "0.3152901294733381\n",
            "Accuracy:  0.8936666666666667\n",
            "############################################################\n",
            "Loss at train in  809  epoch\n",
            "0.00493091152668876\n",
            "Loss at test in  809  epoch\n",
            "0.31992809977209935\n",
            "Accuracy:  0.892\n",
            "############################################################\n",
            "Loss at train in  810  epoch\n",
            "0.0039906972581135545\n",
            "Loss at test in  810  epoch\n",
            "0.3498880321412153\n",
            "Accuracy:  0.889\n",
            "############################################################\n",
            "Loss at train in  811  epoch\n",
            "0.004964472200139096\n",
            "Loss at test in  811  epoch\n",
            "0.31627414503777335\n",
            "Accuracy:  0.8956666666666667\n",
            "############################################################\n",
            "Loss at train in  812  epoch\n",
            "0.0052472503479773615\n",
            "Loss at test in  812  epoch\n",
            "0.32074527649766177\n",
            "Accuracy:  0.892\n",
            "############################################################\n",
            "Loss at train in  813  epoch\n",
            "0.00503104327025684\n",
            "Loss at test in  813  epoch\n",
            "0.3015449775775991\n",
            "Accuracy:  0.899\n",
            "############################################################\n",
            "Loss at train in  814  epoch\n",
            "0.004816652877988111\n",
            "Loss at test in  814  epoch\n",
            "0.3335612833626315\n",
            "Accuracy:  0.896\n",
            "############################################################\n",
            "Loss at train in  815  epoch\n",
            "0.0051943736653472065\n",
            "Loss at test in  815  epoch\n",
            "0.3409686890641972\n",
            "Accuracy:  0.8936666666666667\n",
            "############################################################\n",
            "Loss at train in  816  epoch\n",
            "0.004816767786471967\n",
            "Loss at test in  816  epoch\n",
            "0.3303647591965019\n",
            "Accuracy:  0.891\n",
            "############################################################\n",
            "Loss at train in  817  epoch\n",
            "0.004665760925795506\n",
            "Loss at test in  817  epoch\n",
            "0.30816796563594745\n",
            "Accuracy:  0.8946666666666667\n",
            "############################################################\n",
            "Loss at train in  818  epoch\n",
            "0.004928910473929656\n",
            "Loss at test in  818  epoch\n",
            "0.31943087205446286\n",
            "Accuracy:  0.8966666666666666\n",
            "############################################################\n",
            "Loss at train in  819  epoch\n",
            "0.004955762712506388\n",
            "Loss at test in  819  epoch\n",
            "0.3334588238918529\n",
            "Accuracy:  0.8876666666666667\n",
            "############################################################\n",
            "Loss at train in  820  epoch\n",
            "0.005189210127850571\n",
            "Loss at test in  820  epoch\n",
            "0.32034237669026844\n",
            "Accuracy:  0.8973333333333333\n",
            "############################################################\n",
            "Loss at train in  821  epoch\n",
            "0.004545416233707838\n",
            "Loss at test in  821  epoch\n",
            "0.32712169557306486\n",
            "Accuracy:  0.8966666666666666\n",
            "############################################################\n",
            "Loss at train in  822  epoch\n",
            "0.00459660743403074\n",
            "Loss at test in  822  epoch\n",
            "0.3303246190401687\n",
            "Accuracy:  0.884\n",
            "############################################################\n",
            "Loss at train in  823  epoch\n",
            "0.004915021013225709\n",
            "Loss at test in  823  epoch\n",
            "0.3384019526114217\n",
            "Accuracy:  0.8866666666666667\n",
            "############################################################\n",
            "Loss at train in  824  epoch\n",
            "0.004484097747271106\n",
            "Loss at test in  824  epoch\n",
            "0.3081479946861582\n",
            "Accuracy:  0.8943333333333333\n",
            "############################################################\n",
            "Loss at train in  825  epoch\n",
            "0.004712005808912086\n",
            "Loss at test in  825  epoch\n",
            "0.3264888526442675\n",
            "Accuracy:  0.8963333333333333\n",
            "############################################################\n",
            "Loss at train in  826  epoch\n",
            "0.003832100274433951\n",
            "Loss at test in  826  epoch\n",
            "0.3342646006726427\n",
            "Accuracy:  0.8946666666666667\n",
            "############################################################\n",
            "Loss at train in  827  epoch\n",
            "0.004649104964872773\n",
            "Loss at test in  827  epoch\n",
            "0.3271935398760976\n",
            "Accuracy:  0.8883333333333333\n",
            "############################################################\n",
            "Loss at train in  828  epoch\n",
            "0.005015947488146362\n",
            "Loss at test in  828  epoch\n",
            "0.3402481633685501\n",
            "Accuracy:  0.8913333333333333\n",
            "############################################################\n",
            "Loss at train in  829  epoch\n",
            "0.004550158352574283\n",
            "Loss at test in  829  epoch\n",
            "0.33828520635097836\n",
            "Accuracy:  0.8916666666666667\n",
            "############################################################\n",
            "Loss at train in  830  epoch\n",
            "0.004601576728149218\n",
            "Loss at test in  830  epoch\n",
            "0.33602730838621764\n",
            "Accuracy:  0.893\n",
            "############################################################\n",
            "Loss at train in  831  epoch\n",
            "0.0050253981960826305\n",
            "Loss at test in  831  epoch\n",
            "0.33773583214026165\n",
            "Accuracy:  0.881\n",
            "############################################################\n",
            "Loss at train in  832  epoch\n",
            "0.004596727927861254\n",
            "Loss at test in  832  epoch\n",
            "0.3493475607247162\n",
            "Accuracy:  0.8803333333333333\n",
            "############################################################\n",
            "Loss at train in  833  epoch\n",
            "0.004783135068967886\n",
            "Loss at test in  833  epoch\n",
            "0.3157815673331557\n",
            "Accuracy:  0.8966666666666666\n",
            "############################################################\n",
            "Loss at train in  834  epoch\n",
            "0.005515078841755574\n",
            "Loss at test in  834  epoch\n",
            "0.3244820630721176\n",
            "Accuracy:  0.8896666666666667\n",
            "############################################################\n",
            "Loss at train in  835  epoch\n",
            "0.0047541162116459335\n",
            "Loss at test in  835  epoch\n",
            "0.32341181486243004\n",
            "Accuracy:  0.8973333333333333\n",
            "############################################################\n",
            "Loss at train in  836  epoch\n",
            "0.004766913664490532\n",
            "Loss at test in  836  epoch\n",
            "0.3364326976883992\n",
            "Accuracy:  0.8976666666666666\n",
            "############################################################\n",
            "Loss at train in  837  epoch\n",
            "0.005036351128285845\n",
            "Loss at test in  837  epoch\n",
            "0.3199021891032141\n",
            "Accuracy:  0.8926666666666667\n",
            "############################################################\n",
            "Loss at train in  838  epoch\n",
            "0.004462551972758813\n",
            "Loss at test in  838  epoch\n",
            "0.32150005405353105\n",
            "Accuracy:  0.895\n",
            "############################################################\n",
            "Loss at train in  839  epoch\n",
            "0.004358054131059483\n",
            "Loss at test in  839  epoch\n",
            "0.3213463542437398\n",
            "Accuracy:  0.8953333333333333\n",
            "############################################################\n",
            "Loss at train in  840  epoch\n",
            "0.004036487735868004\n",
            "Loss at test in  840  epoch\n",
            "0.3245209134583818\n",
            "Accuracy:  0.897\n",
            "############################################################\n",
            "Loss at train in  841  epoch\n",
            "0.0044180669153390684\n",
            "Loss at test in  841  epoch\n",
            "0.3179030881155029\n",
            "Accuracy:  0.8936666666666667\n",
            "############################################################\n",
            "Loss at train in  842  epoch\n",
            "0.0046807020245428895\n",
            "Loss at test in  842  epoch\n",
            "0.3217817116121879\n",
            "Accuracy:  0.8953333333333333\n",
            "############################################################\n",
            "Loss at train in  843  epoch\n",
            "0.004739611672282442\n",
            "Loss at test in  843  epoch\n",
            "0.3373305763085801\n",
            "Accuracy:  0.8956666666666667\n",
            "############################################################\n",
            "Loss at train in  844  epoch\n",
            "0.0049421618049549036\n",
            "Loss at test in  844  epoch\n",
            "0.36327454946866683\n",
            "Accuracy:  0.8846666666666667\n",
            "############################################################\n",
            "Loss at train in  845  epoch\n",
            "0.004679541663688763\n",
            "Loss at test in  845  epoch\n",
            "0.33518885923610237\n",
            "Accuracy:  0.8923333333333333\n",
            "############################################################\n",
            "Loss at train in  846  epoch\n",
            "0.004442949801835146\n",
            "Loss at test in  846  epoch\n",
            "0.31750146499156556\n",
            "Accuracy:  0.896\n",
            "############################################################\n",
            "Loss at train in  847  epoch\n",
            "0.00425437822391839\n",
            "Loss at test in  847  epoch\n",
            "0.3222081538491919\n",
            "Accuracy:  0.8986666666666666\n",
            "############################################################\n",
            "Loss at train in  848  epoch\n",
            "0.0050514372881797324\n",
            "Loss at test in  848  epoch\n",
            "0.32380517184284935\n",
            "Accuracy:  0.8933333333333333\n",
            "############################################################\n",
            "Loss at train in  849  epoch\n",
            "0.00482470357586881\n",
            "Loss at test in  849  epoch\n",
            "0.33808803922416525\n",
            "Accuracy:  0.8986666666666666\n",
            "############################################################\n",
            "Loss at train in  850  epoch\n",
            "0.004911364202774491\n",
            "Loss at test in  850  epoch\n",
            "0.3275501369648282\n",
            "Accuracy:  0.892\n",
            "############################################################\n",
            "Loss at train in  851  epoch\n",
            "0.004546270001675808\n",
            "Loss at test in  851  epoch\n",
            "0.3211915404808353\n",
            "Accuracy:  0.894\n",
            "############################################################\n",
            "Loss at train in  852  epoch\n",
            "0.004508765995160824\n",
            "Loss at test in  852  epoch\n",
            "0.318698743487411\n",
            "Accuracy:  0.8983333333333333\n",
            "############################################################\n",
            "Loss at train in  853  epoch\n",
            "0.0048275740523418525\n",
            "Loss at test in  853  epoch\n",
            "0.3321558184509973\n",
            "Accuracy:  0.8903333333333333\n",
            "############################################################\n",
            "Loss at train in  854  epoch\n",
            "0.005106392824585112\n",
            "Loss at test in  854  epoch\n",
            "0.33074354730825484\n",
            "Accuracy:  0.888\n",
            "############################################################\n",
            "Loss at train in  855  epoch\n",
            "0.0056891797997241506\n",
            "Loss at test in  855  epoch\n",
            "0.3375018014742037\n",
            "Accuracy:  0.8883333333333333\n",
            "############################################################\n",
            "Loss at train in  856  epoch\n",
            "0.004637384003560649\n",
            "Loss at test in  856  epoch\n",
            "0.32929366618138023\n",
            "Accuracy:  0.8943333333333333\n",
            "############################################################\n",
            "Loss at train in  857  epoch\n",
            "0.005318692813989078\n",
            "Loss at test in  857  epoch\n",
            "0.32146194664783123\n",
            "Accuracy:  0.897\n",
            "############################################################\n",
            "Loss at train in  858  epoch\n",
            "0.004989978812343692\n",
            "Loss at test in  858  epoch\n",
            "0.3567448579156617\n",
            "Accuracy:  0.883\n",
            "############################################################\n",
            "Loss at train in  859  epoch\n",
            "0.004601848960218123\n",
            "Loss at test in  859  epoch\n",
            "0.3195990343099599\n",
            "Accuracy:  0.8963333333333333\n",
            "############################################################\n",
            "Loss at train in  860  epoch\n",
            "0.0042119801696747314\n",
            "Loss at test in  860  epoch\n",
            "0.330079600818411\n",
            "Accuracy:  0.8956666666666667\n",
            "############################################################\n",
            "Loss at train in  861  epoch\n",
            "0.005013082669934635\n",
            "Loss at test in  861  epoch\n",
            "0.32760400229291176\n",
            "Accuracy:  0.897\n",
            "############################################################\n",
            "Loss at train in  862  epoch\n",
            "0.005033997665369732\n",
            "Loss at test in  862  epoch\n",
            "0.30825800729774033\n",
            "Accuracy:  0.8976666666666666\n",
            "############################################################\n",
            "Loss at train in  863  epoch\n",
            "0.005352858480321103\n",
            "Loss at test in  863  epoch\n",
            "0.31562468032075713\n",
            "Accuracy:  0.8976666666666666\n",
            "############################################################\n",
            "Loss at train in  864  epoch\n",
            "0.004200752258297008\n",
            "Loss at test in  864  epoch\n",
            "0.31362492414998366\n",
            "Accuracy:  0.8963333333333333\n",
            "############################################################\n",
            "Loss at train in  865  epoch\n",
            "0.004657949124656231\n",
            "Loss at test in  865  epoch\n",
            "0.3194007232555873\n",
            "Accuracy:  0.8953333333333333\n",
            "############################################################\n",
            "Loss at train in  866  epoch\n",
            "0.004967338752701334\n",
            "Loss at test in  866  epoch\n",
            "0.3617080259147637\n",
            "Accuracy:  0.8823333333333333\n",
            "############################################################\n",
            "Loss at train in  867  epoch\n",
            "0.004764836068535337\n",
            "Loss at test in  867  epoch\n",
            "0.32965739726227994\n",
            "Accuracy:  0.895\n",
            "############################################################\n",
            "Loss at train in  868  epoch\n",
            "0.004903594156782115\n",
            "Loss at test in  868  epoch\n",
            "0.32366809247151646\n",
            "Accuracy:  0.8866666666666667\n",
            "############################################################\n",
            "Loss at train in  869  epoch\n",
            "0.004897834758193933\n",
            "Loss at test in  869  epoch\n",
            "0.33245819387939707\n",
            "Accuracy:  0.8906666666666667\n",
            "############################################################\n",
            "Loss at train in  870  epoch\n",
            "0.004496397909228077\n",
            "Loss at test in  870  epoch\n",
            "0.3271769735779596\n",
            "Accuracy:  0.8913333333333333\n",
            "############################################################\n",
            "Loss at train in  871  epoch\n",
            "0.00520031060645726\n",
            "Loss at test in  871  epoch\n",
            "0.3162977230050684\n",
            "Accuracy:  0.892\n",
            "############################################################\n",
            "Loss at train in  872  epoch\n",
            "0.004411821661161494\n",
            "Loss at test in  872  epoch\n",
            "0.32817794479119444\n",
            "Accuracy:  0.894\n",
            "############################################################\n",
            "Loss at train in  873  epoch\n",
            "0.0041012030798445115\n",
            "Loss at test in  873  epoch\n",
            "0.3379103825432441\n",
            "Accuracy:  0.8943333333333333\n",
            "############################################################\n",
            "Loss at train in  874  epoch\n",
            "0.004779583741972657\n",
            "Loss at test in  874  epoch\n",
            "0.31653590462371645\n",
            "Accuracy:  0.8916666666666667\n",
            "############################################################\n",
            "Loss at train in  875  epoch\n",
            "0.004731450300535799\n",
            "Loss at test in  875  epoch\n",
            "0.32991375321451905\n",
            "Accuracy:  0.8946666666666667\n",
            "############################################################\n",
            "Loss at train in  876  epoch\n",
            "0.005583678933222382\n",
            "Loss at test in  876  epoch\n",
            "0.31192015727612105\n",
            "Accuracy:  0.8986666666666666\n",
            "############################################################\n",
            "Loss at train in  877  epoch\n",
            "0.004117805810059267\n",
            "Loss at test in  877  epoch\n",
            "0.34336240655449435\n",
            "Accuracy:  0.8906666666666667\n",
            "############################################################\n",
            "Loss at train in  878  epoch\n",
            "0.004738336295145225\n",
            "Loss at test in  878  epoch\n",
            "0.3425687632019717\n",
            "Accuracy:  0.892\n",
            "############################################################\n",
            "Loss at train in  879  epoch\n",
            "0.004633872422306141\n",
            "Loss at test in  879  epoch\n",
            "0.3199655084757952\n",
            "Accuracy:  0.897\n",
            "############################################################\n",
            "Loss at train in  880  epoch\n",
            "0.005394051880058466\n",
            "Loss at test in  880  epoch\n",
            "0.3176479955857668\n",
            "Accuracy:  0.8926666666666667\n",
            "############################################################\n",
            "Loss at train in  881  epoch\n",
            "0.004679714098335769\n",
            "Loss at test in  881  epoch\n",
            "0.37976967817777935\n",
            "Accuracy:  0.89\n",
            "############################################################\n",
            "Loss at train in  882  epoch\n",
            "0.004515469349557475\n",
            "Loss at test in  882  epoch\n",
            "0.3150442904575754\n",
            "Accuracy:  0.8983333333333333\n",
            "############################################################\n",
            "Loss at train in  883  epoch\n",
            "0.0048610357325445455\n",
            "Loss at test in  883  epoch\n",
            "0.32073433370975907\n",
            "Accuracy:  0.8946666666666667\n",
            "############################################################\n",
            "Loss at train in  884  epoch\n",
            "0.0045888305186181574\n",
            "Loss at test in  884  epoch\n",
            "0.3353505792033276\n",
            "Accuracy:  0.8926666666666667\n",
            "############################################################\n",
            "Loss at train in  885  epoch\n",
            "0.005022919469139106\n",
            "Loss at test in  885  epoch\n",
            "0.3122667681029901\n",
            "Accuracy:  0.8973333333333333\n",
            "############################################################\n",
            "Loss at train in  886  epoch\n",
            "0.005105503555461806\n",
            "Loss at test in  886  epoch\n",
            "0.3179970575111532\n",
            "Accuracy:  0.9026666666666666\n",
            "############################################################\n",
            "Loss at train in  887  epoch\n",
            "0.004772727074185376\n",
            "Loss at test in  887  epoch\n",
            "0.3236359178055595\n",
            "Accuracy:  0.892\n",
            "############################################################\n",
            "Loss at train in  888  epoch\n",
            "0.00434451904430802\n",
            "Loss at test in  888  epoch\n",
            "0.3392420242325155\n",
            "Accuracy:  0.8903333333333333\n",
            "############################################################\n",
            "Loss at train in  889  epoch\n",
            "0.004558675293378495\n",
            "Loss at test in  889  epoch\n",
            "0.34235892850834504\n",
            "Accuracy:  0.887\n",
            "############################################################\n",
            "Loss at train in  890  epoch\n",
            "0.0041459599641396625\n",
            "Loss at test in  890  epoch\n",
            "0.33373800402969994\n",
            "Accuracy:  0.8913333333333333\n",
            "############################################################\n",
            "Loss at train in  891  epoch\n",
            "0.004494179573840857\n",
            "Loss at test in  891  epoch\n",
            "0.3554560364248963\n",
            "Accuracy:  0.8903333333333333\n",
            "############################################################\n",
            "Loss at train in  892  epoch\n",
            "0.004574672423285849\n",
            "Loss at test in  892  epoch\n",
            "0.3206150231322695\n",
            "Accuracy:  0.8883333333333333\n",
            "############################################################\n",
            "Loss at train in  893  epoch\n",
            "0.004937089682978787\n",
            "Loss at test in  893  epoch\n",
            "0.34013164083836106\n",
            "Accuracy:  0.893\n",
            "############################################################\n",
            "Loss at train in  894  epoch\n",
            "0.00492873146864606\n",
            "Loss at test in  894  epoch\n",
            "0.3228514664906258\n",
            "Accuracy:  0.893\n",
            "############################################################\n",
            "Loss at train in  895  epoch\n",
            "0.004540390121908846\n",
            "Loss at test in  895  epoch\n",
            "0.3361004157106214\n",
            "Accuracy:  0.8913333333333333\n",
            "############################################################\n",
            "Loss at train in  896  epoch\n",
            "0.004051681817603365\n",
            "Loss at test in  896  epoch\n",
            "0.3316547614383227\n",
            "Accuracy:  0.8933333333333333\n",
            "############################################################\n",
            "Loss at train in  897  epoch\n",
            "0.004616869265573536\n",
            "Loss at test in  897  epoch\n",
            "0.3385226881895908\n",
            "Accuracy:  0.89\n",
            "############################################################\n",
            "Loss at train in  898  epoch\n",
            "0.0039574069862535\n",
            "Loss at test in  898  epoch\n",
            "0.3303773989791064\n",
            "Accuracy:  0.898\n",
            "############################################################\n",
            "Loss at train in  899  epoch\n",
            "0.005109398817516132\n",
            "Loss at test in  899  epoch\n",
            "0.36142758605135\n",
            "Accuracy:  0.878\n",
            "############################################################\n",
            "Loss at train in  900  epoch\n",
            "0.0043479734268062255\n",
            "Loss at test in  900  epoch\n",
            "0.3203249913657234\n",
            "Accuracy:  0.8983333333333333\n",
            "############################################################\n",
            "Loss at train in  901  epoch\n",
            "0.0054719211645638515\n",
            "Loss at test in  901  epoch\n",
            "0.3471271447164862\n",
            "Accuracy:  0.887\n",
            "############################################################\n",
            "Loss at train in  902  epoch\n",
            "0.004640550186753321\n",
            "Loss at test in  902  epoch\n",
            "0.3334279409501843\n",
            "Accuracy:  0.8983333333333333\n",
            "############################################################\n",
            "Loss at train in  903  epoch\n",
            "0.004839093503545704\n",
            "Loss at test in  903  epoch\n",
            "0.3172723625302174\n",
            "Accuracy:  0.895\n",
            "############################################################\n",
            "Loss at train in  904  epoch\n",
            "0.004132515289579726\n",
            "Loss at test in  904  epoch\n",
            "0.3528102488212857\n",
            "Accuracy:  0.8936666666666667\n",
            "############################################################\n",
            "Loss at train in  905  epoch\n",
            "0.004147283183505219\n",
            "Loss at test in  905  epoch\n",
            "0.3282309127920158\n",
            "Accuracy:  0.8926666666666667\n",
            "############################################################\n",
            "Loss at train in  906  epoch\n",
            "0.005557883577514496\n",
            "Loss at test in  906  epoch\n",
            "0.3178614068342577\n",
            "Accuracy:  0.8873333333333333\n",
            "############################################################\n",
            "Loss at train in  907  epoch\n",
            "0.0048570321569878635\n",
            "Loss at test in  907  epoch\n",
            "0.32298755879701124\n",
            "Accuracy:  0.8873333333333333\n",
            "############################################################\n",
            "Loss at train in  908  epoch\n",
            "0.004608380496975366\n",
            "Loss at test in  908  epoch\n",
            "0.3540645876975656\n",
            "Accuracy:  0.8906666666666667\n",
            "############################################################\n",
            "Loss at train in  909  epoch\n",
            "0.005215983971836845\n",
            "Loss at test in  909  epoch\n",
            "0.31418697610510193\n",
            "Accuracy:  0.8913333333333333\n",
            "############################################################\n",
            "Loss at train in  910  epoch\n",
            "0.00438870357714648\n",
            "Loss at test in  910  epoch\n",
            "0.3247882391378188\n",
            "Accuracy:  0.896\n",
            "############################################################\n",
            "Loss at train in  911  epoch\n",
            "0.004143379262431598\n",
            "Loss at test in  911  epoch\n",
            "0.33086960341332294\n",
            "Accuracy:  0.8953333333333333\n",
            "############################################################\n",
            "Loss at train in  912  epoch\n",
            "0.00471666471476209\n",
            "Loss at test in  912  epoch\n",
            "0.33245849726141524\n",
            "Accuracy:  0.8893333333333333\n",
            "############################################################\n",
            "Loss at train in  913  epoch\n",
            "0.004635196764136461\n",
            "Loss at test in  913  epoch\n",
            "0.33731809028976223\n",
            "Accuracy:  0.8943333333333333\n",
            "############################################################\n",
            "Loss at train in  914  epoch\n",
            "0.005417581136660533\n",
            "Loss at test in  914  epoch\n",
            "0.33426181212001627\n",
            "Accuracy:  0.894\n",
            "############################################################\n",
            "Loss at train in  915  epoch\n",
            "0.004992228151621878\n",
            "Loss at test in  915  epoch\n",
            "0.33277644339728235\n",
            "Accuracy:  0.885\n",
            "############################################################\n",
            "Loss at train in  916  epoch\n",
            "0.004701641675837844\n",
            "Loss at test in  916  epoch\n",
            "0.32204057382519113\n",
            "Accuracy:  0.8963333333333333\n",
            "############################################################\n",
            "Loss at train in  917  epoch\n",
            "0.004263908903691863\n",
            "Loss at test in  917  epoch\n",
            "0.3133741919986008\n",
            "Accuracy:  0.8976666666666666\n",
            "############################################################\n",
            "Loss at train in  918  epoch\n",
            "0.0043552804975937045\n",
            "Loss at test in  918  epoch\n",
            "0.3473971598492151\n",
            "Accuracy:  0.887\n",
            "############################################################\n",
            "Loss at train in  919  epoch\n",
            "0.004663408756392598\n",
            "Loss at test in  919  epoch\n",
            "0.3233661258826191\n",
            "Accuracy:  0.893\n",
            "############################################################\n",
            "Loss at train in  920  epoch\n",
            "0.004267683108691197\n",
            "Loss at test in  920  epoch\n",
            "0.31737436843669437\n",
            "Accuracy:  0.9006666666666666\n",
            "############################################################\n",
            "Loss at train in  921  epoch\n",
            "0.005159986852091229\n",
            "Loss at test in  921  epoch\n",
            "0.3129581928451025\n",
            "Accuracy:  0.8956666666666667\n",
            "############################################################\n",
            "Loss at train in  922  epoch\n",
            "0.0036984635482576163\n",
            "Loss at test in  922  epoch\n",
            "0.3474722770993109\n",
            "Accuracy:  0.893\n",
            "############################################################\n",
            "Loss at train in  923  epoch\n",
            "0.00432202216574028\n",
            "Loss at test in  923  epoch\n",
            "0.32998417308465267\n",
            "Accuracy:  0.8953333333333333\n",
            "############################################################\n",
            "Loss at train in  924  epoch\n",
            "0.005399123188768851\n",
            "Loss at test in  924  epoch\n",
            "0.32742221758925033\n",
            "Accuracy:  0.8916666666666667\n",
            "############################################################\n",
            "Loss at train in  925  epoch\n",
            "0.005124260997253449\n",
            "Loss at test in  925  epoch\n",
            "0.32710322152541704\n",
            "Accuracy:  0.9016666666666666\n",
            "############################################################\n",
            "Loss at train in  926  epoch\n",
            "0.004226884249443723\n",
            "Loss at test in  926  epoch\n",
            "0.3254533175910442\n",
            "Accuracy:  0.8976666666666666\n",
            "############################################################\n",
            "Loss at train in  927  epoch\n",
            "0.00479527960621356\n",
            "Loss at test in  927  epoch\n",
            "0.3469779244523662\n",
            "Accuracy:  0.8926666666666667\n",
            "############################################################\n",
            "Loss at train in  928  epoch\n",
            "0.004702313135766497\n",
            "Loss at test in  928  epoch\n",
            "0.3319511988279055\n",
            "Accuracy:  0.8896666666666667\n",
            "############################################################\n",
            "Loss at train in  929  epoch\n",
            "0.00456957594207484\n",
            "Loss at test in  929  epoch\n",
            "0.317298987764446\n",
            "Accuracy:  0.8976666666666666\n",
            "############################################################\n",
            "Loss at train in  930  epoch\n",
            "0.00366744605036422\n",
            "Loss at test in  930  epoch\n",
            "0.3176816767452009\n",
            "Accuracy:  0.8896666666666667\n",
            "############################################################\n",
            "Loss at train in  931  epoch\n",
            "0.003884629741232334\n",
            "Loss at test in  931  epoch\n",
            "0.3402549205217478\n",
            "Accuracy:  0.8923333333333333\n",
            "############################################################\n",
            "Loss at train in  932  epoch\n",
            "0.004790621680517961\n",
            "Loss at test in  932  epoch\n",
            "0.3441741719708748\n",
            "Accuracy:  0.8916666666666667\n",
            "############################################################\n",
            "Loss at train in  933  epoch\n",
            "0.004360330620786779\n",
            "Loss at test in  933  epoch\n",
            "0.3172040028381715\n",
            "Accuracy:  0.8986666666666666\n",
            "############################################################\n",
            "Loss at train in  934  epoch\n",
            "0.0045754420118426795\n",
            "Loss at test in  934  epoch\n",
            "0.3653842686394046\n",
            "Accuracy:  0.885\n",
            "############################################################\n",
            "Loss at train in  935  epoch\n",
            "0.0048513535006606805\n",
            "Loss at test in  935  epoch\n",
            "0.32713941264531776\n",
            "Accuracy:  0.8936666666666667\n",
            "############################################################\n",
            "Loss at train in  936  epoch\n",
            "0.005072907074042131\n",
            "Loss at test in  936  epoch\n",
            "0.32521989204603236\n",
            "Accuracy:  0.897\n",
            "############################################################\n",
            "Loss at train in  937  epoch\n",
            "0.004474826083516144\n",
            "Loss at test in  937  epoch\n",
            "0.3170872686356703\n",
            "Accuracy:  0.9026666666666666\n",
            "############################################################\n",
            "Loss at train in  938  epoch\n",
            "0.004038228389567312\n",
            "Loss at test in  938  epoch\n",
            "0.3717269289221194\n",
            "Accuracy:  0.8866666666666667\n",
            "############################################################\n",
            "Loss at train in  939  epoch\n",
            "0.005161102292606881\n",
            "Loss at test in  939  epoch\n",
            "0.33772988930708575\n",
            "Accuracy:  0.8906666666666667\n",
            "############################################################\n",
            "Loss at train in  940  epoch\n",
            "0.00443009884776665\n",
            "Loss at test in  940  epoch\n",
            "0.31788821597267786\n",
            "Accuracy:  0.899\n",
            "############################################################\n",
            "Loss at train in  941  epoch\n",
            "0.004017643445748541\n",
            "Loss at test in  941  epoch\n",
            "0.3404013780576413\n",
            "Accuracy:  0.8946666666666667\n",
            "############################################################\n",
            "Loss at train in  942  epoch\n",
            "0.005364774464769144\n",
            "Loss at test in  942  epoch\n",
            "0.3101252790444665\n",
            "Accuracy:  0.892\n",
            "############################################################\n",
            "Loss at train in  943  epoch\n",
            "0.0042796710698964\n",
            "Loss at test in  943  epoch\n",
            "0.34757531211708903\n",
            "Accuracy:  0.8926666666666667\n",
            "############################################################\n",
            "Loss at train in  944  epoch\n",
            "0.004225496224176517\n",
            "Loss at test in  944  epoch\n",
            "0.33037137515768455\n",
            "Accuracy:  0.8883333333333333\n",
            "############################################################\n",
            "Loss at train in  945  epoch\n",
            "0.004394017005779517\n",
            "Loss at test in  945  epoch\n",
            "0.3654595215075468\n",
            "Accuracy:  0.885\n",
            "############################################################\n",
            "Loss at train in  946  epoch\n",
            "0.004656266857935627\n",
            "Loss at test in  946  epoch\n",
            "0.31518270232393614\n",
            "Accuracy:  0.893\n",
            "############################################################\n",
            "Loss at train in  947  epoch\n",
            "0.00448927303520202\n",
            "Loss at test in  947  epoch\n",
            "0.33258435427097277\n",
            "Accuracy:  0.891\n",
            "############################################################\n",
            "Loss at train in  948  epoch\n",
            "0.004527333911366826\n",
            "Loss at test in  948  epoch\n",
            "0.32427245655384224\n",
            "Accuracy:  0.8993333333333333\n",
            "############################################################\n",
            "Loss at train in  949  epoch\n",
            "0.004669377041298578\n",
            "Loss at test in  949  epoch\n",
            "0.34774759805259264\n",
            "Accuracy:  0.8876666666666667\n",
            "############################################################\n",
            "Loss at train in  950  epoch\n",
            "0.004370960650537881\n",
            "Loss at test in  950  epoch\n",
            "0.35477482854007203\n",
            "Accuracy:  0.8906666666666667\n",
            "############################################################\n",
            "Loss at train in  951  epoch\n",
            "0.005007841755927545\n",
            "Loss at test in  951  epoch\n",
            "0.3495722568830606\n",
            "Accuracy:  0.8886666666666667\n",
            "############################################################\n",
            "Loss at train in  952  epoch\n",
            "0.004635281151519538\n",
            "Loss at test in  952  epoch\n",
            "0.33356718060846346\n",
            "Accuracy:  0.8993333333333333\n",
            "############################################################\n",
            "Loss at train in  953  epoch\n",
            "0.0043820790484901655\n",
            "Loss at test in  953  epoch\n",
            "0.3369753435861257\n",
            "Accuracy:  0.8916666666666667\n",
            "############################################################\n",
            "Loss at train in  954  epoch\n",
            "0.004023875930447998\n",
            "Loss at test in  954  epoch\n",
            "0.33084414965801306\n",
            "Accuracy:  0.899\n",
            "############################################################\n",
            "Loss at train in  955  epoch\n",
            "0.0038749980345476054\n",
            "Loss at test in  955  epoch\n",
            "0.3402177778547757\n",
            "Accuracy:  0.892\n",
            "############################################################\n",
            "Loss at train in  956  epoch\n",
            "0.0037285966163008257\n",
            "Loss at test in  956  epoch\n",
            "0.3288250889942591\n",
            "Accuracy:  0.8943333333333333\n",
            "############################################################\n",
            "Loss at train in  957  epoch\n",
            "0.004494506187840357\n",
            "Loss at test in  957  epoch\n",
            "0.331883007227901\n",
            "Accuracy:  0.8973333333333333\n",
            "############################################################\n",
            "Loss at train in  958  epoch\n",
            "0.003662652357976402\n",
            "Loss at test in  958  epoch\n",
            "0.35560157112245233\n",
            "Accuracy:  0.8993333333333333\n",
            "############################################################\n",
            "Loss at train in  959  epoch\n",
            "0.0043441008212963365\n",
            "Loss at test in  959  epoch\n",
            "0.35006691015054464\n",
            "Accuracy:  0.8913333333333333\n",
            "############################################################\n",
            "Loss at train in  960  epoch\n",
            "0.005176512454140646\n",
            "Loss at test in  960  epoch\n",
            "0.35359675182520733\n",
            "Accuracy:  0.8913333333333333\n",
            "############################################################\n",
            "Loss at train in  961  epoch\n",
            "0.0039373115854696465\n",
            "Loss at test in  961  epoch\n",
            "0.35797195082811256\n",
            "Accuracy:  0.892\n",
            "############################################################\n",
            "Loss at train in  962  epoch\n",
            "0.004495640642286909\n",
            "Loss at test in  962  epoch\n",
            "0.32487576397304285\n",
            "Accuracy:  0.897\n",
            "############################################################\n",
            "Loss at train in  963  epoch\n",
            "0.005073106617233026\n",
            "Loss at test in  963  epoch\n",
            "0.31518973947578055\n",
            "Accuracy:  0.8966666666666666\n",
            "############################################################\n",
            "Loss at train in  964  epoch\n",
            "0.004107087299830109\n",
            "Loss at test in  964  epoch\n",
            "0.3311511594205465\n",
            "Accuracy:  0.8903333333333333\n",
            "############################################################\n",
            "Loss at train in  965  epoch\n",
            "0.004612438078705928\n",
            "Loss at test in  965  epoch\n",
            "0.3329765506019507\n",
            "Accuracy:  0.893\n",
            "############################################################\n",
            "Loss at train in  966  epoch\n",
            "0.0037343454672798915\n",
            "Loss at test in  966  epoch\n",
            "0.34100130677967905\n",
            "Accuracy:  0.899\n",
            "############################################################\n",
            "Loss at train in  967  epoch\n",
            "0.004570741593066763\n",
            "Loss at test in  967  epoch\n",
            "0.3350269593426323\n",
            "Accuracy:  0.8963333333333333\n",
            "############################################################\n",
            "Loss at train in  968  epoch\n",
            "0.003423548486602829\n",
            "Loss at test in  968  epoch\n",
            "0.3628675404906208\n",
            "Accuracy:  0.8943333333333333\n",
            "############################################################\n",
            "Loss at train in  969  epoch\n",
            "0.004822035485988206\n",
            "Loss at test in  969  epoch\n",
            "0.3370476648209562\n",
            "Accuracy:  0.8943333333333333\n",
            "############################################################\n",
            "Loss at train in  970  epoch\n",
            "0.005097130591198256\n",
            "Loss at test in  970  epoch\n",
            "0.34637179691698816\n",
            "Accuracy:  0.8923333333333333\n",
            "############################################################\n",
            "Loss at train in  971  epoch\n",
            "0.004485310819717325\n",
            "Loss at test in  971  epoch\n",
            "0.3321028886059293\n",
            "Accuracy:  0.8886666666666667\n",
            "############################################################\n",
            "Loss at train in  972  epoch\n",
            "0.004426755135683175\n",
            "Loss at test in  972  epoch\n",
            "0.34048178511773325\n",
            "Accuracy:  0.887\n",
            "############################################################\n",
            "Loss at train in  973  epoch\n",
            "0.004518758192815843\n",
            "Loss at test in  973  epoch\n",
            "0.3268112565539293\n",
            "Accuracy:  0.8946666666666667\n",
            "############################################################\n",
            "Loss at train in  974  epoch\n",
            "0.004488198824484257\n",
            "Loss at test in  974  epoch\n",
            "0.3296607485931908\n",
            "Accuracy:  0.8913333333333333\n",
            "############################################################\n",
            "Loss at train in  975  epoch\n",
            "0.004492499618656713\n",
            "Loss at test in  975  epoch\n",
            "0.32324102020671025\n",
            "Accuracy:  0.8976666666666666\n",
            "############################################################\n",
            "Loss at train in  976  epoch\n",
            "0.0036890575876995023\n",
            "Loss at test in  976  epoch\n",
            "0.3275500714724676\n",
            "Accuracy:  0.8876666666666667\n",
            "############################################################\n",
            "Loss at train in  977  epoch\n",
            "0.004269986735416836\n",
            "Loss at test in  977  epoch\n",
            "0.3142252125209867\n",
            "Accuracy:  0.9016666666666666\n",
            "############################################################\n",
            "Loss at train in  978  epoch\n",
            "0.004346439624160565\n",
            "Loss at test in  978  epoch\n",
            "0.3371115428923986\n",
            "Accuracy:  0.8943333333333333\n",
            "############################################################\n",
            "Loss at train in  979  epoch\n",
            "0.004400287601150896\n",
            "Loss at test in  979  epoch\n",
            "0.31573827930278314\n",
            "Accuracy:  0.894\n",
            "############################################################\n",
            "Loss at train in  980  epoch\n",
            "0.004389132902767474\n",
            "Loss at test in  980  epoch\n",
            "0.3542260526630267\n",
            "Accuracy:  0.89\n",
            "############################################################\n",
            "Loss at train in  981  epoch\n",
            "0.0042187961276014645\n",
            "Loss at test in  981  epoch\n",
            "0.3408463111599634\n",
            "Accuracy:  0.894\n",
            "############################################################\n",
            "Loss at train in  982  epoch\n",
            "0.004703747832555985\n",
            "Loss at test in  982  epoch\n",
            "0.34056949909826084\n",
            "Accuracy:  0.8943333333333333\n",
            "############################################################\n",
            "Loss at train in  983  epoch\n",
            "0.004104686106900349\n",
            "Loss at test in  983  epoch\n",
            "0.34091112599887213\n",
            "Accuracy:  0.8933333333333333\n",
            "############################################################\n",
            "Loss at train in  984  epoch\n",
            "0.004052488274541993\n",
            "Loss at test in  984  epoch\n",
            "0.3395153128573103\n",
            "Accuracy:  0.8923333333333333\n",
            "############################################################\n",
            "Loss at train in  985  epoch\n",
            "0.00483902350981295\n",
            "Loss at test in  985  epoch\n",
            "0.3247906002540684\n",
            "Accuracy:  0.8956666666666667\n",
            "############################################################\n",
            "Loss at train in  986  epoch\n",
            "0.004232102163099346\n",
            "Loss at test in  986  epoch\n",
            "0.34718489424279825\n",
            "Accuracy:  0.8946666666666667\n",
            "############################################################\n",
            "Loss at train in  987  epoch\n",
            "0.004627580345971249\n",
            "Loss at test in  987  epoch\n",
            "0.3207131909834641\n",
            "Accuracy:  0.8956666666666667\n",
            "############################################################\n",
            "Loss at train in  988  epoch\n",
            "0.004396091098008189\n",
            "Loss at test in  988  epoch\n",
            "0.3846146564903644\n",
            "Accuracy:  0.8843333333333333\n",
            "############################################################\n",
            "Loss at train in  989  epoch\n",
            "0.004918603250163769\n",
            "Loss at test in  989  epoch\n",
            "0.32190676333751644\n",
            "Accuracy:  0.898\n",
            "############################################################\n",
            "Loss at train in  990  epoch\n",
            "0.004440206608823985\n",
            "Loss at test in  990  epoch\n",
            "0.350854781008719\n",
            "Accuracy:  0.889\n",
            "############################################################\n",
            "Loss at train in  991  epoch\n",
            "0.0037069498685702736\n",
            "Loss at test in  991  epoch\n",
            "0.3460639850794702\n",
            "Accuracy:  0.8943333333333333\n",
            "############################################################\n",
            "Loss at train in  992  epoch\n",
            "0.004708677697794825\n",
            "Loss at test in  992  epoch\n",
            "0.34334994988476336\n",
            "Accuracy:  0.8956666666666667\n",
            "############################################################\n",
            "Loss at train in  993  epoch\n",
            "0.004804073029406596\n",
            "Loss at test in  993  epoch\n",
            "0.3400369191159219\n",
            "Accuracy:  0.8956666666666667\n",
            "############################################################\n",
            "Loss at train in  994  epoch\n",
            "0.0040801145184820265\n",
            "Loss at test in  994  epoch\n",
            "0.3324186841100193\n",
            "Accuracy:  0.8956666666666667\n",
            "############################################################\n",
            "Loss at train in  995  epoch\n",
            "0.004178281623700881\n",
            "Loss at test in  995  epoch\n",
            "0.34672712498075603\n",
            "Accuracy:  0.8903333333333333\n",
            "############################################################\n",
            "Loss at train in  996  epoch\n",
            "0.004372546723417478\n",
            "Loss at test in  996  epoch\n",
            "0.3711388765856628\n",
            "Accuracy:  0.885\n",
            "############################################################\n",
            "Loss at train in  997  epoch\n",
            "0.0034415680863477504\n",
            "Loss at test in  997  epoch\n",
            "0.37468933484685363\n",
            "Accuracy:  0.8826666666666667\n",
            "############################################################\n",
            "Loss at train in  998  epoch\n",
            "0.004015917477953449\n",
            "Loss at test in  998  epoch\n",
            "0.3357048734165823\n",
            "Accuracy:  0.8946666666666667\n",
            "############################################################\n",
            "Loss at train in  999  epoch\n",
            "0.0042533950152983694\n",
            "Loss at test in  999  epoch\n",
            "0.34806429628473906\n",
            "Accuracy:  0.898\n",
            "############################################################\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x1080 with 3 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "np.random.seed(SEED)\n",
        "NUM_EPOCH = 1000\n",
        "learning_rate = 0.001\n",
        "L_train_acc = [] # массив для хранения лоссов на обучении за эпоху\n",
        "L_test_acc = [] # массив для хранения лоссов на отложенном сете\n",
        "Acc_test_acc = [] # массив для хранения точности на отложенном сете за эпоху\n",
        "\n",
        "loss = CrossEntropy()\n",
        "\n",
        "Acc_to_stop = 0.91\n",
        "\n",
        "fig = plt.figure(figsize=(20, 15))\n",
        "ax1 = fig.add_subplot(311)\n",
        "ax2 = fig.add_subplot(312)\n",
        "ax3 = fig.add_subplot(313)\n",
        "\n",
        "for epoch in tqdm(range(NUM_EPOCH)):\n",
        "\n",
        "    # ЧАСТЬ 1:\n",
        "    # проводим эпоху обучения, сохраняем средний лосс по всем примерам за эпоху\n",
        "    # в переменной L_train_acc\n",
        "\n",
        "    L_acc = 0.\n",
        "    sh = list(range(Xt_train_mod.shape[0]))\n",
        "    np.random.shuffle(sh)\n",
        "    sh = sh[:1500]\n",
        "    for i in range(len(sh)):\n",
        "        x = Xt_train_mod[sh[i]]\n",
        "        y = yt_train_oh[sh[i]]\n",
        "        y_h = net.forward(x)\n",
        "        L = loss.forward(y, y_h)\n",
        "        L_acc += L\n",
        "        dz = loss.backward(1, learning_rate)\n",
        "        dz = net.backward(dz, learning_rate)\n",
        "    L_train_acc.append(L_acc / Xt_train_mod.shape[0])\n",
        "    print(\"Loss at train in \", epoch, \" epoch\")\n",
        "    print(L_train_acc[-1])\n",
        "\n",
        "    # ЧАСТЬ 2:\n",
        "    # Оцениваем сеть после одной эпохи на отложенной выборке\n",
        "    # Сохраняем средний лосс в переменной L_test_acc\n",
        "    # Сохраняем среднее значение accuracy в Acc_test_acc\n",
        "\n",
        "    L_acc = 0.\n",
        "    temp = 0.\n",
        "    for i in range(Xt_test_mod.shape[0]):\n",
        "      x = Xt_test_mod[i]\n",
        "      y = yt_test_oh[i]\n",
        "      y_h = net.forward(x)\n",
        "      L = loss.forward(y, y_h)\n",
        "      L_acc += L\n",
        "      temp += int(y_test[i] == np.argmax(y_h))\n",
        "    L_test_acc.append(L_acc / Xt_test_mod.shape[0])\n",
        "    Acc_test_acc.append(temp / Xt_test_mod.shape[0])\n",
        " \n",
        "    # Выводим 2 графика : \n",
        "    # 1) Лоссы на трейне и отложенном сете по эпохам\n",
        "    # 2) Точность(accuracy) по эпохам на отложенном сете\n",
        "\n",
        "    print(\"Loss at test in \", epoch, \" epoch\")\n",
        "    print(L_test_acc[-1])\n",
        "    print(\"Accuracy: \", Acc_test_acc[-1])\n",
        "    print(\"#\"*60)\n",
        "\n",
        "    ax1.plot(range(epoch + 1), L_train_acc, 'r-')\n",
        "    ax1.set_title('Loss at train')\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    fig.canvas.draw()\n",
        "    \n",
        "    ax2.plot(range(epoch + 1), L_test_acc, 'r-')\n",
        "    ax2.set_title('Loss at test')\n",
        "    ax2.set_xlabel('Epoch')\n",
        "    fig.canvas.draw() \n",
        "    \n",
        "    ax3.plot(range(epoch + 1), Acc_test_acc, 'g-')\n",
        "    ax3.set_title('Accuracy')\n",
        "    ax3.set_xlabel('Epoch')\n",
        "    fig.canvas.draw()\n",
        "\n",
        "    if(Acc_test_acc[-1] > Acc_to_stop):\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "id": "cafadce0",
      "metadata": {
        "id": "cafadce0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "1d0e0091c3fc4ad88414916063ddacdf",
            "0550666969a14f03afb48d6a19eae7b9",
            "a934233ad22543b0aa19cf7f6e24a1c3",
            "a57a670908234f04a99a70d1b1dab6af",
            "2a62277345ff4be7b55312368729c88c",
            "7545aff2ad8b4af6b52f870300d04d35",
            "3efdd1125f9948a7a34c3b132c1a9442",
            "d9a8d3b9e68f43f7ab0c9b72d5e2760f",
            "2243fa615a8b4f52bd5ecc722fec3317",
            "a191411669644aaa8bfef5948083ef71",
            "64fbdc56d67747249ad861965eb8dff9"
          ]
        },
        "outputId": "469c3714-cd39-41f0-a7e7-3dfa73cf109e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1d0e0091c3fc4ad88414916063ddacdf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# формируем сабмишшен\n",
        "with open(OUTPUT_FNAME, 'w') as fout: \n",
        "    fout.write(\"Id,Category\\n\")\n",
        "    for i, x in tqdm(enumerate(X_valid_mod)):\n",
        "        n_out = net.forward(x)\n",
        "        fout.write(f\"{i},{np.argmax(n_out, axis=0)}\\n\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    },
    "colab": {
      "name": "Network 2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "057c56bb7c63429588a1ae7b02bd1ee3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7417324dfa2e411f869f59820c370cad",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7b45758f3438487094a0f4ab032c7641",
              "IPY_MODEL_c3346df0d1aa486ea84f8b4280c42c7b",
              "IPY_MODEL_8247dbc9c7e5426093e40e8d0b3f8d01"
            ]
          }
        },
        "7417324dfa2e411f869f59820c370cad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7b45758f3438487094a0f4ab032c7641": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2c4fc5885cf342c38b39655bbeebcae4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ec80d5f905624c5fa5e63426b8696f45"
          }
        },
        "c3346df0d1aa486ea84f8b4280c42c7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3a5041d6cfde40fba520d53400611162",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_78d6bb76ac644552b90ec10402e14b30"
          }
        },
        "8247dbc9c7e5426093e40e8d0b3f8d01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_904ca9309a3745bfb393becc615920de",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1000/1000 [1:29:55&lt;00:00,  9.47s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5dd52d5f6f124352915a32ca4ec9c105"
          }
        },
        "2c4fc5885cf342c38b39655bbeebcae4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ec80d5f905624c5fa5e63426b8696f45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3a5041d6cfde40fba520d53400611162": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "78d6bb76ac644552b90ec10402e14b30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "904ca9309a3745bfb393becc615920de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5dd52d5f6f124352915a32ca4ec9c105": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1d0e0091c3fc4ad88414916063ddacdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0550666969a14f03afb48d6a19eae7b9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a934233ad22543b0aa19cf7f6e24a1c3",
              "IPY_MODEL_a57a670908234f04a99a70d1b1dab6af",
              "IPY_MODEL_2a62277345ff4be7b55312368729c88c"
            ]
          }
        },
        "0550666969a14f03afb48d6a19eae7b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a934233ad22543b0aa19cf7f6e24a1c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7545aff2ad8b4af6b52f870300d04d35",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3efdd1125f9948a7a34c3b132c1a9442"
          }
        },
        "a57a670908234f04a99a70d1b1dab6af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d9a8d3b9e68f43f7ab0c9b72d5e2760f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2243fa615a8b4f52bd5ecc722fec3317"
          }
        },
        "2a62277345ff4be7b55312368729c88c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a191411669644aaa8bfef5948083ef71",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 10000/? [00:01&lt;00:00, 5798.51it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_64fbdc56d67747249ad861965eb8dff9"
          }
        },
        "7545aff2ad8b4af6b52f870300d04d35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3efdd1125f9948a7a34c3b132c1a9442": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d9a8d3b9e68f43f7ab0c9b72d5e2760f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2243fa615a8b4f52bd5ecc722fec3317": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": "20px",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a191411669644aaa8bfef5948083ef71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "64fbdc56d67747249ad861965eb8dff9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}